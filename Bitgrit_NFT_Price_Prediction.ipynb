{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/denizstij/Bitgrit_NFT_Price_Prediction/blob/main/Bitgrit_NFT_Price_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdVH8mhgrqeN",
        "outputId": "e8cb18f7-7c31-4f91-861c-bbbb6ffaf3d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.8/dist-packages (1.1.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from catboost) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from catboost) (1.7.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost) (2022.7)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly->catboost) (8.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "from catboost import Pool, CatBoostRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdI4pf-7NEyT",
        "outputId": "c6f758d6-da4c-45af-d112-b32ccc86f7ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not connected to a GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mObyf0vg6nNH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import GroupShuffleSplit, StratifiedGroupKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
        "\n",
        "\n",
        "import lightgbm as lgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uj-cQWKYuY4W"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.width', 1000)\n",
        "#pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p7Wh4Pk36xj8"
      },
      "outputs": [],
      "source": [
        "dataset_path='/content/drive/MyDrive/Colab Notebooks/BritGritNFTPrices/dataset/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YzRmxeioKZ-a"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed=55):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Yp8sHRq8Kbq4"
      },
      "outputs": [],
      "source": [
        "MY_SEED=55\n",
        "#MAX_SALE=1500\n",
        "MAX_SALE=1\n",
        "seed_everything(MY_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Znf7iSfAxj1j"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "20VErAbG_Z45"
      },
      "outputs": [],
      "source": [
        "df_cols=pd.read_csv(dataset_path+'collections.csv')\n",
        "df_cols_stats=pd.read_csv(dataset_path+'collections_twitter_stats.csv')\n",
        "df_all_train=pd.read_csv(dataset_path+'nfts_train.csv')\n",
        "df_submission=pd.read_csv(dataset_path+'submission_format.csv')\n",
        "df_nfts_predict=pd.read_csv(dataset_path+'nfts_predict.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LUV7xeXJMmb-"
      },
      "outputs": [],
      "source": [
        "df_cols['seller_fees']=df_cols['seller_fees']/10000\n",
        "df_cols['platform_fees']=df_cols['platform_fees']/10000\n",
        "\n",
        "df_all_train['last_sale_price']=df_all_train['last_sale_price'] /MAX_SALE\n",
        "#df_all_train['last_sale_price']=np.log(df_all_train['last_sale_price'])\n",
        "HUBER_DELTA=df_all_train['last_sale_price'].mean()+3*df_all_train['last_sale_price'].std()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FcwmR91yI4dB"
      },
      "outputs": [],
      "source": [
        "df_cols['creation_date']=df_cols['creation_date'].map(lambda x: np.int32(x.replace('-','')))\n",
        "df_cols['verification_status']=df_cols['verification_status'].astype(str)\n",
        "df_cols['contract_type']=df_cols['contract_type'].astype(str)\n",
        "\n",
        "df_all_train['last_sale_date']=df_all_train['last_sale_date'].map(lambda x: np.int32(x.replace('-','')))\n",
        "df_nfts_predict['last_sale_date']=df_nfts_predict['last_sale_date'].map(lambda x: np.int32(x.replace('-','')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztiyQZ__AFuF",
        "outputId": "f39717f1-109b-42c6-89e9-08721a8dad3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48 entries, 0 to 47\n",
            "Data columns (total 14 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   Unnamed: 0           48 non-null     int64  \n",
            " 1   collection_id        48 non-null     int64  \n",
            " 2   total_supply         48 non-null     int64  \n",
            " 3   creation_date        48 non-null     int32  \n",
            " 4   verification_status  48 non-null     object \n",
            " 5   n_of_traits          48 non-null     int64  \n",
            " 6   contract_type        48 non-null     object \n",
            " 7   seller_fees          46 non-null     float64\n",
            " 8   platform_fees        48 non-null     float64\n",
            " 9   openrarity_enabled   48 non-null     bool   \n",
            " 10  has_website          48 non-null     bool   \n",
            " 11  has_own_twitter      48 non-null     bool   \n",
            " 12  has_discord          48 non-null     bool   \n",
            " 13  has_medium           48 non-null     bool   \n",
            "dtypes: bool(5), float64(2), int32(1), int64(4), object(2)\n",
            "memory usage: 3.5+ KB\n"
          ]
        }
      ],
      "source": [
        "df_cols.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "nOMreTDtAMZS",
        "outputId": "ea051031-55b1-4e32-e9d7-821edc27b104"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0  collection_id  total_supply  creation_date  n_of_traits  seller_fees  platform_fees\n",
              "count       48.00      48.000000     48.000000      48.000000    48.000000    46.000000   4.800000e+01\n",
              "mean        23.50      30.333333  10760.979167  202155.729167    12.083333     0.071196   2.500000e-02\n",
              "std         14.00      18.062932   9524.450152      49.038734    11.741603     0.024363   3.506162e-18\n",
              "min          0.00       0.000000      1.000000  202101.000000     0.000000     0.020000   2.500000e-02\n",
              "25%         11.75      14.750000   5541.000000  202108.000000     8.000000     0.050000   2.500000e-02\n",
              "50%         23.50      30.500000   9555.000000  202156.500000     9.500000     0.075000   2.500000e-02\n",
              "75%         35.25      45.250000  10000.000000  202204.000000    14.000000     0.090000   2.500000e-02\n",
              "max         47.00      60.000000  58351.000000  202207.000000    80.000000     0.100000   2.500000e-02"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2b82205-7a85-4fd9-ae2c-e974d3523bd3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>collection_id</th>\n",
              "      <th>total_supply</th>\n",
              "      <th>creation_date</th>\n",
              "      <th>n_of_traits</th>\n",
              "      <th>seller_fees</th>\n",
              "      <th>platform_fees</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>48.00</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>4.800000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>23.50</td>\n",
              "      <td>30.333333</td>\n",
              "      <td>10760.979167</td>\n",
              "      <td>202155.729167</td>\n",
              "      <td>12.083333</td>\n",
              "      <td>0.071196</td>\n",
              "      <td>2.500000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>14.00</td>\n",
              "      <td>18.062932</td>\n",
              "      <td>9524.450152</td>\n",
              "      <td>49.038734</td>\n",
              "      <td>11.741603</td>\n",
              "      <td>0.024363</td>\n",
              "      <td>3.506162e-18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>202101.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>2.500000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.75</td>\n",
              "      <td>14.750000</td>\n",
              "      <td>5541.000000</td>\n",
              "      <td>202108.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>2.500000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>23.50</td>\n",
              "      <td>30.500000</td>\n",
              "      <td>9555.000000</td>\n",
              "      <td>202156.500000</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>0.075000</td>\n",
              "      <td>2.500000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>35.25</td>\n",
              "      <td>45.250000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>202204.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>2.500000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>47.00</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>58351.000000</td>\n",
              "      <td>202207.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>2.500000e-02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2b82205-7a85-4fd9-ae2c-e974d3523bd3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2b82205-7a85-4fd9-ae2c-e974d3523bd3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2b82205-7a85-4fd9-ae2c-e974d3523bd3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df_cols.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGbSTby7AQ8K",
        "outputId": "af9e1fb1-e2cc-4306-a05d-6f1c007b8e11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48 entries, 0 to 47\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Unnamed: 0         48 non-null     int64  \n",
            " 1   collection_id      48 non-null     int64  \n",
            " 2   n_tweets_in_range  48 non-null     int64  \n",
            " 3   avg_likes          48 non-null     float64\n",
            " 4   avg_replies        48 non-null     float64\n",
            " 5   avg_retweets       48 non-null     float64\n",
            " 6   min_likes          48 non-null     int64  \n",
            " 7   min_replies        48 non-null     int64  \n",
            " 8   min_retweets       48 non-null     int64  \n",
            " 9   max_likes          48 non-null     int64  \n",
            " 10  max_replies        48 non-null     int64  \n",
            " 11  max_retweets       48 non-null     int64  \n",
            "dtypes: float64(3), int64(9)\n",
            "memory usage: 4.6 KB\n"
          ]
        }
      ],
      "source": [
        "df_cols_stats.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "wFyY5RUhAxRC",
        "outputId": "1ef4909f-8df2-4316-b1a2-6979483c3cef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0  collection_id  n_tweets_in_range   avg_likes  avg_replies  avg_retweets   min_likes  min_replies  min_retweets    max_likes  max_replies  max_retweets\n",
              "count       48.00      48.000000          48.000000   48.000000    48.000000     48.000000   48.000000    48.000000     48.000000    48.000000    48.000000     48.000000\n",
              "mean        23.50      30.333333          43.250000  106.612882    21.821623     52.061582   20.458333     3.916667      8.291667   331.020833    98.041667    208.895833\n",
              "std         14.00      18.062932         120.698058  188.034103    55.518648     91.257491   54.476604    10.771976     13.639677   786.673646   373.930586    468.414857\n",
              "min          0.00       0.000000           1.000000    0.000000     0.000000      0.000000    0.000000     0.000000      0.000000     0.000000     0.000000      0.000000\n",
              "25%         11.75      14.750000           4.750000    7.423289     0.887821      2.913973    0.000000     0.000000      0.000000    18.750000     6.000000     12.000000\n",
              "50%         23.50      30.500000          11.500000   13.500000     4.114286     11.384211    0.000000     0.000000      1.000000    82.000000    17.500000     52.500000\n",
              "75%         35.25      45.250000          26.000000   90.295455     9.111111     64.418280    3.750000     0.500000      7.500000   300.500000    70.250000    173.250000\n",
              "max         47.00      60.000000         668.000000  707.875000   353.400000    442.000000  236.000000    52.000000     46.000000  5079.000000  2601.000000   2990.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60e54df4-8bb0-4f7e-9b6d-977f543cb317\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>collection_id</th>\n",
              "      <th>n_tweets_in_range</th>\n",
              "      <th>avg_likes</th>\n",
              "      <th>avg_replies</th>\n",
              "      <th>avg_retweets</th>\n",
              "      <th>min_likes</th>\n",
              "      <th>min_replies</th>\n",
              "      <th>min_retweets</th>\n",
              "      <th>max_likes</th>\n",
              "      <th>max_replies</th>\n",
              "      <th>max_retweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>48.00</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>48.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>23.50</td>\n",
              "      <td>30.333333</td>\n",
              "      <td>43.250000</td>\n",
              "      <td>106.612882</td>\n",
              "      <td>21.821623</td>\n",
              "      <td>52.061582</td>\n",
              "      <td>20.458333</td>\n",
              "      <td>3.916667</td>\n",
              "      <td>8.291667</td>\n",
              "      <td>331.020833</td>\n",
              "      <td>98.041667</td>\n",
              "      <td>208.895833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>14.00</td>\n",
              "      <td>18.062932</td>\n",
              "      <td>120.698058</td>\n",
              "      <td>188.034103</td>\n",
              "      <td>55.518648</td>\n",
              "      <td>91.257491</td>\n",
              "      <td>54.476604</td>\n",
              "      <td>10.771976</td>\n",
              "      <td>13.639677</td>\n",
              "      <td>786.673646</td>\n",
              "      <td>373.930586</td>\n",
              "      <td>468.414857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.75</td>\n",
              "      <td>14.750000</td>\n",
              "      <td>4.750000</td>\n",
              "      <td>7.423289</td>\n",
              "      <td>0.887821</td>\n",
              "      <td>2.913973</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18.750000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>12.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>23.50</td>\n",
              "      <td>30.500000</td>\n",
              "      <td>11.500000</td>\n",
              "      <td>13.500000</td>\n",
              "      <td>4.114286</td>\n",
              "      <td>11.384211</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>17.500000</td>\n",
              "      <td>52.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>35.25</td>\n",
              "      <td>45.250000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>90.295455</td>\n",
              "      <td>9.111111</td>\n",
              "      <td>64.418280</td>\n",
              "      <td>3.750000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>300.500000</td>\n",
              "      <td>70.250000</td>\n",
              "      <td>173.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>47.00</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>668.000000</td>\n",
              "      <td>707.875000</td>\n",
              "      <td>353.400000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>236.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>5079.000000</td>\n",
              "      <td>2601.000000</td>\n",
              "      <td>2990.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60e54df4-8bb0-4f7e-9b6d-977f543cb317')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-60e54df4-8bb0-4f7e-9b6d-977f543cb317 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-60e54df4-8bb0-4f7e-9b6d-977f543cb317');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df_cols_stats.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9egIoCoAzpq",
        "outputId": "c503daf6-87ee-4724-fb57-556bf8f07b0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 309910 entries, 0 to 309909\n",
            "Data columns (total 9 columns):\n",
            " #   Column               Non-Null Count   Dtype  \n",
            "---  ------               --------------   -----  \n",
            " 0   global_index         309910 non-null  int64  \n",
            " 1   nft_id               309910 non-null  int64  \n",
            " 2   collection_id        309910 non-null  int64  \n",
            " 3   rarity_score         309910 non-null  float64\n",
            " 4   openrarity_score     80480 non-null   float64\n",
            " 5   openrarity_rank      80480 non-null   float64\n",
            " 6   openrarity_max_rank  80480 non-null   float64\n",
            " 7   last_sale_date       309910 non-null  int32  \n",
            " 8   last_sale_price      309910 non-null  float64\n",
            "dtypes: float64(5), int32(1), int64(3)\n",
            "memory usage: 20.1 MB\n"
          ]
        }
      ],
      "source": [
        "df_all_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5MWyof_A5ZD",
        "outputId": "0ff0e0aa-8475-498d-8a51-f4772d8fac7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 181214 entries, 0 to 181213\n",
            "Data columns (total 8 columns):\n",
            " #   Column               Non-Null Count   Dtype  \n",
            "---  ------               --------------   -----  \n",
            " 0   global_index         181214 non-null  int64  \n",
            " 1   nft_id               181214 non-null  int64  \n",
            " 2   collection_id        181214 non-null  int64  \n",
            " 3   rarity_score         181214 non-null  float64\n",
            " 4   openrarity_score     38626 non-null   float64\n",
            " 5   openrarity_rank      38626 non-null   float64\n",
            " 6   openrarity_max_rank  38626 non-null   float64\n",
            " 7   last_sale_date       181214 non-null  int32  \n",
            "dtypes: float64(4), int32(1), int64(3)\n",
            "memory usage: 10.4 MB\n"
          ]
        }
      ],
      "source": [
        "df_nfts_predict.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMmZqHXjA7tL",
        "outputId": "f3dc9029-e0c3-4b75-a484-cdfb0bd84ab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50 entries, 0 to 49\n",
            "Data columns (total 2 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   global_index     50 non-null     int64  \n",
            " 1   last_sale_price  50 non-null     float64\n",
            "dtypes: float64(1), int64(1)\n",
            "memory usage: 928.0 bytes\n"
          ]
        }
      ],
      "source": [
        "df_submission.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a85ymuGWZyPf",
        "outputId": "09784c3d-c3d9-4b5e-e496-1a14f22345b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "set(df_nfts_predict.collection_id.values).intersection(set(df_all_train.collection_id.values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "tfzK88EdA-Rj",
        "outputId": "f744eeec-c898-406d-aac1-2b9cb46dd872"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       global_index  last_sale_price\n",
              "count      50.00000        50.000000\n",
              "mean       24.50000         0.617073\n",
              "std        14.57738         0.600778\n",
              "min         0.00000         0.022996\n",
              "25%        12.25000         0.205264\n",
              "50%        24.50000         0.338147\n",
              "75%        36.75000         0.920657\n",
              "max        49.00000         2.266743"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f012bfe-5c2e-45b7-a981-0dd2c60fbfe5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>global_index</th>\n",
              "      <th>last_sale_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>50.00000</td>\n",
              "      <td>50.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>24.50000</td>\n",
              "      <td>0.617073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>14.57738</td>\n",
              "      <td>0.600778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.022996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>12.25000</td>\n",
              "      <td>0.205264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>24.50000</td>\n",
              "      <td>0.338147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>36.75000</td>\n",
              "      <td>0.920657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>49.00000</td>\n",
              "      <td>2.266743</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f012bfe-5c2e-45b7-a981-0dd2c60fbfe5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f012bfe-5c2e-45b7-a981-0dd2c60fbfe5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f012bfe-5c2e-45b7-a981-0dd2c60fbfe5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df_submission.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axw9zadhaJ52",
        "outputId": "ca63897d-3afd-4dfa-d97d-c6e14bcf622f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 181214 entries, 0 to 181213\n",
            "Data columns (total 8 columns):\n",
            " #   Column               Non-Null Count   Dtype  \n",
            "---  ------               --------------   -----  \n",
            " 0   global_index         181214 non-null  int64  \n",
            " 1   nft_id               181214 non-null  int64  \n",
            " 2   collection_id        181214 non-null  int64  \n",
            " 3   rarity_score         181214 non-null  float64\n",
            " 4   openrarity_score     38626 non-null   float64\n",
            " 5   openrarity_rank      38626 non-null   float64\n",
            " 6   openrarity_max_rank  38626 non-null   float64\n",
            " 7   last_sale_date       181214 non-null  int32  \n",
            "dtypes: float64(4), int32(1), int64(3)\n",
            "memory usage: 10.4 MB\n"
          ]
        }
      ],
      "source": [
        "df_nfts_predict.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "_1Ya2by_BFeD",
        "outputId": "5aff818d-0411-4421-efef-c71f30f080a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        global_index         nft_id  collection_id   rarity_score  openrarity_score  openrarity_rank  openrarity_max_rank  last_sale_date\n",
              "count  181214.000000  181214.000000  181214.000000  181214.000000      38626.000000     38626.000000         38626.000000   181214.000000\n",
              "mean   309791.155888   11445.662471      28.762866     232.415184          1.000000      4372.867628          8741.760731   202204.358532\n",
              "std    167228.382814   11585.749965      15.321820    1392.046522          0.159457      2857.568048          2300.558399       17.554032\n",
              "min         0.000000       0.000000       2.000000       0.000000          0.601661         1.000000          3332.000000   202102.000000\n",
              "25%    231959.250000    3235.250000      22.000000     129.334538          0.880993      1925.000000          9854.000000   202206.000000\n",
              "50%    287356.500000    7108.500000      35.000000     178.813158          0.982769      3989.000000          9999.000000   202208.000000\n",
              "75%    459554.750000   16220.000000      39.000000     263.697190          1.086070      6767.000000         10000.000000   202209.000000\n",
              "max    618141.000000   48256.000000      53.000000  152922.000000          2.561688     10000.000000         10000.000000   202211.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b1e7121-1624-4a92-9529-5d329c3b9639\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>global_index</th>\n",
              "      <th>nft_id</th>\n",
              "      <th>collection_id</th>\n",
              "      <th>rarity_score</th>\n",
              "      <th>openrarity_score</th>\n",
              "      <th>openrarity_rank</th>\n",
              "      <th>openrarity_max_rank</th>\n",
              "      <th>last_sale_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>181214.000000</td>\n",
              "      <td>181214.000000</td>\n",
              "      <td>181214.000000</td>\n",
              "      <td>181214.000000</td>\n",
              "      <td>38626.000000</td>\n",
              "      <td>38626.000000</td>\n",
              "      <td>38626.000000</td>\n",
              "      <td>181214.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>309791.155888</td>\n",
              "      <td>11445.662471</td>\n",
              "      <td>28.762866</td>\n",
              "      <td>232.415184</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4372.867628</td>\n",
              "      <td>8741.760731</td>\n",
              "      <td>202204.358532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>167228.382814</td>\n",
              "      <td>11585.749965</td>\n",
              "      <td>15.321820</td>\n",
              "      <td>1392.046522</td>\n",
              "      <td>0.159457</td>\n",
              "      <td>2857.568048</td>\n",
              "      <td>2300.558399</td>\n",
              "      <td>17.554032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.601661</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3332.000000</td>\n",
              "      <td>202102.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>231959.250000</td>\n",
              "      <td>3235.250000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>129.334538</td>\n",
              "      <td>0.880993</td>\n",
              "      <td>1925.000000</td>\n",
              "      <td>9854.000000</td>\n",
              "      <td>202206.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>287356.500000</td>\n",
              "      <td>7108.500000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>178.813158</td>\n",
              "      <td>0.982769</td>\n",
              "      <td>3989.000000</td>\n",
              "      <td>9999.000000</td>\n",
              "      <td>202208.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>459554.750000</td>\n",
              "      <td>16220.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>263.697190</td>\n",
              "      <td>1.086070</td>\n",
              "      <td>6767.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>202209.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>618141.000000</td>\n",
              "      <td>48256.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>152922.000000</td>\n",
              "      <td>2.561688</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>202211.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b1e7121-1624-4a92-9529-5d329c3b9639')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b1e7121-1624-4a92-9529-5d329c3b9639 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b1e7121-1624-4a92-9529-5d329c3b9639');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "df_nfts_predict.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "cdJz6biYBG1b",
        "outputId": "d210afbf-cc5b-48db-f634-549f6c68ed33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        global_index         nft_id  collection_id   rarity_score  openrarity_score  openrarity_rank  openrarity_max_rank  last_sale_date  last_sale_price\n",
              "count  309910.000000  309910.000000  309910.000000  309910.000000      80480.000000     80480.000000         80480.000000   309910.000000     3.099100e+05\n",
              "mean   317003.207947    6738.162024      30.507160    1437.092531          1.000000      5630.164737         11255.829672   202192.401129     2.162269e+00\n",
              "std    173138.765569    5977.542096      18.331668    4303.585892          0.152825      3812.126968          3452.713804       34.436556     1.275132e+01\n",
              "min     21928.000000       0.000000       0.000000       1.000000          0.626738         1.000000          5555.000000   202103.000000     6.485360e-08\n",
              "25%    174892.250000    2453.000000      13.000000     106.587184          0.906820      2515.750000          9928.000000   202202.000000     4.077085e-03\n",
              "50%    341467.500000    5138.000000      34.000000     170.797030          0.978289      5030.000000         10000.000000   202207.000000     8.103344e-03\n",
              "75%    493626.750000    8720.750000      46.000000     289.614129          1.059866      8207.250000         15000.000000   202209.000000     3.252062e-01\n",
              "max    590227.000000   29898.000000      60.000000   90354.072248          3.663833     15555.000000         15555.000000   202211.000000     1.024002e+03"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c54d64e-174e-4522-9761-8c91c77bcd5f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>global_index</th>\n",
              "      <th>nft_id</th>\n",
              "      <th>collection_id</th>\n",
              "      <th>rarity_score</th>\n",
              "      <th>openrarity_score</th>\n",
              "      <th>openrarity_rank</th>\n",
              "      <th>openrarity_max_rank</th>\n",
              "      <th>last_sale_date</th>\n",
              "      <th>last_sale_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>309910.000000</td>\n",
              "      <td>309910.000000</td>\n",
              "      <td>309910.000000</td>\n",
              "      <td>309910.000000</td>\n",
              "      <td>80480.000000</td>\n",
              "      <td>80480.000000</td>\n",
              "      <td>80480.000000</td>\n",
              "      <td>309910.000000</td>\n",
              "      <td>3.099100e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>317003.207947</td>\n",
              "      <td>6738.162024</td>\n",
              "      <td>30.507160</td>\n",
              "      <td>1437.092531</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5630.164737</td>\n",
              "      <td>11255.829672</td>\n",
              "      <td>202192.401129</td>\n",
              "      <td>2.162269e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>173138.765569</td>\n",
              "      <td>5977.542096</td>\n",
              "      <td>18.331668</td>\n",
              "      <td>4303.585892</td>\n",
              "      <td>0.152825</td>\n",
              "      <td>3812.126968</td>\n",
              "      <td>3452.713804</td>\n",
              "      <td>34.436556</td>\n",
              "      <td>1.275132e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>21928.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.626738</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5555.000000</td>\n",
              "      <td>202103.000000</td>\n",
              "      <td>6.485360e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>174892.250000</td>\n",
              "      <td>2453.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>106.587184</td>\n",
              "      <td>0.906820</td>\n",
              "      <td>2515.750000</td>\n",
              "      <td>9928.000000</td>\n",
              "      <td>202202.000000</td>\n",
              "      <td>4.077085e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>341467.500000</td>\n",
              "      <td>5138.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>170.797030</td>\n",
              "      <td>0.978289</td>\n",
              "      <td>5030.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>202207.000000</td>\n",
              "      <td>8.103344e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>493626.750000</td>\n",
              "      <td>8720.750000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>289.614129</td>\n",
              "      <td>1.059866</td>\n",
              "      <td>8207.250000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>202209.000000</td>\n",
              "      <td>3.252062e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>590227.000000</td>\n",
              "      <td>29898.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>90354.072248</td>\n",
              "      <td>3.663833</td>\n",
              "      <td>15555.000000</td>\n",
              "      <td>15555.000000</td>\n",
              "      <td>202211.000000</td>\n",
              "      <td>1.024002e+03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c54d64e-174e-4522-9761-8c91c77bcd5f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c54d64e-174e-4522-9761-8c91c77bcd5f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c54d64e-174e-4522-9761-8c91c77bcd5f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "df_all_train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "KnwOH8TtarnY",
        "outputId": "8cca8c14-f97e-496a-e42d-7a0cd0cbee7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f93e9847730>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "df_all_train.groupby('collection_id')['collection_id'].count().plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "HKy5IcuT0Y0b"
      },
      "outputs": [],
      "source": [
        "def plot_corr(df, describe, figsize=(4,4)):\n",
        "  plt.figure(figsize =figsize)\n",
        "  corr = df.corr()\n",
        "  mask = np.triu(np.ones_like(corr, dtype = bool))\n",
        "  sns.heatmap(corr, mask = mask, robust = True, center = 0,square = True, linewidths =.6)\n",
        "  title=f'Correlation of {describe} Variables'\n",
        "  plt.title(title)\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "FOli5b-i068Z",
        "outputId": "a949b568-bd06-49b1-8091-6036dcbc598a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_corr(df_all_train,'Train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "BehKn_PsM-1w",
        "outputId": "74dbd18b-e2b1-42cf-8d1f-c984e0dfd4ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f93e9292eb0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "df_all_train.last_sale_price.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "o0w4A60N7qFT",
        "outputId": "fdf06c1a-8010-4fa7-8c44-edf9a2534ea0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f93e9215df0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "df_cols.seller_fees.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "QyeA9ax1lA_d",
        "outputId": "2dd402c8-b19f-44c3-b5e2-56a3b36fa1ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        global_index        nft_id  collection_id  rarity_score  openrarity_score  openrarity_rank  openrarity_max_rank  last_sale_date  last_sale_price\n",
              "count   41453.000000  41453.000000   41453.000000  41453.000000      14443.000000      14443.00000         14443.000000    41453.000000     4.145300e+04\n",
              "mean   293070.699009   4142.983403      33.289919    140.056423          1.000000       3801.52586          7582.076923   202199.045521     8.104070e-01\n",
              "std    170076.589033   2650.743844      18.684191    233.573074          0.132693       2384.36402          1602.600498       26.797274     6.423811e+00\n",
              "min     21928.000000      0.000000       0.000000      1.000000          0.770374          1.00000          5555.000000   202104.000000     1.261076e-07\n",
              "25%    175071.000000   1872.000000      26.000000     52.442926          0.931205       1804.50000          5555.000000   202205.000000     4.547653e-03\n",
              "50%    215432.000000   3945.000000      37.000000    108.716551          0.990835       3611.00000          8849.000000   202207.000000     9.035782e-03\n",
              "75%    322712.000000   6133.000000      38.000000    161.446023          1.050099       5416.50000          8849.000000   202209.000000     3.508993e-01\n",
              "max    562664.000000   9999.000000      59.000000   9793.201352          3.663833       8849.00000          8849.000000   202211.000000     4.134943e+02"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46c5ef86-ccc6-47b0-9ce2-8aeea01d0cdd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>global_index</th>\n",
              "      <th>nft_id</th>\n",
              "      <th>collection_id</th>\n",
              "      <th>rarity_score</th>\n",
              "      <th>openrarity_score</th>\n",
              "      <th>openrarity_rank</th>\n",
              "      <th>openrarity_max_rank</th>\n",
              "      <th>last_sale_date</th>\n",
              "      <th>last_sale_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>41453.000000</td>\n",
              "      <td>41453.000000</td>\n",
              "      <td>41453.000000</td>\n",
              "      <td>41453.000000</td>\n",
              "      <td>14443.000000</td>\n",
              "      <td>14443.00000</td>\n",
              "      <td>14443.000000</td>\n",
              "      <td>41453.000000</td>\n",
              "      <td>4.145300e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>293070.699009</td>\n",
              "      <td>4142.983403</td>\n",
              "      <td>33.289919</td>\n",
              "      <td>140.056423</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3801.52586</td>\n",
              "      <td>7582.076923</td>\n",
              "      <td>202199.045521</td>\n",
              "      <td>8.104070e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>170076.589033</td>\n",
              "      <td>2650.743844</td>\n",
              "      <td>18.684191</td>\n",
              "      <td>233.573074</td>\n",
              "      <td>0.132693</td>\n",
              "      <td>2384.36402</td>\n",
              "      <td>1602.600498</td>\n",
              "      <td>26.797274</td>\n",
              "      <td>6.423811e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>21928.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.770374</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>5555.000000</td>\n",
              "      <td>202104.000000</td>\n",
              "      <td>1.261076e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>175071.000000</td>\n",
              "      <td>1872.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>52.442926</td>\n",
              "      <td>0.931205</td>\n",
              "      <td>1804.50000</td>\n",
              "      <td>5555.000000</td>\n",
              "      <td>202205.000000</td>\n",
              "      <td>4.547653e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>215432.000000</td>\n",
              "      <td>3945.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>108.716551</td>\n",
              "      <td>0.990835</td>\n",
              "      <td>3611.00000</td>\n",
              "      <td>8849.000000</td>\n",
              "      <td>202207.000000</td>\n",
              "      <td>9.035782e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>322712.000000</td>\n",
              "      <td>6133.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>161.446023</td>\n",
              "      <td>1.050099</td>\n",
              "      <td>5416.50000</td>\n",
              "      <td>8849.000000</td>\n",
              "      <td>202209.000000</td>\n",
              "      <td>3.508993e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>562664.000000</td>\n",
              "      <td>9999.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>9793.201352</td>\n",
              "      <td>3.663833</td>\n",
              "      <td>8849.00000</td>\n",
              "      <td>8849.000000</td>\n",
              "      <td>202211.000000</td>\n",
              "      <td>4.134943e+02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46c5ef86-ccc6-47b0-9ce2-8aeea01d0cdd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46c5ef86-ccc6-47b0-9ce2-8aeea01d0cdd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46c5ef86-ccc6-47b0-9ce2-8aeea01d0cdd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "df_all_train[df_all_train.collection_id.isin([49,0,38,37,59,19,26])].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Zd8-JTOfaHzy",
        "outputId": "0a90cc78-eae1-4045-84f7-08823de35fd2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        global_index         nft_id  collection_id   rarity_score  openrarity_score  openrarity_rank  openrarity_max_rank  last_sale_date  last_sale_price\n",
              "count  268457.000000  268457.000000  268457.000000  268457.000000      66037.000000     66037.000000         66037.000000   268457.000000     2.684570e+05\n",
              "mean   320698.676097    7138.888917      30.077469    1637.370556          1.000000      6030.107667         12059.318791   202191.375155     2.371013e+00\n",
              "std    173312.800242    6242.022048      18.238862    4590.468484          0.156885      3946.652814          3220.157346       35.358747     1.345383e+01\n",
              "min     32621.000000       0.000000       1.000000       6.086957          0.626738         1.000000          5555.000000   202103.000000     6.485360e-08\n",
              "25%    126682.000000    2567.000000      13.000000     115.935029          0.904555      2752.000000          9999.000000   202202.000000     4.013937e-03\n",
              "50%    360470.000000    5436.000000      34.000000     179.105017          0.973403      5504.000000         10000.000000   202206.000000     7.975547e-03\n",
              "75%    493990.000000    9269.000000      46.000000     319.059293          1.062781      8795.000000         15000.000000   202209.000000     3.131162e-01\n",
              "max    590227.000000   29898.000000      60.000000   90354.072248          3.162588     15555.000000         15555.000000   202211.000000     1.024002e+03"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c240a80-2c03-46db-9aa2-9eab611ced11\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>global_index</th>\n",
              "      <th>nft_id</th>\n",
              "      <th>collection_id</th>\n",
              "      <th>rarity_score</th>\n",
              "      <th>openrarity_score</th>\n",
              "      <th>openrarity_rank</th>\n",
              "      <th>openrarity_max_rank</th>\n",
              "      <th>last_sale_date</th>\n",
              "      <th>last_sale_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>268457.000000</td>\n",
              "      <td>268457.000000</td>\n",
              "      <td>268457.000000</td>\n",
              "      <td>268457.000000</td>\n",
              "      <td>66037.000000</td>\n",
              "      <td>66037.000000</td>\n",
              "      <td>66037.000000</td>\n",
              "      <td>268457.000000</td>\n",
              "      <td>2.684570e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>320698.676097</td>\n",
              "      <td>7138.888917</td>\n",
              "      <td>30.077469</td>\n",
              "      <td>1637.370556</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6030.107667</td>\n",
              "      <td>12059.318791</td>\n",
              "      <td>202191.375155</td>\n",
              "      <td>2.371013e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>173312.800242</td>\n",
              "      <td>6242.022048</td>\n",
              "      <td>18.238862</td>\n",
              "      <td>4590.468484</td>\n",
              "      <td>0.156885</td>\n",
              "      <td>3946.652814</td>\n",
              "      <td>3220.157346</td>\n",
              "      <td>35.358747</td>\n",
              "      <td>1.345383e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>32621.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.086957</td>\n",
              "      <td>0.626738</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5555.000000</td>\n",
              "      <td>202103.000000</td>\n",
              "      <td>6.485360e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>126682.000000</td>\n",
              "      <td>2567.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>115.935029</td>\n",
              "      <td>0.904555</td>\n",
              "      <td>2752.000000</td>\n",
              "      <td>9999.000000</td>\n",
              "      <td>202202.000000</td>\n",
              "      <td>4.013937e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>360470.000000</td>\n",
              "      <td>5436.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>179.105017</td>\n",
              "      <td>0.973403</td>\n",
              "      <td>5504.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>202206.000000</td>\n",
              "      <td>7.975547e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>493990.000000</td>\n",
              "      <td>9269.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>319.059293</td>\n",
              "      <td>1.062781</td>\n",
              "      <td>8795.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>202209.000000</td>\n",
              "      <td>3.131162e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>590227.000000</td>\n",
              "      <td>29898.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>90354.072248</td>\n",
              "      <td>3.162588</td>\n",
              "      <td>15555.000000</td>\n",
              "      <td>15555.000000</td>\n",
              "      <td>202211.000000</td>\n",
              "      <td>1.024002e+03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c240a80-2c03-46db-9aa2-9eab611ced11')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9c240a80-2c03-46db-9aa2-9eab611ced11 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9c240a80-2c03-46db-9aa2-9eab611ced11');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "df_all_train[~df_all_train.collection_id.isin([49,0,38,37,59,19,26])].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmL5-zK5EbEJ"
      },
      "source": [
        "# Create CV test for training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "FIW1SgugEiMS"
      },
      "outputs": [],
      "source": [
        "gs = GroupShuffleSplit(n_splits=1, test_size=0.1, random_state=MY_SEED)\n",
        "train_ix, valid_ix = next(gs.split(df_all_train, groups=df_all_train.collection_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "KV8dUM1PE83o"
      },
      "outputs": [],
      "source": [
        "df_train_raw=df_all_train.loc[train_ix,]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "iI1yHXNUFFsR"
      },
      "outputs": [],
      "source": [
        "df_valid_raw=df_all_train.loc[valid_ix,]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee6UhyoXK3mC"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "rd4JnpAlhpVW"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import TransformerMixin, BaseEstimator\n",
        "\n",
        "class CategoricalTransformer(TransformerMixin, BaseEstimator):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.labelEncoder_vs=LabelEncoder() # verification_status_encoded\n",
        "        self.labelEncoder_ct=LabelEncoder() # contract_type\n",
        "\n",
        "    def fit(self, df, y=None):            \n",
        "        self.labelEncoder_vs.fit(df['verification_status'])\n",
        "        self.labelEncoder_ct.fit(df['contract_type'])\n",
        "        return self    \n",
        "\n",
        "    def transform(self, df, y=None):\n",
        "        self.feature_names=[]    \n",
        "        self.feature_names.extend(df.columns.values)     \n",
        "        \n",
        "        print(f'starting categorical feature with input shape: {df.shape}')\n",
        "        df['verification_status']=self.labelEncoder_vs.transform(df.verification_status).astype(\"int\")\n",
        "        df['contract_type']=self.labelEncoder_ct.transform(df.contract_type).astype(\"int\")\n",
        "        df['openrarity_enabled']=df['openrarity_enabled'].astype(\"int\")\n",
        "        df['has_website']=df['has_website'].astype(\"int\")\n",
        "        df['has_own_twitter']=df['has_own_twitter'].astype(\"int\")\n",
        "        df['has_discord']=df['has_discord'].astype(\"int\")\n",
        "        df['has_medium']=df['has_medium'].astype(\"int\")\n",
        "\n",
        "        return df[self.feature_names]\n",
        "    \n",
        "    def get_feature_names(self):\n",
        "        return self.feature_names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "yLOSSdV_Iztf"
      },
      "outputs": [],
      "source": [
        "class FeatureTransformers(TransformerMixin, BaseEstimator):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "    def fit(self, df, y=None):    \n",
        "        self.avg_avg_likes=df['avg_likes'].mean()                \n",
        "        self.avg_avg_replies=df['avg_replies'].mean()                \n",
        "        self.avg_avg_retweets=df['avg_retweets'].mean()                \n",
        "        self.avg_fee=(df['seller_fees']+df['platform_fees']).mean()\n",
        "        return self    \n",
        "\n",
        "    def transform(self, df, y=None):\n",
        "        self.feature_names=['shelf_duration','openrarity_ratio','last_sale_date_year','last_sale_date_month',\n",
        "                            'inverse_total_supply','ratio_avg_likes','ratio_avg_replies','ratio_avg_retweets',\n",
        "                            'total_avg_likes','total_avg_twitter_activity', 'total_fee','ratio_avg_fee']            \n",
        "        self.feature_names.extend(df.columns.values)     \n",
        "        \n",
        "        print(f'starting feature with input shape: {df.shape}')\n",
        "        df['last_sale_date_year']=df['last_sale_date']//100\n",
        "        df['last_sale_date_month']=df['last_sale_date']%100\n",
        "        df['shelf_duration']=df['last_sale_date']-df['creation_date']\n",
        "        df['openrarity_ratio']=df['openrarity_rank']/df['openrarity_max_rank']      \n",
        "        df['inverse_total_supply']=1/df['total_supply']\n",
        "        df['ratio_avg_likes']=df['avg_likes']/self.avg_avg_likes\n",
        "        df['ratio_avg_replies']=df['avg_replies']/self.avg_avg_replies\n",
        "        df['ratio_avg_retweets']=df['avg_retweets']/self.avg_avg_retweets\n",
        "        df['total_avg_likes']=df['avg_retweets']*df['n_tweets_in_range']\n",
        "        df['total_avg_twitter_activity']=df['avg_likes']+df['avg_retweets']+df['avg_replies']\n",
        "        df['total_fee']=df['seller_fees']+df['platform_fees']\n",
        "        df['ratio_avg_fee']=df['total_fee']/self.avg_fee\n",
        "\n",
        "        return df[self.feature_names]\n",
        "    \n",
        "    def get_feature_names(self):\n",
        "        return self.feature_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "bl1eSs7sEq9K"
      },
      "outputs": [],
      "source": [
        "class AvgPriceTransformer(TransformerMixin, BaseEstimator):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "    def fit(self, df, y=None):   \n",
        "\n",
        "\n",
        "        self.last_sale_year_avg_price=df.groupby('last_sale_date_year')['last_sale_price'].mean().rename('last_sale_price_year_avg')\n",
        "        self.last_sale_year_std_price=df.groupby('last_sale_date_year')['last_sale_price'].std().rename('last_sale_price_year_std')\n",
        "        self.last_sale_year_min_price=df.groupby('last_sale_date_year')['last_sale_price'].min().rename('last_sale_price_year_min')\n",
        "        self.last_sale_year_max_price=df.groupby('last_sale_date_year')['last_sale_price'].max().rename('last_sale_price_year_max')\n",
        "\n",
        "        self.last_sale_month_avg_price=df.groupby('last_sale_date_month')['last_sale_price'].mean().rename('last_sale_price_month_avg')\n",
        "        self.last_sale_month_std_price=df.groupby('last_sale_date_month')['last_sale_price'].std().rename('last_sale_price_month_std')\n",
        "\n",
        "        self.shelf_life_avg_price=df.groupby('shelf_duration')['last_sale_price'].mean().rename('last_sale_price_shelf_life_avg')\n",
        "        self.shelf_life_std_price=df.groupby('shelf_duration')['last_sale_price'].std().rename('last_sale_price_shelf_life_std')\n",
        "        self.shelf_life_min_price=df.groupby('shelf_duration')['last_sale_price'].min().rename('last_sale_price_shelf_life_min')\n",
        "        self.shelf_life_max_price=df.groupby('shelf_duration')['last_sale_price'].max().rename('last_sale_price_shelf_life_max')\n",
        "\n",
        "        self.last_sale_year_month_avg_price=df.groupby('last_sale_date')['last_sale_price'].mean().rename('last_sale_price_avg')\n",
        "        self.last_sale_year_month_std_price=df.groupby('last_sale_date')['last_sale_price'].std().rename('last_sale_price_std')\n",
        "        self.last_sale_year_month_min_price=df.groupby('last_sale_date')['last_sale_price'].min().rename('last_sale_price_min')\n",
        "        self.last_sale_year_month_max_price=df.groupby('last_sale_date')['last_sale_price'].max().rename('last_sale_price_max')\n",
        "\n",
        "        return self    \n",
        "\n",
        "    def transform(self, df, y=None):\n",
        "        self.feature_names=['last_sale_price_shelf_life_avg','last_sale_price_shelf_life_std','last_sale_price_shelf_life_min','last_sale_price_shelf_life_max',\n",
        "                            'last_sale_price_year_avg', 'last_sale_price_year_std','last_sale_price_year_min','last_sale_price_year_max',\n",
        "                            'last_sale_price_month_avg','last_sale_price_month_std', 'last_sale_price_avg', 'last_sale_price_std', 'last_sale_price_min','last_sale_price_max']            \n",
        "\n",
        "        self.feature_names.extend(df.columns.values)     \n",
        "\n",
        "        print(f'starting avg price feature with input shape: {df.shape}')\n",
        "        \n",
        "        df=df.merge(self.last_sale_year_month_avg_price,on='last_sale_date', how='left')\n",
        "        df=df.merge(self.last_sale_year_month_std_price,on='last_sale_date', how='left')\n",
        "        df=df.merge(self.last_sale_year_month_min_price,on='last_sale_date', how='left')\n",
        "        df=df.merge(self.last_sale_year_month_max_price,on='last_sale_date', how='left')\n",
        "        \n",
        "        df=df.merge(self.last_sale_year_avg_price,on='last_sale_date_year', how='left')\n",
        "        df=df.merge(self.last_sale_year_std_price,on='last_sale_date_year', how='left')\n",
        "        df=df.merge(self.last_sale_year_min_price,on='last_sale_date_year', how='left')\n",
        "        df=df.merge(self.last_sale_year_max_price,on='last_sale_date_year', how='left')\n",
        "\n",
        "        df=df.merge(self.last_sale_month_avg_price,on='last_sale_date_month', how='left')\n",
        "        df=df.merge(self.last_sale_month_std_price,on='last_sale_date_month', how='left')\n",
        "\n",
        "        df=df.merge(self.shelf_life_avg_price,on='shelf_duration', how='left')\n",
        "        df=df.merge(self.shelf_life_std_price,on='shelf_duration', how='left')\n",
        "        df=df.merge(self.shelf_life_min_price,on='shelf_duration', how='left')\n",
        "        df=df.merge(self.shelf_life_max_price,on='shelf_duration', how='left')\n",
        "      \n",
        "        return df[self.feature_names]\n",
        "    \n",
        "    def get_feature_names(self):\n",
        "        return self.feature_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "efnmGl5kywcz"
      },
      "outputs": [],
      "source": [
        "class FillNAImputer(TransformerMixin, BaseEstimator):        \n",
        "        \n",
        "    def fit(self, x, y=None):    \n",
        "        return self   \n",
        "\n",
        "    def transform(self, df, y=None):\n",
        "        self.feature_names=[]    \n",
        "        self.feature_names.extend(df.columns.values)     \n",
        "                                    \n",
        "        print(f'starting fill na imputer with input shape:  {df.shape}')                        \n",
        "        # first fill zero values with NA \n",
        "        df.fillna(0,inplace=True)\n",
        "        return  df[self.feature_names]\n",
        "    \n",
        "    def get_feature_names(self):\n",
        "        return self.feature_names    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "CmnKhEyNsbTD"
      },
      "outputs": [],
      "source": [
        "def createPreprocessing():\n",
        "    preprocessing=make_pipeline(CategoricalTransformer(),                             \n",
        "                                FeatureTransformers(),\n",
        "                                AvgPriceTransformer(),\n",
        "                                FillNAImputer(),\n",
        "                                verbose=True)\n",
        "    return preprocessing\n",
        "preprocessing=createPreprocessing()\n",
        "preprocessing_all=createPreprocessing()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Np0gditxMZUK"
      },
      "outputs": [],
      "source": [
        "num_features=['total_avg_twitter_activity','total_avg_likes','ratio_avg_likes','ratio_avg_replies','ratio_avg_retweets','inverse_total_supply', 'rarity_score', 'openrarity_score', 'openrarity_rank', 'openrarity_max_rank', 'total_supply','n_of_traits', \n",
        "              'n_tweets_in_range', 'avg_likes', 'avg_replies', 'avg_retweets', 'min_likes', 'min_replies', 'min_retweets', 'max_likes', 'max_replies','max_retweets',\n",
        "              'shelf_duration','openrarity_ratio','last_sale_date_year','last_sale_date_month',\n",
        "              'last_sale_price_shelf_life_avg','last_sale_price_shelf_life_std','last_sale_price_shelf_life_min','last_sale_price_shelf_life_max',\n",
        "              'last_sale_price_year_avg', 'last_sale_price_year_std','last_sale_price_year_min','last_sale_price_year_max',\n",
        "              'last_sale_price_avg', 'last_sale_price_std', 'last_sale_price_min','last_sale_price_max']\n",
        "\n",
        "\n",
        "num_features=['total_avg_likes',  'n_of_traits', 'total_supply',\n",
        "       'shelf_duration', 'avg_likes', 'max_replies', 'avg_replies', 'ratio_avg_likes',\n",
        "       'max_likes', 'total_avg_twitter_activity', 'last_sale_price_std',\n",
        "       'max_retweets', 'last_sale_date_month', 'ratio_avg_replies',\n",
        "       'rarity_score', 'ratio_avg_retweets', 'avg_retweets',\n",
        "       'last_sale_price_avg', 'last_sale_price_month_avg','last_sale_price_month_std',\n",
        "       'last_sale_price_shelf_life_max', 'last_sale_price_max',\n",
        "       'n_tweets_in_range', 'last_sale_price_min', 'min_retweets',\n",
        "       'last_sale_price_shelf_life_avg']\n",
        "\n",
        "cat_features=['contract_type','creation_date', 'last_sale_date'] #['verification_status','contract_type','openrarity_enabled', 'has_website','has_own_twitter', 'has_discord', 'has_medium','creation_date','last_sale_date']\n",
        "target_feature='last_sale_price'\n",
        "#target_feature='total_sale_price'\n",
        "all_column_names= num_features + cat_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "4rg4gGJ_GD8R",
        "outputId": "0b172c15-8714-404d-e327-f5f7c992bc54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting categorical feature with input shape: (270911, 33)\n",
            "[Pipeline]  (step 1 of 4) Processing categoricaltransformer, total=   0.2s\n",
            "starting feature with input shape: (270911, 33)\n",
            "[Pipeline]  (step 2 of 4) Processing featuretransformers, total=   0.1s\n",
            "starting avg price feature with input shape: (270911, 45)\n",
            "[Pipeline]  (step 3 of 4) Processing avgpricetransformer, total=   1.3s\n",
            "starting fill na imputer with input shape:  (270911, 59)\n",
            "[Pipeline] ..... (step 4 of 4) Processing fillnaimputer, total=   0.0s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        last_sale_price_shelf_life_avg  last_sale_price_shelf_life_std  last_sale_price_shelf_life_min  last_sale_price_shelf_life_max  last_sale_price_year_avg  last_sale_price_year_std  last_sale_price_year_min  last_sale_price_year_max  last_sale_price_month_avg  last_sale_price_month_std  last_sale_price_avg  last_sale_price_std  last_sale_price_min  last_sale_price_max  shelf_duration  openrarity_ratio  last_sale_date_year  last_sale_date_month  inverse_total_supply  ratio_avg_likes  ratio_avg_replies  ratio_avg_retweets  total_avg_likes  total_avg_twitter_activity  total_fee  ratio_avg_fee  global_index  nft_id  collection_id  rarity_score  openrarity_score  openrarity_rank  openrarity_max_rank  last_sale_date  total_supply  creation_date  verification_status  n_of_traits  contract_type  seller_fees  platform_fees  openrarity_enabled  has_website  has_own_twitter  has_discord  has_medium  Unnamed: 0_y  n_tweets_in_range   avg_likes  avg_replies  avg_retweets  min_likes  \\\n",
              "0                             0.300481                        3.079332                    1.261076e-07                      105.003970                  0.960079                  4.223822              6.485360e-08                400.001379                   0.417171                   2.324424             0.332075             1.414726         6.485360e-08            43.006384               7               0.0                 2022                    11              1.000000         2.267772           0.396421            1.524617           1889.0                  257.193548      0.125       1.339528         21928       0             49      2.000000               0.0              0.0                  0.0          202211             1         202204                    1            2              1         0.10          0.025                   0            0                1            1           0            39                 31  187.967742     8.290323     60.935484          0   \n",
              "1                             1.142344                        4.211920                    2.962572e-06                      130.005079                  1.216877                  6.358433              3.525795e-07                413.494300                   0.752649                   3.446782             2.491572             5.319862         2.164313e-06           130.005079               1               0.0                 2021                     8              0.000113         1.606797           0.643361            1.380659            607.0                  201.818182      0.075       0.803717         32621       0             45     97.077216               0.0              0.0                  0.0          202108          8888         202107                    1            5              1         0.05          0.025                   0            0                1            1           0            35                 11  133.181818    13.454545     55.181818          0   \n",
              "2                             0.630831                        4.731466                    1.489020e-06                      400.001379                  0.960079                  4.223822              6.485360e-08                400.001379                   0.752649                   3.446782             0.428641             2.855335         1.261076e-07           400.001379             101               0.0                 2022                     8              0.000113         1.606797           0.643361            1.380659            607.0                  201.818182      0.075       0.803717         32622       1             45    139.453086               0.0              0.0                  0.0          202208          8888         202107                    1            5              1         0.05          0.025                   0            0                1            1           0            35                 11  133.181818    13.454545     55.181818          0   \n",
              "3                             1.142344                        4.211920                    2.962572e-06                      130.005079                  1.216877                  6.358433              3.525795e-07                413.494300                   0.752649                   3.446782             2.491572             5.319862         2.164313e-06           130.005079               1               0.0                 2021                     8              0.000113         1.606797           0.643361            1.380659            607.0                  201.818182      0.075       0.803717         32623       2             45    127.753445               0.0              0.0                  0.0          202108          8888         202107                    1            5              1         0.05          0.025                   0            0                1            1           0            35                 11  133.181818    13.454545     55.181818          0   \n",
              "4                             0.223820                        1.284130                    6.485360e-08                       33.007089                  0.960079                  4.223822              6.485360e-08                400.001379                   0.416788                   2.914958             0.256652             1.322104         2.838022e-07            25.502344             102               0.0                 2022                     9              0.000113         1.606797           0.643361            1.380659            607.0                  201.818182      0.075       0.803717         32624       3             45    112.315719               0.0              0.0                  0.0          202209          8888         202107                    1            5              1         0.05          0.025                   0            0                1            1           0            35                 11  133.181818    13.454545     55.181818          0   \n",
              "...                                ...                             ...                             ...                             ...                       ...                       ...                       ...                       ...                        ...                        ...                  ...                  ...                  ...                  ...             ...               ...                  ...                   ...                   ...              ...                ...                 ...              ...                         ...        ...            ...           ...     ...            ...           ...               ...              ...                  ...             ...           ...            ...                  ...          ...            ...          ...            ...                 ...          ...              ...          ...         ...           ...                ...         ...          ...           ...        ...   \n",
              "270906                        0.300481                        3.079332                    1.261076e-07                      105.003970                  0.960079                  4.223822              6.485360e-08                400.001379                   0.752649                   3.446782             0.428641             2.855335         1.261076e-07           400.001379               7               0.0                 2022                     8              0.000100         0.097422           0.164970            0.081316            130.0                   14.775000      0.115       1.232366        562660    9995             26    401.063769               0.0              0.0                  0.0          202208         10000         202201                    0            9              0         0.09          0.025                   0            0                1            0           0            19                 40    8.075000     3.450000      3.250000          0   \n",
              "270907                        0.300481                        3.079332                    1.261076e-07                      105.003970                  0.960079                  4.223822              6.485360e-08                400.001379                   0.752649                   3.446782             0.428641             2.855335         1.261076e-07           400.001379               7               0.0                 2022                     8              0.000100         0.097422           0.164970            0.081316            130.0                   14.775000      0.115       1.232366        562661    9996             26    148.726179               0.0              0.0                  0.0          202208         10000         202201                    0            9              0         0.09          0.025                   0            0                1            0           0            19                 40    8.075000     3.450000      3.250000          0   \n",
              "270908                        0.300481                        3.079332                    1.261076e-07                      105.003970                  0.960079                  4.223822              6.485360e-08                400.001379                   0.752649                   3.446782             0.428641             2.855335         1.261076e-07           400.001379               7               0.0                 2022                     8              0.000100         0.097422           0.164970            0.081316            130.0                   14.775000      0.115       1.232366        562662    9997             26    196.309829               0.0              0.0                  0.0          202208         10000         202201                    0            9              0         0.09          0.025                   0            0                1            0           0            19                 40    8.075000     3.450000      3.250000          0   \n",
              "270909                        0.300481                        3.079332                    1.261076e-07                      105.003970                  0.960079                  4.223822              6.485360e-08                400.001379                   0.752649                   3.446782             0.428641             2.855335         1.261076e-07           400.001379               7               0.0                 2022                     8              0.000100         0.097422           0.164970            0.081316            130.0                   14.775000      0.115       1.232366        562663    9998             26    117.435698               0.0              0.0                  0.0          202208         10000         202201                    0            9              0         0.09          0.025                   0            0                1            0           0            19                 40    8.075000     3.450000      3.250000          0   \n",
              "270910                        0.300481                        3.079332                    1.261076e-07                      105.003970                  0.960079                  4.223822              6.485360e-08                400.001379                   0.752649                   3.446782             0.428641             2.855335         1.261076e-07           400.001379               7               0.0                 2022                     8              0.000100         0.097422           0.164970            0.081316            130.0                   14.775000      0.115       1.232366        562664    9999             26     99.717011               0.0              0.0                  0.0          202208         10000         202201                    0            9              0         0.09          0.025                   0            0                1            0           0            19                 40    8.075000     3.450000      3.250000          0   \n",
              "\n",
              "        min_replies  min_retweets  max_likes  max_replies  max_retweets  \n",
              "0                 0             2        591           28           380  \n",
              "1                 0             7        402           47           239  \n",
              "2                 0             7        402           47           239  \n",
              "3                 0             7        402           47           239  \n",
              "4                 0             7        402           47           239  \n",
              "...             ...           ...        ...          ...           ...  \n",
              "270906            0             0         91           96            88  \n",
              "270907            0             0         91           96            88  \n",
              "270908            0             0         91           96            88  \n",
              "270909            0             0         91           96            88  \n",
              "270910            0             0         91           96            88  \n",
              "\n",
              "[270911 rows x 57 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d1800fb-adba-4e85-94b3-4793e073d0d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>last_sale_price_shelf_life_avg</th>\n",
              "      <th>last_sale_price_shelf_life_std</th>\n",
              "      <th>last_sale_price_shelf_life_min</th>\n",
              "      <th>last_sale_price_shelf_life_max</th>\n",
              "      <th>last_sale_price_year_avg</th>\n",
              "      <th>last_sale_price_year_std</th>\n",
              "      <th>last_sale_price_year_min</th>\n",
              "      <th>last_sale_price_year_max</th>\n",
              "      <th>last_sale_price_month_avg</th>\n",
              "      <th>last_sale_price_month_std</th>\n",
              "      <th>last_sale_price_avg</th>\n",
              "      <th>last_sale_price_std</th>\n",
              "      <th>last_sale_price_min</th>\n",
              "      <th>last_sale_price_max</th>\n",
              "      <th>shelf_duration</th>\n",
              "      <th>openrarity_ratio</th>\n",
              "      <th>last_sale_date_year</th>\n",
              "      <th>last_sale_date_month</th>\n",
              "      <th>inverse_total_supply</th>\n",
              "      <th>ratio_avg_likes</th>\n",
              "      <th>ratio_avg_replies</th>\n",
              "      <th>ratio_avg_retweets</th>\n",
              "      <th>total_avg_likes</th>\n",
              "      <th>total_avg_twitter_activity</th>\n",
              "      <th>total_fee</th>\n",
              "      <th>ratio_avg_fee</th>\n",
              "      <th>global_index</th>\n",
              "      <th>nft_id</th>\n",
              "      <th>collection_id</th>\n",
              "      <th>rarity_score</th>\n",
              "      <th>openrarity_score</th>\n",
              "      <th>openrarity_rank</th>\n",
              "      <th>openrarity_max_rank</th>\n",
              "      <th>last_sale_date</th>\n",
              "      <th>total_supply</th>\n",
              "      <th>creation_date</th>\n",
              "      <th>verification_status</th>\n",
              "      <th>n_of_traits</th>\n",
              "      <th>contract_type</th>\n",
              "      <th>seller_fees</th>\n",
              "      <th>platform_fees</th>\n",
              "      <th>openrarity_enabled</th>\n",
              "      <th>has_website</th>\n",
              "      <th>has_own_twitter</th>\n",
              "      <th>has_discord</th>\n",
              "      <th>has_medium</th>\n",
              "      <th>Unnamed: 0_y</th>\n",
              "      <th>n_tweets_in_range</th>\n",
              "      <th>avg_likes</th>\n",
              "      <th>avg_replies</th>\n",
              "      <th>avg_retweets</th>\n",
              "      <th>min_likes</th>\n",
              "      <th>min_replies</th>\n",
              "      <th>min_retweets</th>\n",
              "      <th>max_likes</th>\n",
              "      <th>max_replies</th>\n",
              "      <th>max_retweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.300481</td>\n",
              "      <td>3.079332</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>105.003970</td>\n",
              "      <td>0.960079</td>\n",
              "      <td>4.223822</td>\n",
              "      <td>6.485360e-08</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>0.417171</td>\n",
              "      <td>2.324424</td>\n",
              "      <td>0.332075</td>\n",
              "      <td>1.414726</td>\n",
              "      <td>6.485360e-08</td>\n",
              "      <td>43.006384</td>\n",
              "      <td>7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2022</td>\n",
              "      <td>11</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.267772</td>\n",
              "      <td>0.396421</td>\n",
              "      <td>1.524617</td>\n",
              "      <td>1889.0</td>\n",
              "      <td>257.193548</td>\n",
              "      <td>0.125</td>\n",
              "      <td>1.339528</td>\n",
              "      <td>21928</td>\n",
              "      <td>0</td>\n",
              "      <td>49</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>202211</td>\n",
              "      <td>1</td>\n",
              "      <td>202204</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>31</td>\n",
              "      <td>187.967742</td>\n",
              "      <td>8.290323</td>\n",
              "      <td>60.935484</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>591</td>\n",
              "      <td>28</td>\n",
              "      <td>380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.142344</td>\n",
              "      <td>4.211920</td>\n",
              "      <td>2.962572e-06</td>\n",
              "      <td>130.005079</td>\n",
              "      <td>1.216877</td>\n",
              "      <td>6.358433</td>\n",
              "      <td>3.525795e-07</td>\n",
              "      <td>413.494300</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>2.491572</td>\n",
              "      <td>5.319862</td>\n",
              "      <td>2.164313e-06</td>\n",
              "      <td>130.005079</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2021</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000113</td>\n",
              "      <td>1.606797</td>\n",
              "      <td>0.643361</td>\n",
              "      <td>1.380659</td>\n",
              "      <td>607.0</td>\n",
              "      <td>201.818182</td>\n",
              "      <td>0.075</td>\n",
              "      <td>0.803717</td>\n",
              "      <td>32621</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>97.077216</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>202108</td>\n",
              "      <td>8888</td>\n",
              "      <td>202107</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>11</td>\n",
              "      <td>133.181818</td>\n",
              "      <td>13.454545</td>\n",
              "      <td>55.181818</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>402</td>\n",
              "      <td>47</td>\n",
              "      <td>239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.630831</td>\n",
              "      <td>4.731466</td>\n",
              "      <td>1.489020e-06</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>0.960079</td>\n",
              "      <td>4.223822</td>\n",
              "      <td>6.485360e-08</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>0.428641</td>\n",
              "      <td>2.855335</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>101</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000113</td>\n",
              "      <td>1.606797</td>\n",
              "      <td>0.643361</td>\n",
              "      <td>1.380659</td>\n",
              "      <td>607.0</td>\n",
              "      <td>201.818182</td>\n",
              "      <td>0.075</td>\n",
              "      <td>0.803717</td>\n",
              "      <td>32622</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>139.453086</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>202208</td>\n",
              "      <td>8888</td>\n",
              "      <td>202107</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>11</td>\n",
              "      <td>133.181818</td>\n",
              "      <td>13.454545</td>\n",
              "      <td>55.181818</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>402</td>\n",
              "      <td>47</td>\n",
              "      <td>239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.142344</td>\n",
              "      <td>4.211920</td>\n",
              "      <td>2.962572e-06</td>\n",
              "      <td>130.005079</td>\n",
              "      <td>1.216877</td>\n",
              "      <td>6.358433</td>\n",
              "      <td>3.525795e-07</td>\n",
              "      <td>413.494300</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>2.491572</td>\n",
              "      <td>5.319862</td>\n",
              "      <td>2.164313e-06</td>\n",
              "      <td>130.005079</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2021</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000113</td>\n",
              "      <td>1.606797</td>\n",
              "      <td>0.643361</td>\n",
              "      <td>1.380659</td>\n",
              "      <td>607.0</td>\n",
              "      <td>201.818182</td>\n",
              "      <td>0.075</td>\n",
              "      <td>0.803717</td>\n",
              "      <td>32623</td>\n",
              "      <td>2</td>\n",
              "      <td>45</td>\n",
              "      <td>127.753445</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>202108</td>\n",
              "      <td>8888</td>\n",
              "      <td>202107</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>11</td>\n",
              "      <td>133.181818</td>\n",
              "      <td>13.454545</td>\n",
              "      <td>55.181818</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>402</td>\n",
              "      <td>47</td>\n",
              "      <td>239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.223820</td>\n",
              "      <td>1.284130</td>\n",
              "      <td>6.485360e-08</td>\n",
              "      <td>33.007089</td>\n",
              "      <td>0.960079</td>\n",
              "      <td>4.223822</td>\n",
              "      <td>6.485360e-08</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>0.416788</td>\n",
              "      <td>2.914958</td>\n",
              "      <td>0.256652</td>\n",
              "      <td>1.322104</td>\n",
              "      <td>2.838022e-07</td>\n",
              "      <td>25.502344</td>\n",
              "      <td>102</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2022</td>\n",
              "      <td>9</td>\n",
              "      <td>0.000113</td>\n",
              "      <td>1.606797</td>\n",
              "      <td>0.643361</td>\n",
              "      <td>1.380659</td>\n",
              "      <td>607.0</td>\n",
              "      <td>201.818182</td>\n",
              "      <td>0.075</td>\n",
              "      <td>0.803717</td>\n",
              "      <td>32624</td>\n",
              "      <td>3</td>\n",
              "      <td>45</td>\n",
              "      <td>112.315719</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>202209</td>\n",
              "      <td>8888</td>\n",
              "      <td>202107</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>11</td>\n",
              "      <td>133.181818</td>\n",
              "      <td>13.454545</td>\n",
              "      <td>55.181818</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>402</td>\n",
              "      <td>47</td>\n",
              "      <td>239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270906</th>\n",
              "      <td>0.300481</td>\n",
              "      <td>3.079332</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>105.003970</td>\n",
              "      <td>0.960079</td>\n",
              "      <td>4.223822</td>\n",
              "      <td>6.485360e-08</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>0.428641</td>\n",
              "      <td>2.855335</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.097422</td>\n",
              "      <td>0.164970</td>\n",
              "      <td>0.081316</td>\n",
              "      <td>130.0</td>\n",
              "      <td>14.775000</td>\n",
              "      <td>0.115</td>\n",
              "      <td>1.232366</td>\n",
              "      <td>562660</td>\n",
              "      <td>9995</td>\n",
              "      <td>26</td>\n",
              "      <td>401.063769</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>202208</td>\n",
              "      <td>10000</td>\n",
              "      <td>202201</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>40</td>\n",
              "      <td>8.075000</td>\n",
              "      <td>3.450000</td>\n",
              "      <td>3.250000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>91</td>\n",
              "      <td>96</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270907</th>\n",
              "      <td>0.300481</td>\n",
              "      <td>3.079332</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>105.003970</td>\n",
              "      <td>0.960079</td>\n",
              "      <td>4.223822</td>\n",
              "      <td>6.485360e-08</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>0.428641</td>\n",
              "      <td>2.855335</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.097422</td>\n",
              "      <td>0.164970</td>\n",
              "      <td>0.081316</td>\n",
              "      <td>130.0</td>\n",
              "      <td>14.775000</td>\n",
              "      <td>0.115</td>\n",
              "      <td>1.232366</td>\n",
              "      <td>562661</td>\n",
              "      <td>9996</td>\n",
              "      <td>26</td>\n",
              "      <td>148.726179</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>202208</td>\n",
              "      <td>10000</td>\n",
              "      <td>202201</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>40</td>\n",
              "      <td>8.075000</td>\n",
              "      <td>3.450000</td>\n",
              "      <td>3.250000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>91</td>\n",
              "      <td>96</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270908</th>\n",
              "      <td>0.300481</td>\n",
              "      <td>3.079332</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>105.003970</td>\n",
              "      <td>0.960079</td>\n",
              "      <td>4.223822</td>\n",
              "      <td>6.485360e-08</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>0.428641</td>\n",
              "      <td>2.855335</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.097422</td>\n",
              "      <td>0.164970</td>\n",
              "      <td>0.081316</td>\n",
              "      <td>130.0</td>\n",
              "      <td>14.775000</td>\n",
              "      <td>0.115</td>\n",
              "      <td>1.232366</td>\n",
              "      <td>562662</td>\n",
              "      <td>9997</td>\n",
              "      <td>26</td>\n",
              "      <td>196.309829</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>202208</td>\n",
              "      <td>10000</td>\n",
              "      <td>202201</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>40</td>\n",
              "      <td>8.075000</td>\n",
              "      <td>3.450000</td>\n",
              "      <td>3.250000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>91</td>\n",
              "      <td>96</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270909</th>\n",
              "      <td>0.300481</td>\n",
              "      <td>3.079332</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>105.003970</td>\n",
              "      <td>0.960079</td>\n",
              "      <td>4.223822</td>\n",
              "      <td>6.485360e-08</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>0.428641</td>\n",
              "      <td>2.855335</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.097422</td>\n",
              "      <td>0.164970</td>\n",
              "      <td>0.081316</td>\n",
              "      <td>130.0</td>\n",
              "      <td>14.775000</td>\n",
              "      <td>0.115</td>\n",
              "      <td>1.232366</td>\n",
              "      <td>562663</td>\n",
              "      <td>9998</td>\n",
              "      <td>26</td>\n",
              "      <td>117.435698</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>202208</td>\n",
              "      <td>10000</td>\n",
              "      <td>202201</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>40</td>\n",
              "      <td>8.075000</td>\n",
              "      <td>3.450000</td>\n",
              "      <td>3.250000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>91</td>\n",
              "      <td>96</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270910</th>\n",
              "      <td>0.300481</td>\n",
              "      <td>3.079332</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>105.003970</td>\n",
              "      <td>0.960079</td>\n",
              "      <td>4.223822</td>\n",
              "      <td>6.485360e-08</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>0.428641</td>\n",
              "      <td>2.855335</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.097422</td>\n",
              "      <td>0.164970</td>\n",
              "      <td>0.081316</td>\n",
              "      <td>130.0</td>\n",
              "      <td>14.775000</td>\n",
              "      <td>0.115</td>\n",
              "      <td>1.232366</td>\n",
              "      <td>562664</td>\n",
              "      <td>9999</td>\n",
              "      <td>26</td>\n",
              "      <td>99.717011</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>202208</td>\n",
              "      <td>10000</td>\n",
              "      <td>202201</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>40</td>\n",
              "      <td>8.075000</td>\n",
              "      <td>3.450000</td>\n",
              "      <td>3.250000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>91</td>\n",
              "      <td>96</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>270911 rows  57 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d1800fb-adba-4e85-94b3-4793e073d0d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d1800fb-adba-4e85-94b3-4793e073d0d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d1800fb-adba-4e85-94b3-4793e073d0d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "df_train=df_train_raw.merge(df_cols,on='collection_id').merge(df_cols_stats, on='collection_id')\n",
        "df_train_processed=preprocessing.fit_transform(df_train.copy())\n",
        "df_train_label=df_train_processed[target_feature].copy()\n",
        "df_train_processed.drop([target_feature,'Unnamed: 0_x'],axis=1,inplace=True)\n",
        "df_train_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Tv291CiclODo",
        "outputId": "def83cb5-2993-4609-b646-08a6de7a42f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f93e91a1730>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "df_train_label.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "6NDHR_ORK_54",
        "outputId": "1a9fbe94-163e-4afb-bea2-d9ac190bdac6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting categorical feature with input shape: (38999, 33)\n",
            "starting feature with input shape: (38999, 33)\n",
            "starting avg price feature with input shape: (38999, 45)\n",
            "starting fill na imputer with input shape:  (38999, 59)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       last_sale_price_shelf_life_avg  last_sale_price_shelf_life_std  last_sale_price_shelf_life_min  last_sale_price_shelf_life_max  last_sale_price_year_avg  last_sale_price_year_std  last_sale_price_year_min  last_sale_price_year_max  last_sale_price_month_avg  last_sale_price_month_std  last_sale_price_avg  last_sale_price_std  last_sale_price_min  last_sale_price_max  shelf_duration  openrarity_ratio  last_sale_date_year  last_sale_date_month  inverse_total_supply  ratio_avg_likes  ratio_avg_replies  ratio_avg_retweets  total_avg_likes  total_avg_twitter_activity  total_fee  ratio_avg_fee  global_index  nft_id  collection_id  rarity_score  openrarity_score  openrarity_rank  openrarity_max_rank  last_sale_date  total_supply  creation_date  verification_status  n_of_traits  contract_type  seller_fees  platform_fees  openrarity_enabled  has_website  has_own_twitter  has_discord  has_medium  Unnamed: 0_y  n_tweets_in_range  avg_likes  avg_replies  avg_retweets  min_likes  \\\n",
              "0                            1.142344                        4.211920                    2.962572e-06                      130.005079                  1.216877                  6.358433              3.525795e-07                413.494300                   1.640477                   5.719008             0.737054             0.592495         3.357847e-03             1.684732               1               0.0                 2021                     5              0.000100         0.000000             0.0000            2.798091           1342.0                  111.833333      0.050       0.535811        116861       0              7    204.010980               0.0              0.0                  0.0          202105          9998         202104                    1            7              1        0.025          0.025                   0            0                1            1           0             7                 12   0.000000     0.000000    111.833333          0   \n",
              "1                            1.142344                        4.211920                    2.962572e-06                      130.005079                  1.216877                  6.358433              3.525795e-07                413.494300                   1.640477                   5.719008             0.737054             0.592495         3.357847e-03             1.684732               1               0.0                 2021                     5              0.000100         0.000000             0.0000            2.798091           1342.0                  111.833333      0.050       0.535811        116862       1              7    182.480289               0.0              0.0                  0.0          202105          9998         202104                    1            7              1        0.025          0.025                   0            0                1            1           0             7                 12   0.000000     0.000000    111.833333          0   \n",
              "2                            0.300481                        3.079332                    1.261076e-07                      105.003970                  1.216877                  6.358433              3.525795e-07                413.494300                   0.417171                   2.324424             0.629498             3.718647         5.902306e-06           105.003970               7               0.0                 2021                    11              0.000100         0.000000             0.0000            2.798091           1342.0                  111.833333      0.050       0.535811        116863       2              7    221.312185               0.0              0.0                  0.0          202111          9998         202104                    1            7              1        0.025          0.025                   0            0                1            1           0             7                 12   0.000000     0.000000    111.833333          0   \n",
              "3                            1.142344                        4.211920                    2.962572e-06                      130.005079                  1.216877                  6.358433              3.525795e-07                413.494300                   1.640477                   5.719008             0.737054             0.592495         3.357847e-03             1.684732               1               0.0                 2021                     5              0.000100         0.000000             0.0000            2.798091           1342.0                  111.833333      0.050       0.535811        116864       3              7    149.498840               0.0              0.0                  0.0          202105          9998         202104                    1            7              1        0.025          0.025                   0            0                1            1           0             7                 12   0.000000     0.000000    111.833333          0   \n",
              "4                            1.142344                        4.211920                    2.962572e-06                      130.005079                  1.216877                  6.358433              3.525795e-07                413.494300                   1.640477                   5.719008             0.737054             0.592495         3.357847e-03             1.684732               1               0.0                 2021                     5              0.000100         0.000000             0.0000            2.798091           1342.0                  111.833333      0.050       0.535811        116865       4              7    268.527043               0.0              0.0                  0.0          202105          9998         202104                    1            7              1        0.025          0.025                   0            0                1            1           0             7                 12   0.000000     0.000000    111.833333          0   \n",
              "...                               ...                             ...                             ...                             ...                       ...                       ...                       ...                       ...                        ...                        ...                  ...                  ...                  ...                  ...             ...               ...                  ...                   ...                   ...              ...                ...                 ...              ...                         ...        ...            ...           ...     ...            ...           ...               ...              ...                  ...             ...           ...            ...                  ...          ...            ...          ...            ...                 ...          ...              ...          ...         ...           ...                ...        ...          ...           ...        ...   \n",
              "38994                        0.727428                        8.431723                    2.422092e-06                      413.494300                  0.960079                  4.223822              6.485360e-08                400.001379                   0.752649                   3.446782             0.428641             2.855335         1.261076e-07           400.001379               6               0.0                 2022                     8              0.000111         0.098374             0.0423            0.028869             30.0                   10.192308      0.115       1.232366        590223    8995              4    128.268841               0.0              0.0                  0.0          202208          9000         202202                    0            8              0        0.090          0.025                   0            0                1            0           0             4                 26   8.153846     0.884615      1.153846          0   \n",
              "38995                        0.727428                        8.431723                    2.422092e-06                      413.494300                  0.960079                  4.223822              6.485360e-08                400.001379                   0.752649                   3.446782             0.428641             2.855335         1.261076e-07           400.001379               6               0.0                 2022                     8              0.000111         0.098374             0.0423            0.028869             30.0                   10.192308      0.115       1.232366        590224    8996              4    152.040769               0.0              0.0                  0.0          202208          9000         202202                    0            8              0        0.090          0.025                   0            0                1            0           0             4                 26   8.153846     0.884615      1.153846          0   \n",
              "38996                        0.727428                        8.431723                    2.422092e-06                      413.494300                  0.960079                  4.223822              6.485360e-08                400.001379                   0.752649                   3.446782             0.428641             2.855335         1.261076e-07           400.001379               6               0.0                 2022                     8              0.000111         0.098374             0.0423            0.028869             30.0                   10.192308      0.115       1.232366        590225    8997              4    178.734807               0.0              0.0                  0.0          202208          9000         202202                    0            8              0        0.090          0.025                   0            0                1            0           0             4                 26   8.153846     0.884615      1.153846          0   \n",
              "38997                        0.727428                        8.431723                    2.422092e-06                      413.494300                  0.960079                  4.223822              6.485360e-08                400.001379                   0.752649                   3.446782             0.428641             2.855335         1.261076e-07           400.001379               6               0.0                 2022                     8              0.000111         0.098374             0.0423            0.028869             30.0                   10.192308      0.115       1.232366        590226    8998              4    130.974464               0.0              0.0                  0.0          202208          9000         202202                    0            8              0        0.090          0.025                   0            0                1            0           0             4                 26   8.153846     0.884615      1.153846          0   \n",
              "38998                        0.727428                        8.431723                    2.422092e-06                      413.494300                  0.960079                  4.223822              6.485360e-08                400.001379                   0.752649                   3.446782             0.428641             2.855335         1.261076e-07           400.001379               6               0.0                 2022                     8              0.000111         0.098374             0.0423            0.028869             30.0                   10.192308      0.115       1.232366        590227    8999              4    103.120966               0.0              0.0                  0.0          202208          9000         202202                    0            8              0        0.090          0.025                   0            0                1            0           0             4                 26   8.153846     0.884615      1.153846          0   \n",
              "\n",
              "       min_replies  min_retweets  max_likes  max_replies  max_retweets  \n",
              "0                0            31          0            0           463  \n",
              "1                0            31          0            0           463  \n",
              "2                0            31          0            0           463  \n",
              "3                0            31          0            0           463  \n",
              "4                0            31          0            0           463  \n",
              "...            ...           ...        ...          ...           ...  \n",
              "38994            0             0         30            6            12  \n",
              "38995            0             0         30            6            12  \n",
              "38996            0             0         30            6            12  \n",
              "38997            0             0         30            6            12  \n",
              "38998            0             0         30            6            12  \n",
              "\n",
              "[38999 rows x 57 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-477388d2-f3d9-4319-82ec-6e3b51f5bf84\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>last_sale_price_shelf_life_avg</th>\n",
              "      <th>last_sale_price_shelf_life_std</th>\n",
              "      <th>last_sale_price_shelf_life_min</th>\n",
              "      <th>last_sale_price_shelf_life_max</th>\n",
              "      <th>last_sale_price_year_avg</th>\n",
              "      <th>last_sale_price_year_std</th>\n",
              "      <th>last_sale_price_year_min</th>\n",
              "      <th>last_sale_price_year_max</th>\n",
              "      <th>last_sale_price_month_avg</th>\n",
              "      <th>last_sale_price_month_std</th>\n",
              "      <th>last_sale_price_avg</th>\n",
              "      <th>last_sale_price_std</th>\n",
              "      <th>last_sale_price_min</th>\n",
              "      <th>last_sale_price_max</th>\n",
              "      <th>shelf_duration</th>\n",
              "      <th>openrarity_ratio</th>\n",
              "      <th>last_sale_date_year</th>\n",
              "      <th>last_sale_date_month</th>\n",
              "      <th>inverse_total_supply</th>\n",
              "      <th>ratio_avg_likes</th>\n",
              "      <th>ratio_avg_replies</th>\n",
              "      <th>ratio_avg_retweets</th>\n",
              "      <th>total_avg_likes</th>\n",
              "      <th>total_avg_twitter_activity</th>\n",
              "      <th>total_fee</th>\n",
              "      <th>ratio_avg_fee</th>\n",
              "      <th>global_index</th>\n",
              "      <th>nft_id</th>\n",
              "      <th>collection_id</th>\n",
              "      <th>rarity_score</th>\n",
              "      <th>openrarity_score</th>\n",
              "      <th>openrarity_rank</th>\n",
              "      <th>openrarity_max_rank</th>\n",
              "      <th>last_sale_date</th>\n",
              "      <th>total_supply</th>\n",
              "      <th>creation_date</th>\n",
              "      <th>verification_status</th>\n",
              "      <th>n_of_traits</th>\n",
              "      <th>contract_type</th>\n",
              "      <th>seller_fees</th>\n",
              "      <th>platform_fees</th>\n",
              "      <th>openrarity_enabled</th>\n",
              "      <th>has_website</th>\n",
              "      <th>has_own_twitter</th>\n",
              "      <th>has_discord</th>\n",
              "      <th>has_medium</th>\n",
              "      <th>Unnamed: 0_y</th>\n",
              "      <th>n_tweets_in_range</th>\n",
              "      <th>avg_likes</th>\n",
              "      <th>avg_replies</th>\n",
              "      <th>avg_retweets</th>\n",
              "      <th>min_likes</th>\n",
              "      <th>min_replies</th>\n",
              "      <th>min_retweets</th>\n",
              "      <th>max_likes</th>\n",
              "      <th>max_replies</th>\n",
              "      <th>max_retweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.142344</td>\n",
              "      <td>4.211920</td>\n",
              "      <td>2.962572e-06</td>\n",
              "      <td>130.005079</td>\n",
              "      <td>1.216877</td>\n",
              "      <td>6.358433</td>\n",
              "      <td>3.525795e-07</td>\n",
              "      <td>413.494300</td>\n",
              "      <td>1.640477</td>\n",
              "      <td>5.719008</td>\n",
              "      <td>0.737054</td>\n",
              "      <td>0.592495</td>\n",
              "      <td>3.357847e-03</td>\n",
              "      <td>1.684732</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2021</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2.798091</td>\n",
              "      <td>1342.0</td>\n",
              "      <td>111.833333</td>\n",
              "      <td>0.050</td>\n",
              "      <td>0.535811</td>\n",
              "      <td>116861</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>204.010980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>202105</td>\n",
              "      <td>9998</td>\n",
              "      <td>202104</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>111.833333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.142344</td>\n",
              "      <td>4.211920</td>\n",
              "      <td>2.962572e-06</td>\n",
              "      <td>130.005079</td>\n",
              "      <td>1.216877</td>\n",
              "      <td>6.358433</td>\n",
              "      <td>3.525795e-07</td>\n",
              "      <td>413.494300</td>\n",
              "      <td>1.640477</td>\n",
              "      <td>5.719008</td>\n",
              "      <td>0.737054</td>\n",
              "      <td>0.592495</td>\n",
              "      <td>3.357847e-03</td>\n",
              "      <td>1.684732</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2021</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2.798091</td>\n",
              "      <td>1342.0</td>\n",
              "      <td>111.833333</td>\n",
              "      <td>0.050</td>\n",
              "      <td>0.535811</td>\n",
              "      <td>116862</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>182.480289</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>202105</td>\n",
              "      <td>9998</td>\n",
              "      <td>202104</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>111.833333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.300481</td>\n",
              "      <td>3.079332</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>105.003970</td>\n",
              "      <td>1.216877</td>\n",
              "      <td>6.358433</td>\n",
              "      <td>3.525795e-07</td>\n",
              "      <td>413.494300</td>\n",
              "      <td>0.417171</td>\n",
              "      <td>2.324424</td>\n",
              "      <td>0.629498</td>\n",
              "      <td>3.718647</td>\n",
              "      <td>5.902306e-06</td>\n",
              "      <td>105.003970</td>\n",
              "      <td>7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2021</td>\n",
              "      <td>11</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2.798091</td>\n",
              "      <td>1342.0</td>\n",
              "      <td>111.833333</td>\n",
              "      <td>0.050</td>\n",
              "      <td>0.535811</td>\n",
              "      <td>116863</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>221.312185</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>202111</td>\n",
              "      <td>9998</td>\n",
              "      <td>202104</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>111.833333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.142344</td>\n",
              "      <td>4.211920</td>\n",
              "      <td>2.962572e-06</td>\n",
              "      <td>130.005079</td>\n",
              "      <td>1.216877</td>\n",
              "      <td>6.358433</td>\n",
              "      <td>3.525795e-07</td>\n",
              "      <td>413.494300</td>\n",
              "      <td>1.640477</td>\n",
              "      <td>5.719008</td>\n",
              "      <td>0.737054</td>\n",
              "      <td>0.592495</td>\n",
              "      <td>3.357847e-03</td>\n",
              "      <td>1.684732</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2021</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2.798091</td>\n",
              "      <td>1342.0</td>\n",
              "      <td>111.833333</td>\n",
              "      <td>0.050</td>\n",
              "      <td>0.535811</td>\n",
              "      <td>116864</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>149.498840</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>202105</td>\n",
              "      <td>9998</td>\n",
              "      <td>202104</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>111.833333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.142344</td>\n",
              "      <td>4.211920</td>\n",
              "      <td>2.962572e-06</td>\n",
              "      <td>130.005079</td>\n",
              "      <td>1.216877</td>\n",
              "      <td>6.358433</td>\n",
              "      <td>3.525795e-07</td>\n",
              "      <td>413.494300</td>\n",
              "      <td>1.640477</td>\n",
              "      <td>5.719008</td>\n",
              "      <td>0.737054</td>\n",
              "      <td>0.592495</td>\n",
              "      <td>3.357847e-03</td>\n",
              "      <td>1.684732</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2021</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2.798091</td>\n",
              "      <td>1342.0</td>\n",
              "      <td>111.833333</td>\n",
              "      <td>0.050</td>\n",
              "      <td>0.535811</td>\n",
              "      <td>116865</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>268.527043</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>202105</td>\n",
              "      <td>9998</td>\n",
              "      <td>202104</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>111.833333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38994</th>\n",
              "      <td>0.727428</td>\n",
              "      <td>8.431723</td>\n",
              "      <td>2.422092e-06</td>\n",
              "      <td>413.494300</td>\n",
              "      <td>0.960079</td>\n",
              "      <td>4.223822</td>\n",
              "      <td>6.485360e-08</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>0.428641</td>\n",
              "      <td>2.855335</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.098374</td>\n",
              "      <td>0.0423</td>\n",
              "      <td>0.028869</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10.192308</td>\n",
              "      <td>0.115</td>\n",
              "      <td>1.232366</td>\n",
              "      <td>590223</td>\n",
              "      <td>8995</td>\n",
              "      <td>4</td>\n",
              "      <td>128.268841</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>202208</td>\n",
              "      <td>9000</td>\n",
              "      <td>202202</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.090</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>8.153846</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>1.153846</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38995</th>\n",
              "      <td>0.727428</td>\n",
              "      <td>8.431723</td>\n",
              "      <td>2.422092e-06</td>\n",
              "      <td>413.494300</td>\n",
              "      <td>0.960079</td>\n",
              "      <td>4.223822</td>\n",
              "      <td>6.485360e-08</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>0.428641</td>\n",
              "      <td>2.855335</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.098374</td>\n",
              "      <td>0.0423</td>\n",
              "      <td>0.028869</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10.192308</td>\n",
              "      <td>0.115</td>\n",
              "      <td>1.232366</td>\n",
              "      <td>590224</td>\n",
              "      <td>8996</td>\n",
              "      <td>4</td>\n",
              "      <td>152.040769</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>202208</td>\n",
              "      <td>9000</td>\n",
              "      <td>202202</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.090</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>8.153846</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>1.153846</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38996</th>\n",
              "      <td>0.727428</td>\n",
              "      <td>8.431723</td>\n",
              "      <td>2.422092e-06</td>\n",
              "      <td>413.494300</td>\n",
              "      <td>0.960079</td>\n",
              "      <td>4.223822</td>\n",
              "      <td>6.485360e-08</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>0.428641</td>\n",
              "      <td>2.855335</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.098374</td>\n",
              "      <td>0.0423</td>\n",
              "      <td>0.028869</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10.192308</td>\n",
              "      <td>0.115</td>\n",
              "      <td>1.232366</td>\n",
              "      <td>590225</td>\n",
              "      <td>8997</td>\n",
              "      <td>4</td>\n",
              "      <td>178.734807</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>202208</td>\n",
              "      <td>9000</td>\n",
              "      <td>202202</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.090</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>8.153846</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>1.153846</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38997</th>\n",
              "      <td>0.727428</td>\n",
              "      <td>8.431723</td>\n",
              "      <td>2.422092e-06</td>\n",
              "      <td>413.494300</td>\n",
              "      <td>0.960079</td>\n",
              "      <td>4.223822</td>\n",
              "      <td>6.485360e-08</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>0.428641</td>\n",
              "      <td>2.855335</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.098374</td>\n",
              "      <td>0.0423</td>\n",
              "      <td>0.028869</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10.192308</td>\n",
              "      <td>0.115</td>\n",
              "      <td>1.232366</td>\n",
              "      <td>590226</td>\n",
              "      <td>8998</td>\n",
              "      <td>4</td>\n",
              "      <td>130.974464</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>202208</td>\n",
              "      <td>9000</td>\n",
              "      <td>202202</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.090</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>8.153846</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>1.153846</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38998</th>\n",
              "      <td>0.727428</td>\n",
              "      <td>8.431723</td>\n",
              "      <td>2.422092e-06</td>\n",
              "      <td>413.494300</td>\n",
              "      <td>0.960079</td>\n",
              "      <td>4.223822</td>\n",
              "      <td>6.485360e-08</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>0.428641</td>\n",
              "      <td>2.855335</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2022</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.098374</td>\n",
              "      <td>0.0423</td>\n",
              "      <td>0.028869</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10.192308</td>\n",
              "      <td>0.115</td>\n",
              "      <td>1.232366</td>\n",
              "      <td>590227</td>\n",
              "      <td>8999</td>\n",
              "      <td>4</td>\n",
              "      <td>103.120966</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>202208</td>\n",
              "      <td>9000</td>\n",
              "      <td>202202</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.090</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>8.153846</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>1.153846</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38999 rows  57 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-477388d2-f3d9-4319-82ec-6e3b51f5bf84')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-477388d2-f3d9-4319-82ec-6e3b51f5bf84 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-477388d2-f3d9-4319-82ec-6e3b51f5bf84');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "df_valid=df_valid_raw.merge(df_cols,on='collection_id').merge(df_cols_stats, on='collection_id')\n",
        "df_valid_processed=preprocessing.transform(df_valid)\n",
        "df_valid_label=df_valid_processed[target_feature].copy()\n",
        "df_valid_processed.drop([target_feature,'Unnamed: 0_x'],axis=1,inplace=True)\n",
        "df_valid_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "PcCNu58MlWx7",
        "outputId": "bc55c3d4-a157-483a-a72e-bb3173f22272"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f93e9068d30>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "df_valid_label.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "7W_NpRObQ5Ed"
      },
      "outputs": [],
      "source": [
        "df_train_all_merged=df_all_train.merge(df_cols,on='collection_id').merge(df_cols_stats, on='collection_id')\n",
        "df_train_all_merged_label=df_train_all_merged[target_feature].copy()\n",
        "#df_train_all_merged.drop(['last_sale_price','Unnamed: 0_x'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "TpTpByOv9P6d",
        "outputId": "0a2cbdce-10d9-4118-cdbd-6ecdc85eda46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        global_index  nft_id  collection_id  rarity_score  openrarity_score  openrarity_rank  openrarity_max_rank  last_sale_date  Unnamed: 0_x  total_supply  creation_date verification_status  n_of_traits contract_type  seller_fees  platform_fees  openrarity_enabled  has_website  has_own_twitter  has_discord  has_medium  Unnamed: 0_y  n_tweets_in_range   avg_likes  avg_replies  avg_retweets  min_likes  min_replies  min_retweets  max_likes  max_replies  max_retweets\n",
              "0                  0       0             29    176.364208               NaN              NaN                  NaN          202206             9          9999         202205            verified           10           own        0.075          0.025               False        False             True        False       False            22                  2  340.500000    68.500000    109.000000          0            0            11        681          137           207\n",
              "1                  1       1             29    207.209228               NaN              NaN                  NaN          202205             9          9999         202205            verified           10           own        0.075          0.025               False        False             True        False       False            22                  2  340.500000    68.500000    109.000000          0            0            11        681          137           207\n",
              "2                  2       2             29    157.293414               NaN              NaN                  NaN          202210             9          9999         202205            verified           10           own        0.075          0.025               False        False             True        False       False            22                  2  340.500000    68.500000    109.000000          0            0            11        681          137           207\n",
              "3                  3       3             29    173.372185               NaN              NaN                  NaN          202206             9          9999         202205            verified           10           own        0.075          0.025               False        False             True        False       False            22                  2  340.500000    68.500000    109.000000          0            0            11        681          137           207\n",
              "4                  4       4             29    190.077584               NaN              NaN                  NaN          202206             9          9999         202205            verified           10           own        0.075          0.025               False        False             True        False       False            22                  2  340.500000    68.500000    109.000000          0            0            11        681          137           207\n",
              "...              ...     ...            ...           ...               ...              ...                  ...             ...           ...           ...            ...                 ...          ...           ...          ...            ...                 ...          ...              ...          ...         ...           ...                ...         ...          ...           ...        ...          ...           ...        ...          ...           ...\n",
              "181209        618137    7140             42    134.963415               NaN              NaN                  NaN          202104            29         22134         202101            approved           80       default        0.070          0.025               False        False             True         True        True            32                668    1.252994     0.302395      0.314371          0            0             0         80            6            13\n",
              "181210        618138    7141             42    128.686047               NaN              NaN                  NaN          202104            29         22134         202101            approved           80       default        0.070          0.025               False        False             True         True        True            32                668    1.252994     0.302395      0.314371          0            0             0         80            6            13\n",
              "181211        618139    7142             42  22134.000000               NaN              NaN                  NaN          202104            29         22134         202101            approved           80       default        0.070          0.025               False        False             True         True        True            32                668    1.252994     0.302395      0.314371          0            0             0         80            6            13\n",
              "181212        618140    7143             42  22134.000000               NaN              NaN                  NaN          202104            29         22134         202101            approved           80       default        0.070          0.025               False        False             True         True        True            32                668    1.252994     0.302395      0.314371          0            0             0         80            6            13\n",
              "181213        618141    7144             42    130.970414               NaN              NaN                  NaN          202103            29         22134         202101            approved           80       default        0.070          0.025               False        False             True         True        True            32                668    1.252994     0.302395      0.314371          0            0             0         80            6            13\n",
              "\n",
              "[181214 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27a4dbdd-0ffd-4a57-b19b-7e02e6aa0db1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>global_index</th>\n",
              "      <th>nft_id</th>\n",
              "      <th>collection_id</th>\n",
              "      <th>rarity_score</th>\n",
              "      <th>openrarity_score</th>\n",
              "      <th>openrarity_rank</th>\n",
              "      <th>openrarity_max_rank</th>\n",
              "      <th>last_sale_date</th>\n",
              "      <th>Unnamed: 0_x</th>\n",
              "      <th>total_supply</th>\n",
              "      <th>creation_date</th>\n",
              "      <th>verification_status</th>\n",
              "      <th>n_of_traits</th>\n",
              "      <th>contract_type</th>\n",
              "      <th>seller_fees</th>\n",
              "      <th>platform_fees</th>\n",
              "      <th>openrarity_enabled</th>\n",
              "      <th>has_website</th>\n",
              "      <th>has_own_twitter</th>\n",
              "      <th>has_discord</th>\n",
              "      <th>has_medium</th>\n",
              "      <th>Unnamed: 0_y</th>\n",
              "      <th>n_tweets_in_range</th>\n",
              "      <th>avg_likes</th>\n",
              "      <th>avg_replies</th>\n",
              "      <th>avg_retweets</th>\n",
              "      <th>min_likes</th>\n",
              "      <th>min_replies</th>\n",
              "      <th>min_retweets</th>\n",
              "      <th>max_likes</th>\n",
              "      <th>max_replies</th>\n",
              "      <th>max_retweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>176.364208</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>202206</td>\n",
              "      <td>9</td>\n",
              "      <td>9999</td>\n",
              "      <td>202205</td>\n",
              "      <td>verified</td>\n",
              "      <td>10</td>\n",
              "      <td>own</td>\n",
              "      <td>0.075</td>\n",
              "      <td>0.025</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>340.500000</td>\n",
              "      <td>68.500000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>681</td>\n",
              "      <td>137</td>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>207.209228</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>202205</td>\n",
              "      <td>9</td>\n",
              "      <td>9999</td>\n",
              "      <td>202205</td>\n",
              "      <td>verified</td>\n",
              "      <td>10</td>\n",
              "      <td>own</td>\n",
              "      <td>0.075</td>\n",
              "      <td>0.025</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>340.500000</td>\n",
              "      <td>68.500000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>681</td>\n",
              "      <td>137</td>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>29</td>\n",
              "      <td>157.293414</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>202210</td>\n",
              "      <td>9</td>\n",
              "      <td>9999</td>\n",
              "      <td>202205</td>\n",
              "      <td>verified</td>\n",
              "      <td>10</td>\n",
              "      <td>own</td>\n",
              "      <td>0.075</td>\n",
              "      <td>0.025</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>340.500000</td>\n",
              "      <td>68.500000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>681</td>\n",
              "      <td>137</td>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>29</td>\n",
              "      <td>173.372185</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>202206</td>\n",
              "      <td>9</td>\n",
              "      <td>9999</td>\n",
              "      <td>202205</td>\n",
              "      <td>verified</td>\n",
              "      <td>10</td>\n",
              "      <td>own</td>\n",
              "      <td>0.075</td>\n",
              "      <td>0.025</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>340.500000</td>\n",
              "      <td>68.500000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>681</td>\n",
              "      <td>137</td>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>190.077584</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>202206</td>\n",
              "      <td>9</td>\n",
              "      <td>9999</td>\n",
              "      <td>202205</td>\n",
              "      <td>verified</td>\n",
              "      <td>10</td>\n",
              "      <td>own</td>\n",
              "      <td>0.075</td>\n",
              "      <td>0.025</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>340.500000</td>\n",
              "      <td>68.500000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>681</td>\n",
              "      <td>137</td>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181209</th>\n",
              "      <td>618137</td>\n",
              "      <td>7140</td>\n",
              "      <td>42</td>\n",
              "      <td>134.963415</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>202104</td>\n",
              "      <td>29</td>\n",
              "      <td>22134</td>\n",
              "      <td>202101</td>\n",
              "      <td>approved</td>\n",
              "      <td>80</td>\n",
              "      <td>default</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.025</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>32</td>\n",
              "      <td>668</td>\n",
              "      <td>1.252994</td>\n",
              "      <td>0.302395</td>\n",
              "      <td>0.314371</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181210</th>\n",
              "      <td>618138</td>\n",
              "      <td>7141</td>\n",
              "      <td>42</td>\n",
              "      <td>128.686047</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>202104</td>\n",
              "      <td>29</td>\n",
              "      <td>22134</td>\n",
              "      <td>202101</td>\n",
              "      <td>approved</td>\n",
              "      <td>80</td>\n",
              "      <td>default</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.025</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>32</td>\n",
              "      <td>668</td>\n",
              "      <td>1.252994</td>\n",
              "      <td>0.302395</td>\n",
              "      <td>0.314371</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181211</th>\n",
              "      <td>618139</td>\n",
              "      <td>7142</td>\n",
              "      <td>42</td>\n",
              "      <td>22134.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>202104</td>\n",
              "      <td>29</td>\n",
              "      <td>22134</td>\n",
              "      <td>202101</td>\n",
              "      <td>approved</td>\n",
              "      <td>80</td>\n",
              "      <td>default</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.025</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>32</td>\n",
              "      <td>668</td>\n",
              "      <td>1.252994</td>\n",
              "      <td>0.302395</td>\n",
              "      <td>0.314371</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181212</th>\n",
              "      <td>618140</td>\n",
              "      <td>7143</td>\n",
              "      <td>42</td>\n",
              "      <td>22134.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>202104</td>\n",
              "      <td>29</td>\n",
              "      <td>22134</td>\n",
              "      <td>202101</td>\n",
              "      <td>approved</td>\n",
              "      <td>80</td>\n",
              "      <td>default</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.025</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>32</td>\n",
              "      <td>668</td>\n",
              "      <td>1.252994</td>\n",
              "      <td>0.302395</td>\n",
              "      <td>0.314371</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181213</th>\n",
              "      <td>618141</td>\n",
              "      <td>7144</td>\n",
              "      <td>42</td>\n",
              "      <td>130.970414</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>202103</td>\n",
              "      <td>29</td>\n",
              "      <td>22134</td>\n",
              "      <td>202101</td>\n",
              "      <td>approved</td>\n",
              "      <td>80</td>\n",
              "      <td>default</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.025</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>32</td>\n",
              "      <td>668</td>\n",
              "      <td>1.252994</td>\n",
              "      <td>0.302395</td>\n",
              "      <td>0.314371</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>181214 rows  32 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27a4dbdd-0ffd-4a57-b19b-7e02e6aa0db1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-27a4dbdd-0ffd-4a57-b19b-7e02e6aa0db1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-27a4dbdd-0ffd-4a57-b19b-7e02e6aa0db1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "df_test_all_merged=df_nfts_predict.merge(df_cols,on='collection_id').merge(df_cols_stats, on='collection_id')\n",
        "df_test_all_merged\n",
        "#df_test_all_merged_label=df_test_all_merged[target_feature].copy()\n",
        "#df_train_all_merged.drop(['last_sale_price','Unnamed: 0_x'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "aCtXu-oGwRcM"
      },
      "outputs": [],
      "source": [
        "df_train_all_processed=df_all_train.merge(df_cols,on='collection_id').merge(df_cols_stats, on='collection_id')\n",
        "df_train_all_processed_label=df_train_all_processed[target_feature].copy()\n",
        "#df_train_all_processed.drop(['last_sale_price','Unnamed: 0_x'],axis=1,inplace=True)\n",
        "#df_train_all_processed=preprocessing_all.fit_transform(df_train_all_processed.copy())\n",
        "#df_train_all_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWPLqgf2MIT2",
        "outputId": "8c181837-cfcd-4a29-e90a-a9e7963da170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 38999 entries, 0 to 38998\n",
            "Data columns (total 57 columns):\n",
            " #   Column                          Non-Null Count  Dtype  \n",
            "---  ------                          --------------  -----  \n",
            " 0   last_sale_price_shelf_life_avg  38999 non-null  float64\n",
            " 1   last_sale_price_shelf_life_std  38999 non-null  float64\n",
            " 2   last_sale_price_shelf_life_min  38999 non-null  float64\n",
            " 3   last_sale_price_shelf_life_max  38999 non-null  float64\n",
            " 4   last_sale_price_year_avg        38999 non-null  float64\n",
            " 5   last_sale_price_year_std        38999 non-null  float64\n",
            " 6   last_sale_price_year_min        38999 non-null  float64\n",
            " 7   last_sale_price_year_max        38999 non-null  float64\n",
            " 8   last_sale_price_month_avg       38999 non-null  float64\n",
            " 9   last_sale_price_month_std       38999 non-null  float64\n",
            " 10  last_sale_price_avg             38999 non-null  float64\n",
            " 11  last_sale_price_std             38999 non-null  float64\n",
            " 12  last_sale_price_min             38999 non-null  float64\n",
            " 13  last_sale_price_max             38999 non-null  float64\n",
            " 14  shelf_duration                  38999 non-null  int32  \n",
            " 15  openrarity_ratio                38999 non-null  float64\n",
            " 16  last_sale_date_year             38999 non-null  int32  \n",
            " 17  last_sale_date_month            38999 non-null  int32  \n",
            " 18  inverse_total_supply            38999 non-null  float64\n",
            " 19  ratio_avg_likes                 38999 non-null  float64\n",
            " 20  ratio_avg_replies               38999 non-null  float64\n",
            " 21  ratio_avg_retweets              38999 non-null  float64\n",
            " 22  total_avg_likes                 38999 non-null  float64\n",
            " 23  total_avg_twitter_activity      38999 non-null  float64\n",
            " 24  total_fee                       38999 non-null  float64\n",
            " 25  ratio_avg_fee                   38999 non-null  float64\n",
            " 26  global_index                    38999 non-null  int64  \n",
            " 27  nft_id                          38999 non-null  int64  \n",
            " 28  collection_id                   38999 non-null  int64  \n",
            " 29  rarity_score                    38999 non-null  float64\n",
            " 30  openrarity_score                38999 non-null  float64\n",
            " 31  openrarity_rank                 38999 non-null  float64\n",
            " 32  openrarity_max_rank             38999 non-null  float64\n",
            " 33  last_sale_date                  38999 non-null  int32  \n",
            " 34  total_supply                    38999 non-null  int64  \n",
            " 35  creation_date                   38999 non-null  int32  \n",
            " 36  verification_status             38999 non-null  int64  \n",
            " 37  n_of_traits                     38999 non-null  int64  \n",
            " 38  contract_type                   38999 non-null  int64  \n",
            " 39  seller_fees                     38999 non-null  float64\n",
            " 40  platform_fees                   38999 non-null  float64\n",
            " 41  openrarity_enabled              38999 non-null  int64  \n",
            " 42  has_website                     38999 non-null  int64  \n",
            " 43  has_own_twitter                 38999 non-null  int64  \n",
            " 44  has_discord                     38999 non-null  int64  \n",
            " 45  has_medium                      38999 non-null  int64  \n",
            " 46  Unnamed: 0_y                    38999 non-null  int64  \n",
            " 47  n_tweets_in_range               38999 non-null  int64  \n",
            " 48  avg_likes                       38999 non-null  float64\n",
            " 49  avg_replies                     38999 non-null  float64\n",
            " 50  avg_retweets                    38999 non-null  float64\n",
            " 51  min_likes                       38999 non-null  int64  \n",
            " 52  min_replies                     38999 non-null  int64  \n",
            " 53  min_retweets                    38999 non-null  int64  \n",
            " 54  max_likes                       38999 non-null  int64  \n",
            " 55  max_replies                     38999 non-null  int64  \n",
            " 56  max_retweets                    38999 non-null  int64  \n",
            "dtypes: float64(32), int32(5), int64(20)\n",
            "memory usage: 16.5 MB\n"
          ]
        }
      ],
      "source": [
        "df_valid_processed.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2QQOX0qOH-B",
        "outputId": "b73dda2c-834a-4592-f092-f8bbe4ebec5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 38999 entries, 0 to 38998\n",
            "Data columns (total 29 columns):\n",
            " #   Column                          Non-Null Count  Dtype  \n",
            "---  ------                          --------------  -----  \n",
            " 0   total_avg_likes                 38999 non-null  float64\n",
            " 1   n_of_traits                     38999 non-null  int64  \n",
            " 2   total_supply                    38999 non-null  int64  \n",
            " 3   shelf_duration                  38999 non-null  int32  \n",
            " 4   avg_likes                       38999 non-null  float64\n",
            " 5   max_replies                     38999 non-null  int64  \n",
            " 6   avg_replies                     38999 non-null  float64\n",
            " 7   ratio_avg_likes                 38999 non-null  float64\n",
            " 8   max_likes                       38999 non-null  int64  \n",
            " 9   total_avg_twitter_activity      38999 non-null  float64\n",
            " 10  last_sale_price_std             38999 non-null  float64\n",
            " 11  max_retweets                    38999 non-null  int64  \n",
            " 12  last_sale_date_month            38999 non-null  int32  \n",
            " 13  ratio_avg_replies               38999 non-null  float64\n",
            " 14  rarity_score                    38999 non-null  float64\n",
            " 15  ratio_avg_retweets              38999 non-null  float64\n",
            " 16  avg_retweets                    38999 non-null  float64\n",
            " 17  last_sale_price_avg             38999 non-null  float64\n",
            " 18  last_sale_price_month_avg       38999 non-null  float64\n",
            " 19  last_sale_price_month_std       38999 non-null  float64\n",
            " 20  last_sale_price_shelf_life_max  38999 non-null  float64\n",
            " 21  last_sale_price_max             38999 non-null  float64\n",
            " 22  n_tweets_in_range               38999 non-null  int64  \n",
            " 23  last_sale_price_min             38999 non-null  float64\n",
            " 24  min_retweets                    38999 non-null  int64  \n",
            " 25  last_sale_price_shelf_life_avg  38999 non-null  float64\n",
            " 26  contract_type                   38999 non-null  int64  \n",
            " 27  creation_date                   38999 non-null  int32  \n",
            " 28  last_sale_date                  38999 non-null  int32  \n",
            "dtypes: float64(17), int32(4), int64(8)\n",
            "memory usage: 8.3 MB\n"
          ]
        }
      ],
      "source": [
        "df_valid_processed[all_column_names].info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "oBZtnGcYrIDr",
        "outputId": "9a1a12a6-a16d-4e31-b9e9-a7e6aeec7849"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        total_avg_likes  n_of_traits  total_supply  shelf_duration   avg_likes  max_replies  avg_replies  ratio_avg_likes  max_likes  total_avg_twitter_activity  last_sale_price_std  max_retweets  last_sale_date_month  ratio_avg_replies  rarity_score  ratio_avg_retweets  avg_retweets  last_sale_price_avg  last_sale_price_month_avg  last_sale_price_month_std  last_sale_price_shelf_life_max  last_sale_price_max  n_tweets_in_range  last_sale_price_min  min_retweets  last_sale_price_shelf_life_avg  contract_type  creation_date  last_sale_date\n",
              "0                1889.0            2             1               7  187.967742           28     8.290323         2.267772        591                  257.193548             1.414726           380                    11           0.396421      2.000000            1.524617     60.935484             0.332075                   0.417171                   2.324424                      105.003970            43.006384                 31         6.485360e-08             2                        0.300481              1         202204          202211\n",
              "1                 607.0            5          8888               1  133.181818           47    13.454545         1.606797        402                  201.818182             5.319862           239                     8           0.643361     97.077216            1.380659     55.181818             2.491572                   0.752649                   3.446782                      130.005079           130.005079                 11         2.164313e-06             7                        1.142344              1         202107          202108\n",
              "2                 607.0            5          8888             101  133.181818           47    13.454545         1.606797        402                  201.818182             2.855335           239                     8           0.643361    139.453086            1.380659     55.181818             0.428641                   0.752649                   3.446782                      400.001379           400.001379                 11         1.261076e-07             7                        0.630831              1         202107          202208\n",
              "3                 607.0            5          8888               1  133.181818           47    13.454545         1.606797        402                  201.818182             5.319862           239                     8           0.643361    127.753445            1.380659     55.181818             2.491572                   0.752649                   3.446782                      130.005079           130.005079                 11         2.164313e-06             7                        1.142344              1         202107          202108\n",
              "4                 607.0            5          8888             102  133.181818           47    13.454545         1.606797        402                  201.818182             1.322104           239                     9           0.643361    112.315719            1.380659     55.181818             0.256652                   0.416788                   2.914958                       33.007089            25.502344                 11         2.838022e-07             7                        0.223820              1         202107          202209\n",
              "...                 ...          ...           ...             ...         ...          ...          ...              ...        ...                         ...                  ...           ...                   ...                ...           ...                 ...           ...                  ...                        ...                        ...                             ...                  ...                ...                  ...           ...                             ...            ...            ...             ...\n",
              "270906            130.0            9         10000               7    8.075000           96     3.450000         0.097422         91                   14.775000             2.855335            88                     8           0.164970    401.063769            0.081316      3.250000             0.428641                   0.752649                   3.446782                      105.003970           400.001379                 40         1.261076e-07             0                        0.300481              0         202201          202208\n",
              "270907            130.0            9         10000               7    8.075000           96     3.450000         0.097422         91                   14.775000             2.855335            88                     8           0.164970    148.726179            0.081316      3.250000             0.428641                   0.752649                   3.446782                      105.003970           400.001379                 40         1.261076e-07             0                        0.300481              0         202201          202208\n",
              "270908            130.0            9         10000               7    8.075000           96     3.450000         0.097422         91                   14.775000             2.855335            88                     8           0.164970    196.309829            0.081316      3.250000             0.428641                   0.752649                   3.446782                      105.003970           400.001379                 40         1.261076e-07             0                        0.300481              0         202201          202208\n",
              "270909            130.0            9         10000               7    8.075000           96     3.450000         0.097422         91                   14.775000             2.855335            88                     8           0.164970    117.435698            0.081316      3.250000             0.428641                   0.752649                   3.446782                      105.003970           400.001379                 40         1.261076e-07             0                        0.300481              0         202201          202208\n",
              "270910            130.0            9         10000               7    8.075000           96     3.450000         0.097422         91                   14.775000             2.855335            88                     8           0.164970     99.717011            0.081316      3.250000             0.428641                   0.752649                   3.446782                      105.003970           400.001379                 40         1.261076e-07             0                        0.300481              0         202201          202208\n",
              "\n",
              "[270911 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85d46c9a-ffd8-4065-bdcd-967979cae5ef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_avg_likes</th>\n",
              "      <th>n_of_traits</th>\n",
              "      <th>total_supply</th>\n",
              "      <th>shelf_duration</th>\n",
              "      <th>avg_likes</th>\n",
              "      <th>max_replies</th>\n",
              "      <th>avg_replies</th>\n",
              "      <th>ratio_avg_likes</th>\n",
              "      <th>max_likes</th>\n",
              "      <th>total_avg_twitter_activity</th>\n",
              "      <th>last_sale_price_std</th>\n",
              "      <th>max_retweets</th>\n",
              "      <th>last_sale_date_month</th>\n",
              "      <th>ratio_avg_replies</th>\n",
              "      <th>rarity_score</th>\n",
              "      <th>ratio_avg_retweets</th>\n",
              "      <th>avg_retweets</th>\n",
              "      <th>last_sale_price_avg</th>\n",
              "      <th>last_sale_price_month_avg</th>\n",
              "      <th>last_sale_price_month_std</th>\n",
              "      <th>last_sale_price_shelf_life_max</th>\n",
              "      <th>last_sale_price_max</th>\n",
              "      <th>n_tweets_in_range</th>\n",
              "      <th>last_sale_price_min</th>\n",
              "      <th>min_retweets</th>\n",
              "      <th>last_sale_price_shelf_life_avg</th>\n",
              "      <th>contract_type</th>\n",
              "      <th>creation_date</th>\n",
              "      <th>last_sale_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1889.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>187.967742</td>\n",
              "      <td>28</td>\n",
              "      <td>8.290323</td>\n",
              "      <td>2.267772</td>\n",
              "      <td>591</td>\n",
              "      <td>257.193548</td>\n",
              "      <td>1.414726</td>\n",
              "      <td>380</td>\n",
              "      <td>11</td>\n",
              "      <td>0.396421</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.524617</td>\n",
              "      <td>60.935484</td>\n",
              "      <td>0.332075</td>\n",
              "      <td>0.417171</td>\n",
              "      <td>2.324424</td>\n",
              "      <td>105.003970</td>\n",
              "      <td>43.006384</td>\n",
              "      <td>31</td>\n",
              "      <td>6.485360e-08</td>\n",
              "      <td>2</td>\n",
              "      <td>0.300481</td>\n",
              "      <td>1</td>\n",
              "      <td>202204</td>\n",
              "      <td>202211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>607.0</td>\n",
              "      <td>5</td>\n",
              "      <td>8888</td>\n",
              "      <td>1</td>\n",
              "      <td>133.181818</td>\n",
              "      <td>47</td>\n",
              "      <td>13.454545</td>\n",
              "      <td>1.606797</td>\n",
              "      <td>402</td>\n",
              "      <td>201.818182</td>\n",
              "      <td>5.319862</td>\n",
              "      <td>239</td>\n",
              "      <td>8</td>\n",
              "      <td>0.643361</td>\n",
              "      <td>97.077216</td>\n",
              "      <td>1.380659</td>\n",
              "      <td>55.181818</td>\n",
              "      <td>2.491572</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>130.005079</td>\n",
              "      <td>130.005079</td>\n",
              "      <td>11</td>\n",
              "      <td>2.164313e-06</td>\n",
              "      <td>7</td>\n",
              "      <td>1.142344</td>\n",
              "      <td>1</td>\n",
              "      <td>202107</td>\n",
              "      <td>202108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>607.0</td>\n",
              "      <td>5</td>\n",
              "      <td>8888</td>\n",
              "      <td>101</td>\n",
              "      <td>133.181818</td>\n",
              "      <td>47</td>\n",
              "      <td>13.454545</td>\n",
              "      <td>1.606797</td>\n",
              "      <td>402</td>\n",
              "      <td>201.818182</td>\n",
              "      <td>2.855335</td>\n",
              "      <td>239</td>\n",
              "      <td>8</td>\n",
              "      <td>0.643361</td>\n",
              "      <td>139.453086</td>\n",
              "      <td>1.380659</td>\n",
              "      <td>55.181818</td>\n",
              "      <td>0.428641</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>11</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>7</td>\n",
              "      <td>0.630831</td>\n",
              "      <td>1</td>\n",
              "      <td>202107</td>\n",
              "      <td>202208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>607.0</td>\n",
              "      <td>5</td>\n",
              "      <td>8888</td>\n",
              "      <td>1</td>\n",
              "      <td>133.181818</td>\n",
              "      <td>47</td>\n",
              "      <td>13.454545</td>\n",
              "      <td>1.606797</td>\n",
              "      <td>402</td>\n",
              "      <td>201.818182</td>\n",
              "      <td>5.319862</td>\n",
              "      <td>239</td>\n",
              "      <td>8</td>\n",
              "      <td>0.643361</td>\n",
              "      <td>127.753445</td>\n",
              "      <td>1.380659</td>\n",
              "      <td>55.181818</td>\n",
              "      <td>2.491572</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>130.005079</td>\n",
              "      <td>130.005079</td>\n",
              "      <td>11</td>\n",
              "      <td>2.164313e-06</td>\n",
              "      <td>7</td>\n",
              "      <td>1.142344</td>\n",
              "      <td>1</td>\n",
              "      <td>202107</td>\n",
              "      <td>202108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>607.0</td>\n",
              "      <td>5</td>\n",
              "      <td>8888</td>\n",
              "      <td>102</td>\n",
              "      <td>133.181818</td>\n",
              "      <td>47</td>\n",
              "      <td>13.454545</td>\n",
              "      <td>1.606797</td>\n",
              "      <td>402</td>\n",
              "      <td>201.818182</td>\n",
              "      <td>1.322104</td>\n",
              "      <td>239</td>\n",
              "      <td>9</td>\n",
              "      <td>0.643361</td>\n",
              "      <td>112.315719</td>\n",
              "      <td>1.380659</td>\n",
              "      <td>55.181818</td>\n",
              "      <td>0.256652</td>\n",
              "      <td>0.416788</td>\n",
              "      <td>2.914958</td>\n",
              "      <td>33.007089</td>\n",
              "      <td>25.502344</td>\n",
              "      <td>11</td>\n",
              "      <td>2.838022e-07</td>\n",
              "      <td>7</td>\n",
              "      <td>0.223820</td>\n",
              "      <td>1</td>\n",
              "      <td>202107</td>\n",
              "      <td>202209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270906</th>\n",
              "      <td>130.0</td>\n",
              "      <td>9</td>\n",
              "      <td>10000</td>\n",
              "      <td>7</td>\n",
              "      <td>8.075000</td>\n",
              "      <td>96</td>\n",
              "      <td>3.450000</td>\n",
              "      <td>0.097422</td>\n",
              "      <td>91</td>\n",
              "      <td>14.775000</td>\n",
              "      <td>2.855335</td>\n",
              "      <td>88</td>\n",
              "      <td>8</td>\n",
              "      <td>0.164970</td>\n",
              "      <td>401.063769</td>\n",
              "      <td>0.081316</td>\n",
              "      <td>3.250000</td>\n",
              "      <td>0.428641</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>105.003970</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>40</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.300481</td>\n",
              "      <td>0</td>\n",
              "      <td>202201</td>\n",
              "      <td>202208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270907</th>\n",
              "      <td>130.0</td>\n",
              "      <td>9</td>\n",
              "      <td>10000</td>\n",
              "      <td>7</td>\n",
              "      <td>8.075000</td>\n",
              "      <td>96</td>\n",
              "      <td>3.450000</td>\n",
              "      <td>0.097422</td>\n",
              "      <td>91</td>\n",
              "      <td>14.775000</td>\n",
              "      <td>2.855335</td>\n",
              "      <td>88</td>\n",
              "      <td>8</td>\n",
              "      <td>0.164970</td>\n",
              "      <td>148.726179</td>\n",
              "      <td>0.081316</td>\n",
              "      <td>3.250000</td>\n",
              "      <td>0.428641</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>105.003970</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>40</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.300481</td>\n",
              "      <td>0</td>\n",
              "      <td>202201</td>\n",
              "      <td>202208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270908</th>\n",
              "      <td>130.0</td>\n",
              "      <td>9</td>\n",
              "      <td>10000</td>\n",
              "      <td>7</td>\n",
              "      <td>8.075000</td>\n",
              "      <td>96</td>\n",
              "      <td>3.450000</td>\n",
              "      <td>0.097422</td>\n",
              "      <td>91</td>\n",
              "      <td>14.775000</td>\n",
              "      <td>2.855335</td>\n",
              "      <td>88</td>\n",
              "      <td>8</td>\n",
              "      <td>0.164970</td>\n",
              "      <td>196.309829</td>\n",
              "      <td>0.081316</td>\n",
              "      <td>3.250000</td>\n",
              "      <td>0.428641</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>105.003970</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>40</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.300481</td>\n",
              "      <td>0</td>\n",
              "      <td>202201</td>\n",
              "      <td>202208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270909</th>\n",
              "      <td>130.0</td>\n",
              "      <td>9</td>\n",
              "      <td>10000</td>\n",
              "      <td>7</td>\n",
              "      <td>8.075000</td>\n",
              "      <td>96</td>\n",
              "      <td>3.450000</td>\n",
              "      <td>0.097422</td>\n",
              "      <td>91</td>\n",
              "      <td>14.775000</td>\n",
              "      <td>2.855335</td>\n",
              "      <td>88</td>\n",
              "      <td>8</td>\n",
              "      <td>0.164970</td>\n",
              "      <td>117.435698</td>\n",
              "      <td>0.081316</td>\n",
              "      <td>3.250000</td>\n",
              "      <td>0.428641</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>105.003970</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>40</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.300481</td>\n",
              "      <td>0</td>\n",
              "      <td>202201</td>\n",
              "      <td>202208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270910</th>\n",
              "      <td>130.0</td>\n",
              "      <td>9</td>\n",
              "      <td>10000</td>\n",
              "      <td>7</td>\n",
              "      <td>8.075000</td>\n",
              "      <td>96</td>\n",
              "      <td>3.450000</td>\n",
              "      <td>0.097422</td>\n",
              "      <td>91</td>\n",
              "      <td>14.775000</td>\n",
              "      <td>2.855335</td>\n",
              "      <td>88</td>\n",
              "      <td>8</td>\n",
              "      <td>0.164970</td>\n",
              "      <td>99.717011</td>\n",
              "      <td>0.081316</td>\n",
              "      <td>3.250000</td>\n",
              "      <td>0.428641</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>105.003970</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>40</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.300481</td>\n",
              "      <td>0</td>\n",
              "      <td>202201</td>\n",
              "      <td>202208</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>270911 rows  29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85d46c9a-ffd8-4065-bdcd-967979cae5ef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-85d46c9a-ffd8-4065-bdcd-967979cae5ef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-85d46c9a-ffd8-4065-bdcd-967979cae5ef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "df_train_processed[all_column_names]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "-dfcr6SqzJKl",
        "outputId": "2a1a981c-35c6-4083-c1f5-d7245213a917"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       total_avg_likes  n_of_traits  total_supply  shelf_duration  avg_likes  max_replies  avg_replies  ratio_avg_likes  max_likes  total_avg_twitter_activity  last_sale_price_std  max_retweets  last_sale_date_month  ratio_avg_replies  rarity_score  ratio_avg_retweets  avg_retweets  last_sale_price_avg  last_sale_price_month_avg  last_sale_price_month_std  last_sale_price_shelf_life_max  last_sale_price_max  n_tweets_in_range  last_sale_price_min  min_retweets  last_sale_price_shelf_life_avg  contract_type  creation_date  last_sale_date\n",
              "0               1342.0            7          9998               1   0.000000            0     0.000000         0.000000          0                  111.833333             0.592495           463                     5             0.0000    204.010980            2.798091    111.833333             0.737054                   1.640477                   5.719008                      130.005079             1.684732                 12         3.357847e-03            31                        1.142344              1         202104          202105\n",
              "1               1342.0            7          9998               1   0.000000            0     0.000000         0.000000          0                  111.833333             0.592495           463                     5             0.0000    182.480289            2.798091    111.833333             0.737054                   1.640477                   5.719008                      130.005079             1.684732                 12         3.357847e-03            31                        1.142344              1         202104          202105\n",
              "2               1342.0            7          9998               7   0.000000            0     0.000000         0.000000          0                  111.833333             3.718647           463                    11             0.0000    221.312185            2.798091    111.833333             0.629498                   0.417171                   2.324424                      105.003970           105.003970                 12         5.902306e-06            31                        0.300481              1         202104          202111\n",
              "3               1342.0            7          9998               1   0.000000            0     0.000000         0.000000          0                  111.833333             0.592495           463                     5             0.0000    149.498840            2.798091    111.833333             0.737054                   1.640477                   5.719008                      130.005079             1.684732                 12         3.357847e-03            31                        1.142344              1         202104          202105\n",
              "4               1342.0            7          9998               1   0.000000            0     0.000000         0.000000          0                  111.833333             0.592495           463                     5             0.0000    268.527043            2.798091    111.833333             0.737054                   1.640477                   5.719008                      130.005079             1.684732                 12         3.357847e-03            31                        1.142344              1         202104          202105\n",
              "...                ...          ...           ...             ...        ...          ...          ...              ...        ...                         ...                  ...           ...                   ...                ...           ...                 ...           ...                  ...                        ...                        ...                             ...                  ...                ...                  ...           ...                             ...            ...            ...             ...\n",
              "38994             30.0            8          9000               6   8.153846            6     0.884615         0.098374         30                   10.192308             2.855335            12                     8             0.0423    128.268841            0.028869      1.153846             0.428641                   0.752649                   3.446782                      413.494300           400.001379                 26         1.261076e-07             0                        0.727428              0         202202          202208\n",
              "38995             30.0            8          9000               6   8.153846            6     0.884615         0.098374         30                   10.192308             2.855335            12                     8             0.0423    152.040769            0.028869      1.153846             0.428641                   0.752649                   3.446782                      413.494300           400.001379                 26         1.261076e-07             0                        0.727428              0         202202          202208\n",
              "38996             30.0            8          9000               6   8.153846            6     0.884615         0.098374         30                   10.192308             2.855335            12                     8             0.0423    178.734807            0.028869      1.153846             0.428641                   0.752649                   3.446782                      413.494300           400.001379                 26         1.261076e-07             0                        0.727428              0         202202          202208\n",
              "38997             30.0            8          9000               6   8.153846            6     0.884615         0.098374         30                   10.192308             2.855335            12                     8             0.0423    130.974464            0.028869      1.153846             0.428641                   0.752649                   3.446782                      413.494300           400.001379                 26         1.261076e-07             0                        0.727428              0         202202          202208\n",
              "38998             30.0            8          9000               6   8.153846            6     0.884615         0.098374         30                   10.192308             2.855335            12                     8             0.0423    103.120966            0.028869      1.153846             0.428641                   0.752649                   3.446782                      413.494300           400.001379                 26         1.261076e-07             0                        0.727428              0         202202          202208\n",
              "\n",
              "[38999 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9e5a978-361e-4c39-9153-c675fcf97a72\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_avg_likes</th>\n",
              "      <th>n_of_traits</th>\n",
              "      <th>total_supply</th>\n",
              "      <th>shelf_duration</th>\n",
              "      <th>avg_likes</th>\n",
              "      <th>max_replies</th>\n",
              "      <th>avg_replies</th>\n",
              "      <th>ratio_avg_likes</th>\n",
              "      <th>max_likes</th>\n",
              "      <th>total_avg_twitter_activity</th>\n",
              "      <th>last_sale_price_std</th>\n",
              "      <th>max_retweets</th>\n",
              "      <th>last_sale_date_month</th>\n",
              "      <th>ratio_avg_replies</th>\n",
              "      <th>rarity_score</th>\n",
              "      <th>ratio_avg_retweets</th>\n",
              "      <th>avg_retweets</th>\n",
              "      <th>last_sale_price_avg</th>\n",
              "      <th>last_sale_price_month_avg</th>\n",
              "      <th>last_sale_price_month_std</th>\n",
              "      <th>last_sale_price_shelf_life_max</th>\n",
              "      <th>last_sale_price_max</th>\n",
              "      <th>n_tweets_in_range</th>\n",
              "      <th>last_sale_price_min</th>\n",
              "      <th>min_retweets</th>\n",
              "      <th>last_sale_price_shelf_life_avg</th>\n",
              "      <th>contract_type</th>\n",
              "      <th>creation_date</th>\n",
              "      <th>last_sale_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1342.0</td>\n",
              "      <td>7</td>\n",
              "      <td>9998</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>111.833333</td>\n",
              "      <td>0.592495</td>\n",
              "      <td>463</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>204.010980</td>\n",
              "      <td>2.798091</td>\n",
              "      <td>111.833333</td>\n",
              "      <td>0.737054</td>\n",
              "      <td>1.640477</td>\n",
              "      <td>5.719008</td>\n",
              "      <td>130.005079</td>\n",
              "      <td>1.684732</td>\n",
              "      <td>12</td>\n",
              "      <td>3.357847e-03</td>\n",
              "      <td>31</td>\n",
              "      <td>1.142344</td>\n",
              "      <td>1</td>\n",
              "      <td>202104</td>\n",
              "      <td>202105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1342.0</td>\n",
              "      <td>7</td>\n",
              "      <td>9998</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>111.833333</td>\n",
              "      <td>0.592495</td>\n",
              "      <td>463</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>182.480289</td>\n",
              "      <td>2.798091</td>\n",
              "      <td>111.833333</td>\n",
              "      <td>0.737054</td>\n",
              "      <td>1.640477</td>\n",
              "      <td>5.719008</td>\n",
              "      <td>130.005079</td>\n",
              "      <td>1.684732</td>\n",
              "      <td>12</td>\n",
              "      <td>3.357847e-03</td>\n",
              "      <td>31</td>\n",
              "      <td>1.142344</td>\n",
              "      <td>1</td>\n",
              "      <td>202104</td>\n",
              "      <td>202105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1342.0</td>\n",
              "      <td>7</td>\n",
              "      <td>9998</td>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>111.833333</td>\n",
              "      <td>3.718647</td>\n",
              "      <td>463</td>\n",
              "      <td>11</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>221.312185</td>\n",
              "      <td>2.798091</td>\n",
              "      <td>111.833333</td>\n",
              "      <td>0.629498</td>\n",
              "      <td>0.417171</td>\n",
              "      <td>2.324424</td>\n",
              "      <td>105.003970</td>\n",
              "      <td>105.003970</td>\n",
              "      <td>12</td>\n",
              "      <td>5.902306e-06</td>\n",
              "      <td>31</td>\n",
              "      <td>0.300481</td>\n",
              "      <td>1</td>\n",
              "      <td>202104</td>\n",
              "      <td>202111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1342.0</td>\n",
              "      <td>7</td>\n",
              "      <td>9998</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>111.833333</td>\n",
              "      <td>0.592495</td>\n",
              "      <td>463</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>149.498840</td>\n",
              "      <td>2.798091</td>\n",
              "      <td>111.833333</td>\n",
              "      <td>0.737054</td>\n",
              "      <td>1.640477</td>\n",
              "      <td>5.719008</td>\n",
              "      <td>130.005079</td>\n",
              "      <td>1.684732</td>\n",
              "      <td>12</td>\n",
              "      <td>3.357847e-03</td>\n",
              "      <td>31</td>\n",
              "      <td>1.142344</td>\n",
              "      <td>1</td>\n",
              "      <td>202104</td>\n",
              "      <td>202105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1342.0</td>\n",
              "      <td>7</td>\n",
              "      <td>9998</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>111.833333</td>\n",
              "      <td>0.592495</td>\n",
              "      <td>463</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>268.527043</td>\n",
              "      <td>2.798091</td>\n",
              "      <td>111.833333</td>\n",
              "      <td>0.737054</td>\n",
              "      <td>1.640477</td>\n",
              "      <td>5.719008</td>\n",
              "      <td>130.005079</td>\n",
              "      <td>1.684732</td>\n",
              "      <td>12</td>\n",
              "      <td>3.357847e-03</td>\n",
              "      <td>31</td>\n",
              "      <td>1.142344</td>\n",
              "      <td>1</td>\n",
              "      <td>202104</td>\n",
              "      <td>202105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38994</th>\n",
              "      <td>30.0</td>\n",
              "      <td>8</td>\n",
              "      <td>9000</td>\n",
              "      <td>6</td>\n",
              "      <td>8.153846</td>\n",
              "      <td>6</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>0.098374</td>\n",
              "      <td>30</td>\n",
              "      <td>10.192308</td>\n",
              "      <td>2.855335</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0423</td>\n",
              "      <td>128.268841</td>\n",
              "      <td>0.028869</td>\n",
              "      <td>1.153846</td>\n",
              "      <td>0.428641</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>413.494300</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>26</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.727428</td>\n",
              "      <td>0</td>\n",
              "      <td>202202</td>\n",
              "      <td>202208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38995</th>\n",
              "      <td>30.0</td>\n",
              "      <td>8</td>\n",
              "      <td>9000</td>\n",
              "      <td>6</td>\n",
              "      <td>8.153846</td>\n",
              "      <td>6</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>0.098374</td>\n",
              "      <td>30</td>\n",
              "      <td>10.192308</td>\n",
              "      <td>2.855335</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0423</td>\n",
              "      <td>152.040769</td>\n",
              "      <td>0.028869</td>\n",
              "      <td>1.153846</td>\n",
              "      <td>0.428641</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>413.494300</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>26</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.727428</td>\n",
              "      <td>0</td>\n",
              "      <td>202202</td>\n",
              "      <td>202208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38996</th>\n",
              "      <td>30.0</td>\n",
              "      <td>8</td>\n",
              "      <td>9000</td>\n",
              "      <td>6</td>\n",
              "      <td>8.153846</td>\n",
              "      <td>6</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>0.098374</td>\n",
              "      <td>30</td>\n",
              "      <td>10.192308</td>\n",
              "      <td>2.855335</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0423</td>\n",
              "      <td>178.734807</td>\n",
              "      <td>0.028869</td>\n",
              "      <td>1.153846</td>\n",
              "      <td>0.428641</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>413.494300</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>26</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.727428</td>\n",
              "      <td>0</td>\n",
              "      <td>202202</td>\n",
              "      <td>202208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38997</th>\n",
              "      <td>30.0</td>\n",
              "      <td>8</td>\n",
              "      <td>9000</td>\n",
              "      <td>6</td>\n",
              "      <td>8.153846</td>\n",
              "      <td>6</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>0.098374</td>\n",
              "      <td>30</td>\n",
              "      <td>10.192308</td>\n",
              "      <td>2.855335</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0423</td>\n",
              "      <td>130.974464</td>\n",
              "      <td>0.028869</td>\n",
              "      <td>1.153846</td>\n",
              "      <td>0.428641</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>413.494300</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>26</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.727428</td>\n",
              "      <td>0</td>\n",
              "      <td>202202</td>\n",
              "      <td>202208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38998</th>\n",
              "      <td>30.0</td>\n",
              "      <td>8</td>\n",
              "      <td>9000</td>\n",
              "      <td>6</td>\n",
              "      <td>8.153846</td>\n",
              "      <td>6</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>0.098374</td>\n",
              "      <td>30</td>\n",
              "      <td>10.192308</td>\n",
              "      <td>2.855335</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0423</td>\n",
              "      <td>103.120966</td>\n",
              "      <td>0.028869</td>\n",
              "      <td>1.153846</td>\n",
              "      <td>0.428641</td>\n",
              "      <td>0.752649</td>\n",
              "      <td>3.446782</td>\n",
              "      <td>413.494300</td>\n",
              "      <td>400.001379</td>\n",
              "      <td>26</td>\n",
              "      <td>1.261076e-07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.727428</td>\n",
              "      <td>0</td>\n",
              "      <td>202202</td>\n",
              "      <td>202208</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38999 rows  29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9e5a978-361e-4c39-9153-c675fcf97a72')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e9e5a978-361e-4c39-9153-c675fcf97a72 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e9e5a978-361e-4c39-9153-c675fcf97a72');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "df_valid_processed[all_column_names]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxrmlBF20HRb",
        "outputId": "88d8a757-bbd8-4962-8325-02b6abccb8f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "total_avg_likes                   [1889.0, 607.0, 170.0, 2399.0, 82.0, 16.0, 24....\n",
              "n_of_traits                       [2, 5, 19, 8, 31, 6, 10, 14, 13, 12, 1, 4, 9, ...\n",
              "total_supply                      [1, 8888, 9997, 5022, 6501, 12505, 7993, 9998,...\n",
              "shelf_duration                    [7, 1, 101, 102, 3, 103, 104, 97, 4, 94, 100, ...\n",
              "avg_likes                         [187.96774193548387, 133.1818181818182, 0.0, 3...\n",
              "max_replies                       [28, 47, 0, 121, 14, 5, 12, 41, 101, 10, 21, 9...\n",
              "avg_replies                       [8.290322580645162, 13.454545454545457, 0.0, 5...\n",
              "ratio_avg_likes                   [2.2677724848600023, 1.6067973134455125, 0.0, ...\n",
              "max_likes                         [591, 402, 0, 540, 243, 20, 47, 202, 459, 23, ...\n",
              "total_avg_twitter_activity        [257.19354838709677, 201.81818181818184, 8.947...\n",
              "last_sale_price_std               [1.4147263974694961, 5.319861906801008, 2.8553...\n",
              "max_retweets                      [380, 239, 54, 359, 76, 6, 11, 69, 135, 24, 51...\n",
              "last_sale_date_month                        [11, 8, 9, 10, 4, 1, 7, 12, 2, 6, 3, 5]\n",
              "ratio_avg_replies                 [0.39642119820245936, 0.6433606145570866, 0.0,...\n",
              "rarity_score                      [2.0, 97.07721623225166, 139.45308602172497, 1...\n",
              "ratio_avg_retweets                [1.5246171847329024, 1.380659394827423, 0.2238...\n",
              "avg_retweets                      [60.935483870967744, 55.18181818181818, 8.9473...\n",
              "last_sale_price_avg               [0.332074895527727, 2.4915720992722123, 0.4286...\n",
              "last_sale_price_month_avg         [0.4171711037442939, 0.7526488046173394, 0.416...\n",
              "last_sale_price_month_std         [2.324424249272062, 3.4467817876005236, 2.9149...\n",
              "last_sale_price_shelf_life_max    [105.0039696419018, 130.0050793007316, 400.001...\n",
              "last_sale_price_max               [43.00638365260316, 130.0050793007316, 400.001...\n",
              "n_tweets_in_range                 [31, 11, 19, 13, 2, 3, 18, 35, 4, 151, 8, 16, ...\n",
              "last_sale_price_min               [6.485360305230616e-08, 2.1643131585347144e-06...\n",
              "min_retweets                      [2, 7, 1, 40, 6, 4, 0, 24, 5, 36, 31, 9, 21, 4...\n",
              "last_sale_price_shelf_life_avg    [0.30048115132567393, 1.1423440689124313, 0.63...\n",
              "contract_type                                                                [1, 0]\n",
              "creation_date                     [202204, 202107, 202111, 202206, 202102, 20210...\n",
              "last_sale_date                    [202211, 202108, 202208, 202209, 202110, 20221...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "df_train_processed[all_column_names].apply(lambda x: x.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW00h3F390WM",
        "outputId": "1dd49c11-5353-4a42-c29d-c05c82a23f27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    2.709110e+05\n",
              "mean     9.965007e-01\n",
              "std      4.588282e+00\n",
              "min      6.485360e-08\n",
              "25%      4.073473e-03\n",
              "50%      8.083610e-03\n",
              "75%      3.363717e-01\n",
              "max      4.134943e+02\n",
              "Name: last_sale_price, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "df_train_label.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBAA50YX92wy",
        "outputId": "4860ed9a-9748-45dc-dc08-9c5108ef2093"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    3.899900e+04\n",
              "mean     1.026041e+01\n",
              "std      3.272384e+01\n",
              "min      6.608277e-08\n",
              "25%      4.107917e-03\n",
              "50%      8.244784e-03\n",
              "75%      2.762810e-01\n",
              "max      1.024002e+03\n",
              "Name: last_sale_price, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "df_valid_label.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZcYDTR3z9kT",
        "outputId": "0cac852c-c410-475b-8bf5-0ae99d2e63c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "total_avg_likes                     [1341.9999999999998, 309.0, 29.999999999999993]\n",
              "n_of_traits                                                              [7, 8, 10]\n",
              "total_supply                                              [9998, 9999, 10000, 9000]\n",
              "shelf_duration                    [1, 7, 4, 5, 97, 99, 3, 101, 2, 107, 103, 100,...\n",
              "avg_likes                              [0.0, 227.33333333333331, 8.153846153846153]\n",
              "max_replies                                                              [0, 74, 6]\n",
              "avg_replies                           [0.0, 61.333333333333336, 0.8846153846153846]\n",
              "ratio_avg_likes                       [0.0, 2.742706130937027, 0.09837362391585547]\n",
              "max_likes                                                              [0, 297, 30]\n",
              "total_avg_twitter_activity        [111.83333333333331, 391.66666666666663, 10.19...\n",
              "last_sale_price_std               [0.5924949282557108, 3.7186469553744517, 5.319...\n",
              "max_retweets                                                         [463, 162, 12]\n",
              "last_sale_date_month                        [5, 11, 8, 9, 1, 3, 7, 6, 4, 2, 10, 12]\n",
              "ratio_avg_replies                   [0.0, 2.9327970357287008, 0.042299957246087025]\n",
              "rarity_score                      [204.0109803902137, 182.48028907683928, 221.31...\n",
              "ratio_avg_retweets                [2.7980908822683164, 2.5770792328492096, 0.028...\n",
              "avg_retweets                        [111.83333333333331, 103.0, 1.1538461538461535]\n",
              "last_sale_price_avg               [0.7370535851014551, 0.6294983274500434, 2.491...\n",
              "last_sale_price_month_avg         [1.6404774358941403, 0.4171711037442939, 0.752...\n",
              "last_sale_price_month_std         [5.719007975903024, 2.324424249272062, 3.44678...\n",
              "last_sale_price_shelf_life_max    [130.0050793007316, 105.0039696419018, 100.002...\n",
              "last_sale_price_max               [1.6847323124657845, 105.0039696419018, 130.00...\n",
              "n_tweets_in_range                                                       [12, 3, 26]\n",
              "last_sale_price_min               [0.0033578471979346, 5.902306332788987e-06, 2....\n",
              "min_retweets                                                            [31, 37, 0]\n",
              "last_sale_price_shelf_life_avg    [1.1423440689124313, 0.30048115132567393, 1.02...\n",
              "contract_type                                                                [1, 0]\n",
              "creation_date                                      [202104, 202112, 202201, 202202]\n",
              "last_sale_date                    [202105, 202111, 202108, 202109, 202201, 20220...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "df_valid_processed[all_column_names].apply(lambda x: x.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9rvpmBirD5L",
        "outputId": "061c10ac-d573-4497-f6a0-8b63d4055128"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         1.266732\n",
              "1         1.200357\n",
              "2         3.180572\n",
              "3         3.502910\n",
              "4         4.009567\n",
              "            ...   \n",
              "270906    0.005700\n",
              "270907    0.004271\n",
              "270908    0.003694\n",
              "270909    0.007942\n",
              "270910    0.000732\n",
              "Name: last_sale_price, Length: 270911, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "df_train_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSX9hedSStB_"
      },
      "source": [
        "# Model Training with LightGBM and DART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "y3fiPeJAN3M4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "\n",
        "def create_exp_rmse_score(mult=-1, log=False):\n",
        "  def exp_rmse_score_fn(y_true, y_hat):    \n",
        "      mse=MeanSquaredError()\n",
        "      mse_res=mse(y_true,y_hat)\n",
        "      rmse=K.sqrt(mse_res)\n",
        "      res=K.exp(mult*rmse/10)\n",
        "      if log:\n",
        "        print(f\"Tensor mse_res:{mse_res} rmse: {rmse} res: {res} mult:{mult}\")\n",
        "      return res\n",
        "  return exp_rmse_score_fn\n",
        "\n",
        "def lgb_exp_rmse_score(y_true, y_hat):        \n",
        "\n",
        "    res=exp_rmse_score(y_true,y_hat)\n",
        "    #print(f\"res: {res}\")\n",
        "    return 'exp_rmse', res, True\n",
        "\n",
        "def exp_rmse_score(y_true, y_hat):            \n",
        "    rmse=mean_squared_error (y_true, y_hat, squared=False)        \n",
        "    res=np.exp(-rmse/10)\n",
        "\n",
        "    print(f\"Numpy rmse: {rmse} res: {res}\")\n",
        "\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=np.random.rand(20)\n",
        "b=a*0.1"
      ],
      "metadata": {
        "id": "As53Z5xG6NoY"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K.exp(-1*9.6/10)"
      ],
      "metadata": {
        "id": "9BqOodDr6nTv",
        "outputId": "98abad85-15c7-483e-fccd-a07fb571704d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.3828929>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_exp_rmse_score=create_exp_rmse_score(-1)\n",
        "tensor_exp_rmse_score(a,b)"
      ],
      "metadata": {
        "id": "D8gpfUgK6_F7",
        "outputId": "90cfac2c-98ac-4b50-9902-1bc69919decf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float64, numpy=0.946328668017229>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QNU05Fx17IfC"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Flvm0CYWm9eu"
      },
      "outputs": [],
      "source": [
        "def create_catboost_regressor(num_iter=1000):    \n",
        "    params = {\n",
        "        'iterations':num_iter, \n",
        "        'objective':'RMSE',\n",
        "        #'objective':'Huber',        \n",
        "        'max_depth':6, \n",
        "        'learning_rate':0.01, \n",
        "        'loss_function':'RMSE',\n",
        "        'min_data_in_leaf':120,\n",
        "        'early_stopping_rounds':50,\n",
        "        #'eval_metric':exp_rmse_score,\n",
        "        #'score_function':[exp_rmse_score],\n",
        "        'verbose':1\n",
        "    } \n",
        "    \n",
        "    #lgb_valid = [(df_train_processed[all_column_names],df_train_label),\n",
        "    #            (df_valid_processed[all_column_names],df_valid_label)]\n",
        "    #'eval_set':lgb_valid,                \n",
        "    fit_params={#'feature_name':all_column_names,\n",
        "                'cat_features':cat_features,                \n",
        "                'verbose':1\n",
        "               }\n",
        "    model= CatBoostRegressor(**params)    \n",
        "    return model, fit_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "vGlpv4jKUlIs"
      },
      "outputs": [],
      "source": [
        "def create_lgb_regressor(num_iter=1000):    \n",
        "    params = {\n",
        "        'force_col_wise':True, # memory foot print is smaller\n",
        "        'n_estimators':num_iter,\n",
        "        'objective': 'regression',\n",
        "        'metric': \"rmse\",\n",
        "        #'metric':[lgb_exp_rmse_score],\n",
        "        #'boosting_type': 'dart',\n",
        "        'max_depth' : -1,\n",
        "        'random_state': MY_SEED,        \n",
        "        'learning_rate': 0.01,\n",
        "        #'num_leaves': 2 ** 6, \n",
        "        'min_data_in_leaf': 50,\n",
        "        #'subsample': 0.8,  \n",
        "        #'subsample_freq': 1,\n",
        "        #'first_metric_only': True,\n",
        "        #'boost_from_average': False,\n",
        "        #'tree_learner': 'serial',        \n",
        "        'verbose': 2,      \n",
        "    }   \n",
        "\n",
        "    fit_params={'feature_name':all_column_names,\n",
        "                'eval_metric':[lgb_exp_rmse_score],\n",
        "                'categorical_feature':cat_features,\n",
        "                'verbose':2\n",
        "               }\n",
        "\n",
        "    model=lgb.LGBMRegressor(**fit_params)\n",
        "    return model, fit_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "N56ssc6xsQ7F"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "def create_mlp_regressor(lr0=0.001,num_iter=1000):  \n",
        "\n",
        "  tf.random.set_seed(MY_SEED)\n",
        "  norm_layer= tf.keras.layers.Normalization(input_shape=(len(all_column_names),))\n",
        "  #regulazier=tf.keras.regularizers.L1L2(0.01,0.01)\n",
        "  regulazier=tf.keras.regularizers.L2(0)\n",
        "  model= tf.keras.Sequential([\n",
        "      norm_layer,\n",
        "      tf.keras.layers.Dense(100,activation='relu'),\n",
        "      tf.keras.layers.Dense(100,activation='relu'),\n",
        "      tf.keras.layers.Dense(100,activation='relu'),\n",
        "      #tf.keras.layers.Dense(32,activation='swish', kernel_initializer='he_normal', kernel_regularizer=regulazier),\n",
        "      ##tf.keras.layers.Dropout(0.15),      \n",
        "      #tf.keras.layers.Dense(32,activation='swish', kernel_initializer='he_normal', kernel_regularizer=regulazier),\n",
        "      ##tf.keras.layers.Dropout(0.15),\n",
        "      ##tf.keras.layers.Dense(1, activation='relu', kernel_initializer='he_normal')\n",
        "      tf.keras.layers.Dense(1, kernel_regularizer=regulazier)\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=lr0)  \n",
        "  #optimizer = tf.keras.optimizers.Nadam(learning_rate=lr0)  \n",
        "  #optimizer = tf.keras.optimizers.SGD(learning_rate=lr0,nesterov=True)\n",
        "  #loss=tf.keras.losses.Huber(delta=1.35)\n",
        "  #loss=tf.keras.losses.MeanSquaredLogarithmicError()    \n",
        "  #loss=tf.keras.losses.LogCosh()\n",
        "  #loss= tf.keras.losses.MeanAbsolutePercentageError()\n",
        "  loss='mse'\n",
        "  #loss=create_exp_rmse_score(1)\n",
        "  model.compile(loss=loss, optimizer=optimizer, metrics= [tf.keras.metrics.RootMeanSquaredError(), create_exp_rmse_score(-1) ])\n",
        "  #model.compile(loss=\"mse\", optimizer=optimizer, metrics= [exp_rmse_score])\n",
        "  exp_rmse_score\n",
        "\n",
        "  fit_params={\n",
        "      'epochs':num_iter\n",
        "  }\n",
        "\n",
        "  return model, fit_params, norm_layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B0eTtIIfU6K4",
        "outputId": "daca91d7-2424-45de-beb9-e25765a5a7b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "col_ids: [49 45 54 30  0 58 15 23  7 38 31 50 37  1  8 57 59 19  6 48 14 36 25 13\n",
            " 43 18 60 44 24 51 46 34 26  4]\n",
            "MAX_SALE: 1\n",
            "starting categorical feature with input shape: (247928, 33)\n",
            "[Pipeline]  (step 1 of 4) Processing categoricaltransformer, total=   0.1s\n",
            "starting feature with input shape: (247928, 33)\n",
            "[Pipeline]  (step 2 of 4) Processing featuretransformers, total=   0.1s\n",
            "starting avg price feature with input shape: (247928, 45)\n",
            "[Pipeline]  (step 3 of 4) Processing avgpricetransformer, total=   1.1s\n",
            "starting fill na imputer with input shape:  (247928, 59)\n",
            "[Pipeline] ..... (step 4 of 4) Processing fillnaimputer, total=   0.0s\n",
            "starting categorical feature with input shape: (61982, 33)\n",
            "starting feature with input shape: (61982, 33)\n",
            "starting avg price feature with input shape: (61982, 45)\n",
            "starting fill na imputer with input shape:  (61982, 59)\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization_15 (Normaliza  (None, 29)               59        \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 100)               3000      \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,360\n",
            "Trainable params: 23,301\n",
            "Non-trainable params: 59\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 161.1439 - root_mean_squared_error: 12.6942 - exp_rmse_score_fn: 0.2810 - val_loss: 198.3119 - val_root_mean_squared_error: 14.0823 - val_exp_rmse_score_fn: 0.2446\n",
            "Epoch 2/10000\n",
            "1/1 [==============================] - 1s 580ms/step - loss: 159.8264 - root_mean_squared_error: 12.6422 - exp_rmse_score_fn: 0.2825 - val_loss: 197.1679 - val_root_mean_squared_error: 14.0416 - val_exp_rmse_score_fn: 0.2456\n",
            "Epoch 3/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 158.6895 - root_mean_squared_error: 12.5972 - exp_rmse_score_fn: 0.2837 - val_loss: 196.1619 - val_root_mean_squared_error: 14.0058 - val_exp_rmse_score_fn: 0.2465\n",
            "Epoch 4/10000\n",
            "1/1 [==============================] - 1s 576ms/step - loss: 157.6882 - root_mean_squared_error: 12.5574 - exp_rmse_score_fn: 0.2849 - val_loss: 195.2864 - val_root_mean_squared_error: 13.9745 - val_exp_rmse_score_fn: 0.2472\n",
            "Epoch 5/10000\n",
            "1/1 [==============================] - 1s 570ms/step - loss: 156.8163 - root_mean_squared_error: 12.5226 - exp_rmse_score_fn: 0.2859 - val_loss: 194.4827 - val_root_mean_squared_error: 13.9457 - val_exp_rmse_score_fn: 0.2479\n",
            "Epoch 6/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 156.0137 - root_mean_squared_error: 12.4905 - exp_rmse_score_fn: 0.2868 - val_loss: 193.7279 - val_root_mean_squared_error: 13.9186 - val_exp_rmse_score_fn: 0.2486\n",
            "Epoch 7/10000\n",
            "1/1 [==============================] - 1s 584ms/step - loss: 155.2578 - root_mean_squared_error: 12.4602 - exp_rmse_score_fn: 0.2876 - val_loss: 193.0190 - val_root_mean_squared_error: 13.8931 - val_exp_rmse_score_fn: 0.2492\n",
            "Epoch 8/10000\n",
            "1/1 [==============================] - 1s 548ms/step - loss: 154.5466 - root_mean_squared_error: 12.4317 - exp_rmse_score_fn: 0.2885 - val_loss: 192.3128 - val_root_mean_squared_error: 13.8677 - val_exp_rmse_score_fn: 0.2499\n",
            "Epoch 9/10000\n",
            "1/1 [==============================] - 1s 553ms/step - loss: 153.8392 - root_mean_squared_error: 12.4032 - exp_rmse_score_fn: 0.2893 - val_loss: 191.6095 - val_root_mean_squared_error: 13.8423 - val_exp_rmse_score_fn: 0.2505\n",
            "Epoch 10/10000\n",
            "1/1 [==============================] - 1s 591ms/step - loss: 153.1354 - root_mean_squared_error: 12.3748 - exp_rmse_score_fn: 0.2901 - val_loss: 190.9030 - val_root_mean_squared_error: 13.8168 - val_exp_rmse_score_fn: 0.2512\n",
            "Epoch 11/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 152.4289 - root_mean_squared_error: 12.3462 - exp_rmse_score_fn: 0.2909 - val_loss: 190.1818 - val_root_mean_squared_error: 13.7906 - val_exp_rmse_score_fn: 0.2518\n",
            "Epoch 12/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 151.7088 - root_mean_squared_error: 12.3170 - exp_rmse_score_fn: 0.2918 - val_loss: 189.4248 - val_root_mean_squared_error: 13.7632 - val_exp_rmse_score_fn: 0.2525\n",
            "Epoch 13/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 150.9576 - root_mean_squared_error: 12.2865 - exp_rmse_score_fn: 0.2927 - val_loss: 188.6337 - val_root_mean_squared_error: 13.7344 - val_exp_rmse_score_fn: 0.2532\n",
            "Epoch 14/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 150.1765 - root_mean_squared_error: 12.2547 - exp_rmse_score_fn: 0.2936 - val_loss: 187.7989 - val_root_mean_squared_error: 13.7040 - val_exp_rmse_score_fn: 0.2540\n",
            "Epoch 15/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 149.3574 - root_mean_squared_error: 12.2212 - exp_rmse_score_fn: 0.2946 - val_loss: 186.9030 - val_root_mean_squared_error: 13.6712 - val_exp_rmse_score_fn: 0.2548\n",
            "Epoch 16/10000\n",
            "1/1 [==============================] - 1s 552ms/step - loss: 148.4837 - root_mean_squared_error: 12.1854 - exp_rmse_score_fn: 0.2957 - val_loss: 185.9422 - val_root_mean_squared_error: 13.6361 - val_exp_rmse_score_fn: 0.2557\n",
            "Epoch 17/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 147.5514 - root_mean_squared_error: 12.1471 - exp_rmse_score_fn: 0.2968 - val_loss: 184.9177 - val_root_mean_squared_error: 13.5984 - val_exp_rmse_score_fn: 0.2567\n",
            "Epoch 18/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 146.5620 - root_mean_squared_error: 12.1063 - exp_rmse_score_fn: 0.2980 - val_loss: 183.8269 - val_root_mean_squared_error: 13.5583 - val_exp_rmse_score_fn: 0.2577\n",
            "Epoch 19/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 145.5117 - root_mean_squared_error: 12.0628 - exp_rmse_score_fn: 0.2993 - val_loss: 182.6745 - val_root_mean_squared_error: 13.5157 - val_exp_rmse_score_fn: 0.2588\n",
            "Epoch 20/10000\n",
            "1/1 [==============================] - 1s 561ms/step - loss: 144.4054 - root_mean_squared_error: 12.0169 - exp_rmse_score_fn: 0.3007 - val_loss: 181.4706 - val_root_mean_squared_error: 13.4711 - val_exp_rmse_score_fn: 0.2600\n",
            "Epoch 21/10000\n",
            "1/1 [==============================] - 1s 553ms/step - loss: 143.2539 - root_mean_squared_error: 11.9689 - exp_rmse_score_fn: 0.3021 - val_loss: 180.2157 - val_root_mean_squared_error: 13.4244 - val_exp_rmse_score_fn: 0.2612\n",
            "Epoch 22/10000\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 142.0573 - root_mean_squared_error: 11.9188 - exp_rmse_score_fn: 0.3037 - val_loss: 178.9066 - val_root_mean_squared_error: 13.3756 - val_exp_rmse_score_fn: 0.2625\n",
            "Epoch 23/10000\n",
            "1/1 [==============================] - 1s 556ms/step - loss: 140.8127 - root_mean_squared_error: 11.8665 - exp_rmse_score_fn: 0.3052 - val_loss: 177.5492 - val_root_mean_squared_error: 13.3248 - val_exp_rmse_score_fn: 0.2638\n",
            "Epoch 24/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 139.5246 - root_mean_squared_error: 11.8121 - exp_rmse_score_fn: 0.3069 - val_loss: 176.1421 - val_root_mean_squared_error: 13.2719 - val_exp_rmse_score_fn: 0.2652\n",
            "Epoch 25/10000\n",
            "1/1 [==============================] - 1s 543ms/step - loss: 138.1902 - root_mean_squared_error: 11.7554 - exp_rmse_score_fn: 0.3087 - val_loss: 174.6960 - val_root_mean_squared_error: 13.2173 - val_exp_rmse_score_fn: 0.2667\n",
            "Epoch 26/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 136.8209 - root_mean_squared_error: 11.6970 - exp_rmse_score_fn: 0.3105 - val_loss: 173.2198 - val_root_mean_squared_error: 13.1613 - val_exp_rmse_score_fn: 0.2682\n",
            "Epoch 27/10000\n",
            "1/1 [==============================] - 1s 562ms/step - loss: 135.4255 - root_mean_squared_error: 11.6372 - exp_rmse_score_fn: 0.3123 - val_loss: 171.7209 - val_root_mean_squared_error: 13.1042 - val_exp_rmse_score_fn: 0.2697\n",
            "Epoch 28/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 134.0102 - root_mean_squared_error: 11.5763 - exp_rmse_score_fn: 0.3142 - val_loss: 170.2104 - val_root_mean_squared_error: 13.0465 - val_exp_rmse_score_fn: 0.2713\n",
            "Epoch 29/10000\n",
            "1/1 [==============================] - 1s 556ms/step - loss: 132.5864 - root_mean_squared_error: 11.5146 - exp_rmse_score_fn: 0.3162 - val_loss: 168.7016 - val_root_mean_squared_error: 12.9885 - val_exp_rmse_score_fn: 0.2728\n",
            "Epoch 30/10000\n",
            "1/1 [==============================] - 1s 562ms/step - loss: 131.1674 - root_mean_squared_error: 11.4528 - exp_rmse_score_fn: 0.3181 - val_loss: 167.2036 - val_root_mean_squared_error: 12.9307 - val_exp_rmse_score_fn: 0.2744\n",
            "Epoch 31/10000\n",
            "1/1 [==============================] - 1s 576ms/step - loss: 129.7613 - root_mean_squared_error: 11.3913 - exp_rmse_score_fn: 0.3201 - val_loss: 165.7364 - val_root_mean_squared_error: 12.8739 - val_exp_rmse_score_fn: 0.2760\n",
            "Epoch 32/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 128.3874 - root_mean_squared_error: 11.3308 - exp_rmse_score_fn: 0.3220 - val_loss: 164.3175 - val_root_mean_squared_error: 12.8186 - val_exp_rmse_score_fn: 0.2775\n",
            "Epoch 33/10000\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 127.0612 - root_mean_squared_error: 11.2721 - exp_rmse_score_fn: 0.3239 - val_loss: 162.9537 - val_root_mean_squared_error: 12.7653 - val_exp_rmse_score_fn: 0.2790\n",
            "Epoch 34/10000\n",
            "1/1 [==============================] - 1s 554ms/step - loss: 125.7897 - root_mean_squared_error: 11.2156 - exp_rmse_score_fn: 0.3258 - val_loss: 161.6631 - val_root_mean_squared_error: 12.7147 - val_exp_rmse_score_fn: 0.2804\n",
            "Epoch 35/10000\n",
            "1/1 [==============================] - 1s 576ms/step - loss: 124.5897 - root_mean_squared_error: 11.1620 - exp_rmse_score_fn: 0.3275 - val_loss: 160.4558 - val_root_mean_squared_error: 12.6671 - val_exp_rmse_score_fn: 0.2818\n",
            "Epoch 36/10000\n",
            "1/1 [==============================] - 1s 559ms/step - loss: 123.4688 - root_mean_squared_error: 11.1117 - exp_rmse_score_fn: 0.3292 - val_loss: 159.3246 - val_root_mean_squared_error: 12.6224 - val_exp_rmse_score_fn: 0.2830\n",
            "Epoch 37/10000\n",
            "1/1 [==============================] - 1s 576ms/step - loss: 122.4210 - root_mean_squared_error: 11.0644 - exp_rmse_score_fn: 0.3307 - val_loss: 158.2645 - val_root_mean_squared_error: 12.5803 - val_exp_rmse_score_fn: 0.2842\n",
            "Epoch 38/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 121.4383 - root_mean_squared_error: 11.0199 - exp_rmse_score_fn: 0.3322 - val_loss: 157.2765 - val_root_mean_squared_error: 12.5410 - val_exp_rmse_score_fn: 0.2853\n",
            "Epoch 39/10000\n",
            "1/1 [==============================] - 1s 555ms/step - loss: 120.5206 - root_mean_squared_error: 10.9782 - exp_rmse_score_fn: 0.3336 - val_loss: 156.3523 - val_root_mean_squared_error: 12.5041 - val_exp_rmse_score_fn: 0.2864\n",
            "Epoch 40/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 119.6603 - root_mean_squared_error: 10.9389 - exp_rmse_score_fn: 0.3349 - val_loss: 155.4644 - val_root_mean_squared_error: 12.4685 - val_exp_rmse_score_fn: 0.2874\n",
            "Epoch 41/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 118.8269 - root_mean_squared_error: 10.9008 - exp_rmse_score_fn: 0.3362 - val_loss: 154.5897 - val_root_mean_squared_error: 12.4334 - val_exp_rmse_score_fn: 0.2884\n",
            "Epoch 42/10000\n",
            "1/1 [==============================] - 1s 583ms/step - loss: 117.9969 - root_mean_squared_error: 10.8626 - exp_rmse_score_fn: 0.3375 - val_loss: 153.7182 - val_root_mean_squared_error: 12.3983 - val_exp_rmse_score_fn: 0.2894\n",
            "Epoch 43/10000\n",
            "1/1 [==============================] - 1s 556ms/step - loss: 117.1624 - root_mean_squared_error: 10.8242 - exp_rmse_score_fn: 0.3388 - val_loss: 152.8422 - val_root_mean_squared_error: 12.3629 - val_exp_rmse_score_fn: 0.2905\n",
            "Epoch 44/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 116.3169 - root_mean_squared_error: 10.7850 - exp_rmse_score_fn: 0.3401 - val_loss: 151.9667 - val_root_mean_squared_error: 12.3275 - val_exp_rmse_score_fn: 0.2915\n",
            "Epoch 45/10000\n",
            "1/1 [==============================] - 1s 558ms/step - loss: 115.4637 - root_mean_squared_error: 10.7454 - exp_rmse_score_fn: 0.3415 - val_loss: 151.0916 - val_root_mean_squared_error: 12.2919 - val_exp_rmse_score_fn: 0.2925\n",
            "Epoch 46/10000\n",
            "1/1 [==============================] - 1s 549ms/step - loss: 114.6080 - root_mean_squared_error: 10.7055 - exp_rmse_score_fn: 0.3428 - val_loss: 150.2077 - val_root_mean_squared_error: 12.2559 - val_exp_rmse_score_fn: 0.2936\n",
            "Epoch 47/10000\n",
            "1/1 [==============================] - 1s 583ms/step - loss: 113.7419 - root_mean_squared_error: 10.6650 - exp_rmse_score_fn: 0.3442 - val_loss: 149.3255 - val_root_mean_squared_error: 12.2199 - val_exp_rmse_score_fn: 0.2946\n",
            "Epoch 48/10000\n",
            "1/1 [==============================] - 1s 545ms/step - loss: 112.8790 - root_mean_squared_error: 10.6245 - exp_rmse_score_fn: 0.3456 - val_loss: 148.4516 - val_root_mean_squared_error: 12.1841 - val_exp_rmse_score_fn: 0.2957\n",
            "Epoch 49/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 112.0265 - root_mean_squared_error: 10.5843 - exp_rmse_score_fn: 0.3470 - val_loss: 147.5936 - val_root_mean_squared_error: 12.1488 - val_exp_rmse_score_fn: 0.2967\n",
            "Epoch 50/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 111.1945 - root_mean_squared_error: 10.5449 - exp_rmse_score_fn: 0.3484 - val_loss: 146.7760 - val_root_mean_squared_error: 12.1151 - val_exp_rmse_score_fn: 0.2977\n",
            "Epoch 51/10000\n",
            "1/1 [==============================] - 1s 583ms/step - loss: 110.4108 - root_mean_squared_error: 10.5077 - exp_rmse_score_fn: 0.3497 - val_loss: 146.0113 - val_root_mean_squared_error: 12.0835 - val_exp_rmse_score_fn: 0.2987\n",
            "Epoch 52/10000\n",
            "1/1 [==============================] - 1s 561ms/step - loss: 109.6879 - root_mean_squared_error: 10.4732 - exp_rmse_score_fn: 0.3509 - val_loss: 145.2985 - val_root_mean_squared_error: 12.0540 - val_exp_rmse_score_fn: 0.2996\n",
            "Epoch 53/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 109.0296 - root_mean_squared_error: 10.4417 - exp_rmse_score_fn: 0.3520 - val_loss: 144.6121 - val_root_mean_squared_error: 12.0255 - val_exp_rmse_score_fn: 0.3004\n",
            "Epoch 54/10000\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 108.4101 - root_mean_squared_error: 10.4120 - exp_rmse_score_fn: 0.3530 - val_loss: 143.9427 - val_root_mean_squared_error: 11.9976 - val_exp_rmse_score_fn: 0.3013\n",
            "Epoch 55/10000\n",
            "1/1 [==============================] - 1s 561ms/step - loss: 107.8184 - root_mean_squared_error: 10.3836 - exp_rmse_score_fn: 0.3540 - val_loss: 143.2867 - val_root_mean_squared_error: 11.9702 - val_exp_rmse_score_fn: 0.3021\n",
            "Epoch 56/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 107.2503 - root_mean_squared_error: 10.3562 - exp_rmse_score_fn: 0.3550 - val_loss: 142.6481 - val_root_mean_squared_error: 11.9435 - val_exp_rmse_score_fn: 0.3029\n",
            "Epoch 57/10000\n",
            "1/1 [==============================] - 1s 549ms/step - loss: 106.7068 - root_mean_squared_error: 10.3299 - exp_rmse_score_fn: 0.3559 - val_loss: 142.0216 - val_root_mean_squared_error: 11.9173 - val_exp_rmse_score_fn: 0.3037\n",
            "Epoch 58/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 106.1842 - root_mean_squared_error: 10.3046 - exp_rmse_score_fn: 0.3568 - val_loss: 141.4186 - val_root_mean_squared_error: 11.8920 - val_exp_rmse_score_fn: 0.3045\n",
            "Epoch 59/10000\n",
            "1/1 [==============================] - 1s 555ms/step - loss: 105.6894 - root_mean_squared_error: 10.2805 - exp_rmse_score_fn: 0.3577 - val_loss: 140.8473 - val_root_mean_squared_error: 11.8679 - val_exp_rmse_score_fn: 0.3052\n",
            "Epoch 60/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 105.2249 - root_mean_squared_error: 10.2579 - exp_rmse_score_fn: 0.3585 - val_loss: 140.3096 - val_root_mean_squared_error: 11.8452 - val_exp_rmse_score_fn: 0.3059\n",
            "Epoch 61/10000\n",
            "1/1 [==============================] - 1s 555ms/step - loss: 104.7917 - root_mean_squared_error: 10.2368 - exp_rmse_score_fn: 0.3593 - val_loss: 139.8142 - val_root_mean_squared_error: 11.8243 - val_exp_rmse_score_fn: 0.3065\n",
            "Epoch 62/10000\n",
            "1/1 [==============================] - 1s 553ms/step - loss: 104.3973 - root_mean_squared_error: 10.2175 - exp_rmse_score_fn: 0.3600 - val_loss: 139.3559 - val_root_mean_squared_error: 11.8049 - val_exp_rmse_score_fn: 0.3071\n",
            "Epoch 63/10000\n",
            "1/1 [==============================] - 1s 554ms/step - loss: 104.0340 - root_mean_squared_error: 10.1997 - exp_rmse_score_fn: 0.3606 - val_loss: 138.9229 - val_root_mean_squared_error: 11.7866 - val_exp_rmse_score_fn: 0.3077\n",
            "Epoch 64/10000\n",
            "1/1 [==============================] - 1s 559ms/step - loss: 103.6893 - root_mean_squared_error: 10.1828 - exp_rmse_score_fn: 0.3612 - val_loss: 138.5150 - val_root_mean_squared_error: 11.7692 - val_exp_rmse_score_fn: 0.3082\n",
            "Epoch 65/10000\n",
            "1/1 [==============================] - 1s 585ms/step - loss: 103.3613 - root_mean_squared_error: 10.1667 - exp_rmse_score_fn: 0.3618 - val_loss: 138.1263 - val_root_mean_squared_error: 11.7527 - val_exp_rmse_score_fn: 0.3087\n",
            "Epoch 66/10000\n",
            "1/1 [==============================] - 1s 559ms/step - loss: 103.0411 - root_mean_squared_error: 10.1509 - exp_rmse_score_fn: 0.3624 - val_loss: 137.7445 - val_root_mean_squared_error: 11.7365 - val_exp_rmse_score_fn: 0.3092\n",
            "Epoch 67/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 102.7181 - root_mean_squared_error: 10.1350 - exp_rmse_score_fn: 0.3629 - val_loss: 137.3716 - val_root_mean_squared_error: 11.7206 - val_exp_rmse_score_fn: 0.3097\n",
            "Epoch 68/10000\n",
            "1/1 [==============================] - 1s 562ms/step - loss: 102.3934 - root_mean_squared_error: 10.1190 - exp_rmse_score_fn: 0.3635 - val_loss: 137.0045 - val_root_mean_squared_error: 11.7049 - val_exp_rmse_score_fn: 0.3102\n",
            "Epoch 69/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 102.0656 - root_mean_squared_error: 10.1027 - exp_rmse_score_fn: 0.3641 - val_loss: 136.6446 - val_root_mean_squared_error: 11.6895 - val_exp_rmse_score_fn: 0.3107\n",
            "Epoch 70/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 101.7355 - root_mean_squared_error: 10.0864 - exp_rmse_score_fn: 0.3647 - val_loss: 136.2922 - val_root_mean_squared_error: 11.6744 - val_exp_rmse_score_fn: 0.3112\n",
            "Epoch 71/10000\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 101.4061 - root_mean_squared_error: 10.0701 - exp_rmse_score_fn: 0.3653 - val_loss: 135.9392 - val_root_mean_squared_error: 11.6593 - val_exp_rmse_score_fn: 0.3116\n",
            "Epoch 72/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 101.0744 - root_mean_squared_error: 10.0536 - exp_rmse_score_fn: 0.3659 - val_loss: 135.5984 - val_root_mean_squared_error: 11.6447 - val_exp_rmse_score_fn: 0.3121\n",
            "Epoch 73/10000\n",
            "1/1 [==============================] - 1s 583ms/step - loss: 100.7534 - root_mean_squared_error: 10.0376 - exp_rmse_score_fn: 0.3665 - val_loss: 135.2596 - val_root_mean_squared_error: 11.6301 - val_exp_rmse_score_fn: 0.3125\n",
            "Epoch 74/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 100.4314 - root_mean_squared_error: 10.0215 - exp_rmse_score_fn: 0.3671 - val_loss: 134.9206 - val_root_mean_squared_error: 11.6155 - val_exp_rmse_score_fn: 0.3130\n",
            "Epoch 75/10000\n",
            "1/1 [==============================] - 1s 585ms/step - loss: 100.1056 - root_mean_squared_error: 10.0053 - exp_rmse_score_fn: 0.3677 - val_loss: 134.5741 - val_root_mean_squared_error: 11.6006 - val_exp_rmse_score_fn: 0.3135\n",
            "Epoch 76/10000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 99.7706 - root_mean_squared_error: 9.9885 - exp_rmse_score_fn: 0.3683 - val_loss: 134.2144 - val_root_mean_squared_error: 11.5851 - val_exp_rmse_score_fn: 0.3140\n",
            "Epoch 77/10000\n",
            "1/1 [==============================] - 1s 582ms/step - loss: 99.4239 - root_mean_squared_error: 9.9712 - exp_rmse_score_fn: 0.3689 - val_loss: 133.8404 - val_root_mean_squared_error: 11.5689 - val_exp_rmse_score_fn: 0.3145\n",
            "Epoch 78/10000\n",
            "1/1 [==============================] - 1s 555ms/step - loss: 99.0640 - root_mean_squared_error: 9.9531 - exp_rmse_score_fn: 0.3696 - val_loss: 133.4621 - val_root_mean_squared_error: 11.5526 - val_exp_rmse_score_fn: 0.3150\n",
            "Epoch 79/10000\n",
            "1/1 [==============================] - 1s 571ms/step - loss: 98.7013 - root_mean_squared_error: 9.9349 - exp_rmse_score_fn: 0.3703 - val_loss: 133.0882 - val_root_mean_squared_error: 11.5364 - val_exp_rmse_score_fn: 0.3155\n",
            "Epoch 80/10000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 98.3438 - root_mean_squared_error: 9.9168 - exp_rmse_score_fn: 0.3710 - val_loss: 132.7024 - val_root_mean_squared_error: 11.5197 - val_exp_rmse_score_fn: 0.3160\n",
            "Epoch 81/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 97.9777 - root_mean_squared_error: 9.8984 - exp_rmse_score_fn: 0.3716 - val_loss: 132.3033 - val_root_mean_squared_error: 11.5023 - val_exp_rmse_score_fn: 0.3166\n",
            "Epoch 82/10000\n",
            "1/1 [==============================] - 1s 571ms/step - loss: 97.6025 - root_mean_squared_error: 9.8794 - exp_rmse_score_fn: 0.3723 - val_loss: 131.8920 - val_root_mean_squared_error: 11.4844 - val_exp_rmse_score_fn: 0.3171\n",
            "Epoch 83/10000\n",
            "1/1 [==============================] - 1s 593ms/step - loss: 97.2201 - root_mean_squared_error: 9.8600 - exp_rmse_score_fn: 0.3731 - val_loss: 131.4642 - val_root_mean_squared_error: 11.4658 - val_exp_rmse_score_fn: 0.3177\n",
            "Epoch 84/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 96.8275 - root_mean_squared_error: 9.8401 - exp_rmse_score_fn: 0.3738 - val_loss: 131.0162 - val_root_mean_squared_error: 11.4462 - val_exp_rmse_score_fn: 0.3183\n",
            "Epoch 85/10000\n",
            "1/1 [==============================] - 1s 552ms/step - loss: 96.4184 - root_mean_squared_error: 9.8193 - exp_rmse_score_fn: 0.3746 - val_loss: 130.5502 - val_root_mean_squared_error: 11.4259 - val_exp_rmse_score_fn: 0.3190\n",
            "Epoch 86/10000\n",
            "1/1 [==============================] - 1s 561ms/step - loss: 95.9914 - root_mean_squared_error: 9.7975 - exp_rmse_score_fn: 0.3754 - val_loss: 130.0819 - val_root_mean_squared_error: 11.4053 - val_exp_rmse_score_fn: 0.3196\n",
            "Epoch 87/10000\n",
            "1/1 [==============================] - 1s 552ms/step - loss: 95.5630 - root_mean_squared_error: 9.7756 - exp_rmse_score_fn: 0.3762 - val_loss: 129.5937 - val_root_mean_squared_error: 11.3839 - val_exp_rmse_score_fn: 0.3203\n",
            "Epoch 88/10000\n",
            "1/1 [==============================] - 1s 561ms/step - loss: 95.1179 - root_mean_squared_error: 9.7528 - exp_rmse_score_fn: 0.3771 - val_loss: 129.0813 - val_root_mean_squared_error: 11.3614 - val_exp_rmse_score_fn: 0.3211\n",
            "Epoch 89/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 94.6510 - root_mean_squared_error: 9.7289 - exp_rmse_score_fn: 0.3780 - val_loss: 128.5465 - val_root_mean_squared_error: 11.3378 - val_exp_rmse_score_fn: 0.3218\n",
            "Epoch 90/10000\n",
            "1/1 [==============================] - 1s 561ms/step - loss: 94.1647 - root_mean_squared_error: 9.7038 - exp_rmse_score_fn: 0.3789 - val_loss: 127.9904 - val_root_mean_squared_error: 11.3133 - val_exp_rmse_score_fn: 0.3226\n",
            "Epoch 91/10000\n",
            "1/1 [==============================] - 1s 548ms/step - loss: 93.6632 - root_mean_squared_error: 9.6780 - exp_rmse_score_fn: 0.3799 - val_loss: 127.4131 - val_root_mean_squared_error: 11.2877 - val_exp_rmse_score_fn: 0.3234\n",
            "Epoch 92/10000\n",
            "1/1 [==============================] - 1s 553ms/step - loss: 93.1461 - root_mean_squared_error: 9.6512 - exp_rmse_score_fn: 0.3809 - val_loss: 126.8320 - val_root_mean_squared_error: 11.2620 - val_exp_rmse_score_fn: 0.3243\n",
            "Epoch 93/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 92.6269 - root_mean_squared_error: 9.6243 - exp_rmse_score_fn: 0.3820 - val_loss: 126.2335 - val_root_mean_squared_error: 11.2354 - val_exp_rmse_score_fn: 0.3251\n",
            "Epoch 94/10000\n",
            "1/1 [==============================] - 1s 548ms/step - loss: 92.0917 - root_mean_squared_error: 9.5964 - exp_rmse_score_fn: 0.3830 - val_loss: 125.6214 - val_root_mean_squared_error: 11.2081 - val_exp_rmse_score_fn: 0.3260\n",
            "Epoch 95/10000\n",
            "1/1 [==============================] - 1s 552ms/step - loss: 91.5421 - root_mean_squared_error: 9.5678 - exp_rmse_score_fn: 0.3841 - val_loss: 124.9951 - val_root_mean_squared_error: 11.1801 - val_exp_rmse_score_fn: 0.3269\n",
            "Epoch 96/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 90.9718 - root_mean_squared_error: 9.5379 - exp_rmse_score_fn: 0.3853 - val_loss: 124.3469 - val_root_mean_squared_error: 11.1511 - val_exp_rmse_score_fn: 0.3279\n",
            "Epoch 97/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 90.3800 - root_mean_squared_error: 9.5068 - exp_rmse_score_fn: 0.3865 - val_loss: 123.6743 - val_root_mean_squared_error: 11.1209 - val_exp_rmse_score_fn: 0.3289\n",
            "Epoch 98/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 89.7714 - root_mean_squared_error: 9.4748 - exp_rmse_score_fn: 0.3877 - val_loss: 122.9697 - val_root_mean_squared_error: 11.0892 - val_exp_rmse_score_fn: 0.3299\n",
            "Epoch 99/10000\n",
            "1/1 [==============================] - 1s 554ms/step - loss: 89.1373 - root_mean_squared_error: 9.4413 - exp_rmse_score_fn: 0.3890 - val_loss: 122.2398 - val_root_mean_squared_error: 11.0562 - val_exp_rmse_score_fn: 0.3310\n",
            "Epoch 100/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 88.4890 - root_mean_squared_error: 9.4069 - exp_rmse_score_fn: 0.3904 - val_loss: 121.4743 - val_root_mean_squared_error: 11.0215 - val_exp_rmse_score_fn: 0.3322\n",
            "Epoch 101/10000\n",
            "1/1 [==============================] - 1s 578ms/step - loss: 87.8192 - root_mean_squared_error: 9.3712 - exp_rmse_score_fn: 0.3918 - val_loss: 120.6937 - val_root_mean_squared_error: 10.9861 - val_exp_rmse_score_fn: 0.3333\n",
            "Epoch 102/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 87.1378 - root_mean_squared_error: 9.3348 - exp_rmse_score_fn: 0.3932 - val_loss: 119.8854 - val_root_mean_squared_error: 10.9492 - val_exp_rmse_score_fn: 0.3346\n",
            "Epoch 103/10000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 86.4399 - root_mean_squared_error: 9.2973 - exp_rmse_score_fn: 0.3947 - val_loss: 119.0568 - val_root_mean_squared_error: 10.9113 - val_exp_rmse_score_fn: 0.3358\n",
            "Epoch 104/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 85.7215 - root_mean_squared_error: 9.2586 - exp_rmse_score_fn: 0.3962 - val_loss: 118.2118 - val_root_mean_squared_error: 10.8725 - val_exp_rmse_score_fn: 0.3371\n",
            "Epoch 105/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 84.9797 - root_mean_squared_error: 9.2184 - exp_rmse_score_fn: 0.3978 - val_loss: 117.3709 - val_root_mean_squared_error: 10.8338 - val_exp_rmse_score_fn: 0.3385\n",
            "Epoch 106/10000\n",
            "1/1 [==============================] - 1s 558ms/step - loss: 84.2361 - root_mean_squared_error: 9.1780 - exp_rmse_score_fn: 0.3994 - val_loss: 116.5344 - val_root_mean_squared_error: 10.7951 - val_exp_rmse_score_fn: 0.3398\n",
            "Epoch 107/10000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 83.4905 - root_mean_squared_error: 9.1373 - exp_rmse_score_fn: 0.4010 - val_loss: 115.6800 - val_root_mean_squared_error: 10.7555 - val_exp_rmse_score_fn: 0.3411\n",
            "Epoch 108/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 82.7252 - root_mean_squared_error: 9.0953 - exp_rmse_score_fn: 0.4027 - val_loss: 114.8063 - val_root_mean_squared_error: 10.7148 - val_exp_rmse_score_fn: 0.3425\n",
            "Epoch 109/10000\n",
            "1/1 [==============================] - 1s 553ms/step - loss: 81.9436 - root_mean_squared_error: 9.0523 - exp_rmse_score_fn: 0.4045 - val_loss: 113.9109 - val_root_mean_squared_error: 10.6729 - val_exp_rmse_score_fn: 0.3439\n",
            "Epoch 110/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 81.1546 - root_mean_squared_error: 9.0086 - exp_rmse_score_fn: 0.4062 - val_loss: 113.0049 - val_root_mean_squared_error: 10.6304 - val_exp_rmse_score_fn: 0.3454\n",
            "Epoch 111/10000\n",
            "1/1 [==============================] - 1s 558ms/step - loss: 80.3576 - root_mean_squared_error: 8.9642 - exp_rmse_score_fn: 0.4080 - val_loss: 112.1040 - val_root_mean_squared_error: 10.5879 - val_exp_rmse_score_fn: 0.3469\n",
            "Epoch 112/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 79.5601 - root_mean_squared_error: 8.9196 - exp_rmse_score_fn: 0.4098 - val_loss: 111.1920 - val_root_mean_squared_error: 10.5448 - val_exp_rmse_score_fn: 0.3484\n",
            "Epoch 113/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 78.7594 - root_mean_squared_error: 8.8747 - exp_rmse_score_fn: 0.4117 - val_loss: 110.2760 - val_root_mean_squared_error: 10.5012 - val_exp_rmse_score_fn: 0.3499\n",
            "Epoch 114/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 77.9601 - root_mean_squared_error: 8.8295 - exp_rmse_score_fn: 0.4136 - val_loss: 109.3627 - val_root_mean_squared_error: 10.4577 - val_exp_rmse_score_fn: 0.3514\n",
            "Epoch 115/10000\n",
            "1/1 [==============================] - 1s 558ms/step - loss: 77.1700 - root_mean_squared_error: 8.7846 - exp_rmse_score_fn: 0.4154 - val_loss: 108.4368 - val_root_mean_squared_error: 10.4133 - val_exp_rmse_score_fn: 0.3530\n",
            "Epoch 116/10000\n",
            "1/1 [==============================] - 1s 577ms/step - loss: 76.3839 - root_mean_squared_error: 8.7398 - exp_rmse_score_fn: 0.4173 - val_loss: 107.5022 - val_root_mean_squared_error: 10.3683 - val_exp_rmse_score_fn: 0.3546\n",
            "Epoch 117/10000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 75.6028 - root_mean_squared_error: 8.6950 - exp_rmse_score_fn: 0.4192 - val_loss: 106.5958 - val_root_mean_squared_error: 10.3245 - val_exp_rmse_score_fn: 0.3561\n",
            "Epoch 118/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 74.8383 - root_mean_squared_error: 8.6509 - exp_rmse_score_fn: 0.4210 - val_loss: 105.7289 - val_root_mean_squared_error: 10.2825 - val_exp_rmse_score_fn: 0.3576\n",
            "Epoch 119/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 74.0951 - root_mean_squared_error: 8.6078 - exp_rmse_score_fn: 0.4228 - val_loss: 104.8661 - val_root_mean_squared_error: 10.2404 - val_exp_rmse_score_fn: 0.3591\n",
            "Epoch 120/10000\n",
            "1/1 [==============================] - 1s 584ms/step - loss: 73.3659 - root_mean_squared_error: 8.5654 - exp_rmse_score_fn: 0.4246 - val_loss: 104.0215 - val_root_mean_squared_error: 10.1991 - val_exp_rmse_score_fn: 0.3606\n",
            "Epoch 121/10000\n",
            "1/1 [==============================] - 1s 546ms/step - loss: 72.6513 - root_mean_squared_error: 8.5236 - exp_rmse_score_fn: 0.4264 - val_loss: 103.2162 - val_root_mean_squared_error: 10.1595 - val_exp_rmse_score_fn: 0.3621\n",
            "Epoch 122/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 71.9688 - root_mean_squared_error: 8.4834 - exp_rmse_score_fn: 0.4281 - val_loss: 102.4359 - val_root_mean_squared_error: 10.1211 - val_exp_rmse_score_fn: 0.3635\n",
            "Epoch 123/10000\n",
            "1/1 [==============================] - 1s 562ms/step - loss: 71.3029 - root_mean_squared_error: 8.4441 - exp_rmse_score_fn: 0.4298 - val_loss: 101.6325 - val_root_mean_squared_error: 10.0813 - val_exp_rmse_score_fn: 0.3649\n",
            "Epoch 124/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 70.6646 - root_mean_squared_error: 8.4062 - exp_rmse_score_fn: 0.4314 - val_loss: 100.8820 - val_root_mean_squared_error: 10.0440 - val_exp_rmse_score_fn: 0.3663\n",
            "Epoch 125/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 70.0453 - root_mean_squared_error: 8.3693 - exp_rmse_score_fn: 0.4330 - val_loss: 100.1550 - val_root_mean_squared_error: 10.0077 - val_exp_rmse_score_fn: 0.3676\n",
            "Epoch 126/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 69.4635 - root_mean_squared_error: 8.3345 - exp_rmse_score_fn: 0.4345 - val_loss: 99.4520 - val_root_mean_squared_error: 9.9726 - val_exp_rmse_score_fn: 0.3689\n",
            "Epoch 127/10000\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 68.9092 - root_mean_squared_error: 8.3012 - exp_rmse_score_fn: 0.4360 - val_loss: 98.8375 - val_root_mean_squared_error: 9.9417 - val_exp_rmse_score_fn: 0.3700\n",
            "Epoch 128/10000\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 68.3945 - root_mean_squared_error: 8.2701 - exp_rmse_score_fn: 0.4374 - val_loss: 98.2377 - val_root_mean_squared_error: 9.9115 - val_exp_rmse_score_fn: 0.3711\n",
            "Epoch 129/10000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 67.9055 - root_mean_squared_error: 8.2405 - exp_rmse_score_fn: 0.4387 - val_loss: 97.6525 - val_root_mean_squared_error: 9.8819 - val_exp_rmse_score_fn: 0.3722\n",
            "Epoch 130/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 67.4403 - root_mean_squared_error: 8.2122 - exp_rmse_score_fn: 0.4399 - val_loss: 97.1469 - val_root_mean_squared_error: 9.8563 - val_exp_rmse_score_fn: 0.3732\n",
            "Epoch 131/10000\n",
            "1/1 [==============================] - 1s 559ms/step - loss: 67.0112 - root_mean_squared_error: 8.1860 - exp_rmse_score_fn: 0.4410 - val_loss: 96.6289 - val_root_mean_squared_error: 9.8300 - val_exp_rmse_score_fn: 0.3742\n",
            "Epoch 132/10000\n",
            "1/1 [==============================] - 1s 570ms/step - loss: 66.5922 - root_mean_squared_error: 8.1604 - exp_rmse_score_fn: 0.4422 - val_loss: 96.1395 - val_root_mean_squared_error: 9.8051 - val_exp_rmse_score_fn: 0.3751\n",
            "Epoch 133/10000\n",
            "1/1 [==============================] - 1s 570ms/step - loss: 66.1929 - root_mean_squared_error: 8.1359 - exp_rmse_score_fn: 0.4433 - val_loss: 95.6913 - val_root_mean_squared_error: 9.7822 - val_exp_rmse_score_fn: 0.3760\n",
            "Epoch 134/10000\n",
            "1/1 [==============================] - 1s 554ms/step - loss: 65.8003 - root_mean_squared_error: 8.1117 - exp_rmse_score_fn: 0.4443 - val_loss: 95.2674 - val_root_mean_squared_error: 9.7605 - val_exp_rmse_score_fn: 0.3768\n",
            "Epoch 135/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 65.4329 - root_mean_squared_error: 8.0891 - exp_rmse_score_fn: 0.4453 - val_loss: 94.8542 - val_root_mean_squared_error: 9.7393 - val_exp_rmse_score_fn: 0.3776\n",
            "Epoch 136/10000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 65.0924 - root_mean_squared_error: 8.0680 - exp_rmse_score_fn: 0.4463 - val_loss: 94.3939 - val_root_mean_squared_error: 9.7157 - val_exp_rmse_score_fn: 0.3785\n",
            "Epoch 137/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 64.7401 - root_mean_squared_error: 8.0461 - exp_rmse_score_fn: 0.4473 - val_loss: 94.0091 - val_root_mean_squared_error: 9.6958 - val_exp_rmse_score_fn: 0.3792\n",
            "Epoch 138/10000\n",
            "1/1 [==============================] - 1s 577ms/step - loss: 64.4027 - root_mean_squared_error: 8.0251 - exp_rmse_score_fn: 0.4482 - val_loss: 93.6767 - val_root_mean_squared_error: 9.6787 - val_exp_rmse_score_fn: 0.3799\n",
            "Epoch 139/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 64.0836 - root_mean_squared_error: 8.0052 - exp_rmse_score_fn: 0.4491 - val_loss: 93.2652 - val_root_mean_squared_error: 9.6574 - val_exp_rmse_score_fn: 0.3807\n",
            "Epoch 140/10000\n",
            "1/1 [==============================] - 1s 552ms/step - loss: 63.7621 - root_mean_squared_error: 7.9851 - exp_rmse_score_fn: 0.4500 - val_loss: 92.8618 - val_root_mean_squared_error: 9.6365 - val_exp_rmse_score_fn: 0.3815\n",
            "Epoch 141/10000\n",
            "1/1 [==============================] - 1s 584ms/step - loss: 63.4311 - root_mean_squared_error: 7.9644 - exp_rmse_score_fn: 0.4509 - val_loss: 92.4926 - val_root_mean_squared_error: 9.6173 - val_exp_rmse_score_fn: 0.3822\n",
            "Epoch 142/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 63.1087 - root_mean_squared_error: 7.9441 - exp_rmse_score_fn: 0.4518 - val_loss: 92.0875 - val_root_mean_squared_error: 9.5962 - val_exp_rmse_score_fn: 0.3830\n",
            "Epoch 143/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 62.7997 - root_mean_squared_error: 7.9246 - exp_rmse_score_fn: 0.4527 - val_loss: 91.7153 - val_root_mean_squared_error: 9.5768 - val_exp_rmse_score_fn: 0.3838\n",
            "Epoch 144/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 62.5064 - root_mean_squared_error: 7.9061 - exp_rmse_score_fn: 0.4536 - val_loss: 91.4123 - val_root_mean_squared_error: 9.5610 - val_exp_rmse_score_fn: 0.3844\n",
            "Epoch 145/10000\n",
            "1/1 [==============================] - 1s 571ms/step - loss: 62.2050 - root_mean_squared_error: 7.8870 - exp_rmse_score_fn: 0.4544 - val_loss: 91.0324 - val_root_mean_squared_error: 9.5411 - val_exp_rmse_score_fn: 0.3852\n",
            "Epoch 146/10000\n",
            "1/1 [==============================] - 1s 553ms/step - loss: 61.8999 - root_mean_squared_error: 7.8677 - exp_rmse_score_fn: 0.4553 - val_loss: 90.6751 - val_root_mean_squared_error: 9.5223 - val_exp_rmse_score_fn: 0.3859\n",
            "Epoch 147/10000\n",
            "1/1 [==============================] - 1s 559ms/step - loss: 61.6131 - root_mean_squared_error: 7.8494 - exp_rmse_score_fn: 0.4561 - val_loss: 90.4031 - val_root_mean_squared_error: 9.5081 - val_exp_rmse_score_fn: 0.3864\n",
            "Epoch 148/10000\n",
            "1/1 [==============================] - 1s 554ms/step - loss: 61.3268 - root_mean_squared_error: 7.8311 - exp_rmse_score_fn: 0.4570 - val_loss: 90.0516 - val_root_mean_squared_error: 9.4896 - val_exp_rmse_score_fn: 0.3871\n",
            "Epoch 149/10000\n",
            "1/1 [==============================] - 1s 571ms/step - loss: 61.0490 - root_mean_squared_error: 7.8134 - exp_rmse_score_fn: 0.4578 - val_loss: 89.7344 - val_root_mean_squared_error: 9.4728 - val_exp_rmse_score_fn: 0.3878\n",
            "Epoch 150/10000\n",
            "1/1 [==============================] - 1s 554ms/step - loss: 60.7815 - root_mean_squared_error: 7.7962 - exp_rmse_score_fn: 0.4586 - val_loss: 89.4690 - val_root_mean_squared_error: 9.4588 - val_exp_rmse_score_fn: 0.3883\n",
            "Epoch 151/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 60.5139 - root_mean_squared_error: 7.7791 - exp_rmse_score_fn: 0.4594 - val_loss: 89.2025 - val_root_mean_squared_error: 9.4447 - val_exp_rmse_score_fn: 0.3889\n",
            "Epoch 152/10000\n",
            "1/1 [==============================] - 1s 559ms/step - loss: 60.2597 - root_mean_squared_error: 7.7627 - exp_rmse_score_fn: 0.4601 - val_loss: 88.9167 - val_root_mean_squared_error: 9.4296 - val_exp_rmse_score_fn: 0.3895\n",
            "Epoch 153/10000\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 60.0161 - root_mean_squared_error: 7.7470 - exp_rmse_score_fn: 0.4608 - val_loss: 88.6668 - val_root_mean_squared_error: 9.4163 - val_exp_rmse_score_fn: 0.3900\n",
            "Epoch 154/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 59.7714 - root_mean_squared_error: 7.7312 - exp_rmse_score_fn: 0.4616 - val_loss: 88.3712 - val_root_mean_squared_error: 9.4006 - val_exp_rmse_score_fn: 0.3906\n",
            "Epoch 155/10000\n",
            "1/1 [==============================] - 1s 559ms/step - loss: 59.5329 - root_mean_squared_error: 7.7158 - exp_rmse_score_fn: 0.4623 - val_loss: 88.0677 - val_root_mean_squared_error: 9.3844 - val_exp_rmse_score_fn: 0.3912\n",
            "Epoch 156/10000\n",
            "1/1 [==============================] - 1s 582ms/step - loss: 59.3054 - root_mean_squared_error: 7.7010 - exp_rmse_score_fn: 0.4630 - val_loss: 87.8224 - val_root_mean_squared_error: 9.3714 - val_exp_rmse_score_fn: 0.3917\n",
            "Epoch 157/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 59.0819 - root_mean_squared_error: 7.6865 - exp_rmse_score_fn: 0.4636 - val_loss: 87.5549 - val_root_mean_squared_error: 9.3571 - val_exp_rmse_score_fn: 0.3923\n",
            "Epoch 158/10000\n",
            "1/1 [==============================] - 1s 578ms/step - loss: 58.8608 - root_mean_squared_error: 7.6721 - exp_rmse_score_fn: 0.4643 - val_loss: 87.3163 - val_root_mean_squared_error: 9.3443 - val_exp_rmse_score_fn: 0.3928\n",
            "Epoch 159/10000\n",
            "1/1 [==============================] - 1s 554ms/step - loss: 58.6537 - root_mean_squared_error: 7.6586 - exp_rmse_score_fn: 0.4649 - val_loss: 87.0773 - val_root_mean_squared_error: 9.3315 - val_exp_rmse_score_fn: 0.3933\n",
            "Epoch 160/10000\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 58.4414 - root_mean_squared_error: 7.6447 - exp_rmse_score_fn: 0.4656 - val_loss: 86.7898 - val_root_mean_squared_error: 9.3161 - val_exp_rmse_score_fn: 0.3939\n",
            "Epoch 161/10000\n",
            "1/1 [==============================] - 1s 558ms/step - loss: 58.2384 - root_mean_squared_error: 7.6314 - exp_rmse_score_fn: 0.4662 - val_loss: 86.5833 - val_root_mean_squared_error: 9.3050 - val_exp_rmse_score_fn: 0.3944\n",
            "Epoch 162/10000\n",
            "1/1 [==============================] - 1s 556ms/step - loss: 58.0446 - root_mean_squared_error: 7.6187 - exp_rmse_score_fn: 0.4668 - val_loss: 86.3124 - val_root_mean_squared_error: 9.2904 - val_exp_rmse_score_fn: 0.3949\n",
            "Epoch 163/10000\n",
            "1/1 [==============================] - 1s 586ms/step - loss: 57.8586 - root_mean_squared_error: 7.6065 - exp_rmse_score_fn: 0.4674 - val_loss: 86.1257 - val_root_mean_squared_error: 9.2804 - val_exp_rmse_score_fn: 0.3953\n",
            "Epoch 164/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 57.6753 - root_mean_squared_error: 7.5944 - exp_rmse_score_fn: 0.4679 - val_loss: 85.8863 - val_root_mean_squared_error: 9.2675 - val_exp_rmse_score_fn: 0.3958\n",
            "Epoch 165/10000\n",
            "1/1 [==============================] - 1s 578ms/step - loss: 57.4963 - root_mean_squared_error: 7.5826 - exp_rmse_score_fn: 0.4685 - val_loss: 85.6411 - val_root_mean_squared_error: 9.2542 - val_exp_rmse_score_fn: 0.3964\n",
            "Epoch 166/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 57.3223 - root_mean_squared_error: 7.5712 - exp_rmse_score_fn: 0.4690 - val_loss: 85.4463 - val_root_mean_squared_error: 9.2437 - val_exp_rmse_score_fn: 0.3968\n",
            "Epoch 167/10000\n",
            "1/1 [==============================] - 1s 585ms/step - loss: 57.1575 - root_mean_squared_error: 7.5603 - exp_rmse_score_fn: 0.4695 - val_loss: 85.1829 - val_root_mean_squared_error: 9.2295 - val_exp_rmse_score_fn: 0.3973\n",
            "Epoch 168/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 56.9952 - root_mean_squared_error: 7.5495 - exp_rmse_score_fn: 0.4700 - val_loss: 85.0557 - val_root_mean_squared_error: 9.2226 - val_exp_rmse_score_fn: 0.3976\n",
            "Epoch 169/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 56.8372 - root_mean_squared_error: 7.5390 - exp_rmse_score_fn: 0.4705 - val_loss: 84.7983 - val_root_mean_squared_error: 9.2086 - val_exp_rmse_score_fn: 0.3982\n",
            "Epoch 170/10000\n",
            "1/1 [==============================] - 1s 578ms/step - loss: 56.6864 - root_mean_squared_error: 7.5290 - exp_rmse_score_fn: 0.4710 - val_loss: 84.6571 - val_root_mean_squared_error: 9.2009 - val_exp_rmse_score_fn: 0.3985\n",
            "Epoch 171/10000\n",
            "1/1 [==============================] - 1s 554ms/step - loss: 56.5419 - root_mean_squared_error: 7.5194 - exp_rmse_score_fn: 0.4714 - val_loss: 84.4222 - val_root_mean_squared_error: 9.1882 - val_exp_rmse_score_fn: 0.3990\n",
            "Epoch 172/10000\n",
            "1/1 [==============================] - 1s 587ms/step - loss: 56.3997 - root_mean_squared_error: 7.5100 - exp_rmse_score_fn: 0.4719 - val_loss: 84.2848 - val_root_mean_squared_error: 9.1807 - val_exp_rmse_score_fn: 0.3993\n",
            "Epoch 173/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 56.2584 - root_mean_squared_error: 7.5006 - exp_rmse_score_fn: 0.4723 - val_loss: 84.0672 - val_root_mean_squared_error: 9.1688 - val_exp_rmse_score_fn: 0.3998\n",
            "Epoch 174/10000\n",
            "1/1 [==============================] - 1s 580ms/step - loss: 56.1249 - root_mean_squared_error: 7.4917 - exp_rmse_score_fn: 0.4728 - val_loss: 83.9322 - val_root_mean_squared_error: 9.1615 - val_exp_rmse_score_fn: 0.4001\n",
            "Epoch 175/10000\n",
            "1/1 [==============================] - 1s 558ms/step - loss: 55.9977 - root_mean_squared_error: 7.4832 - exp_rmse_score_fn: 0.4732 - val_loss: 83.7109 - val_root_mean_squared_error: 9.1494 - val_exp_rmse_score_fn: 0.4005\n",
            "Epoch 176/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 55.8736 - root_mean_squared_error: 7.4749 - exp_rmse_score_fn: 0.4736 - val_loss: 83.6879 - val_root_mean_squared_error: 9.1481 - val_exp_rmse_score_fn: 0.4006\n",
            "Epoch 177/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 55.7622 - root_mean_squared_error: 7.4674 - exp_rmse_score_fn: 0.4739 - val_loss: 83.3622 - val_root_mean_squared_error: 9.1303 - val_exp_rmse_score_fn: 0.4013\n",
            "Epoch 178/10000\n",
            "1/1 [==============================] - 1s 582ms/step - loss: 55.6635 - root_mean_squared_error: 7.4608 - exp_rmse_score_fn: 0.4742 - val_loss: 83.5846 - val_root_mean_squared_error: 9.1425 - val_exp_rmse_score_fn: 0.4008\n",
            "Epoch 179/10000\n",
            "1/1 [==============================] - 1s 554ms/step - loss: 55.5921 - root_mean_squared_error: 7.4560 - exp_rmse_score_fn: 0.4744 - val_loss: 83.0205 - val_root_mean_squared_error: 9.1116 - val_exp_rmse_score_fn: 0.4021\n",
            "Epoch 180/10000\n",
            "1/1 [==============================] - 1s 561ms/step - loss: 55.5411 - root_mean_squared_error: 7.4526 - exp_rmse_score_fn: 0.4746 - val_loss: 83.4250 - val_root_mean_squared_error: 9.1337 - val_exp_rmse_score_fn: 0.4012\n",
            "Epoch 181/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 55.4378 - root_mean_squared_error: 7.4457 - exp_rmse_score_fn: 0.4749 - val_loss: 82.8290 - val_root_mean_squared_error: 9.1010 - val_exp_rmse_score_fn: 0.4025\n",
            "Epoch 182/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 55.2613 - root_mean_squared_error: 7.4338 - exp_rmse_score_fn: 0.4755 - val_loss: 82.7283 - val_root_mean_squared_error: 9.0955 - val_exp_rmse_score_fn: 0.4027\n",
            "Epoch 183/10000\n",
            "1/1 [==============================] - 1s 577ms/step - loss: 55.1562 - root_mean_squared_error: 7.4267 - exp_rmse_score_fn: 0.4758 - val_loss: 82.9678 - val_root_mean_squared_error: 9.1087 - val_exp_rmse_score_fn: 0.4022\n",
            "Epoch 184/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 55.1289 - root_mean_squared_error: 7.4249 - exp_rmse_score_fn: 0.4759 - val_loss: 82.4342 - val_root_mean_squared_error: 9.0793 - val_exp_rmse_score_fn: 0.4034\n",
            "Epoch 185/10000\n",
            "1/1 [==============================] - 1s 551ms/step - loss: 55.0289 - root_mean_squared_error: 7.4181 - exp_rmse_score_fn: 0.4762 - val_loss: 82.5213 - val_root_mean_squared_error: 9.0841 - val_exp_rmse_score_fn: 0.4032\n",
            "Epoch 186/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 54.8972 - root_mean_squared_error: 7.4093 - exp_rmse_score_fn: 0.4767 - val_loss: 82.5164 - val_root_mean_squared_error: 9.0839 - val_exp_rmse_score_fn: 0.4032\n",
            "Epoch 187/10000\n",
            "1/1 [==============================] - 1s 570ms/step - loss: 54.8362 - root_mean_squared_error: 7.4051 - exp_rmse_score_fn: 0.4769 - val_loss: 82.1334 - val_root_mean_squared_error: 9.0627 - val_exp_rmse_score_fn: 0.4040\n",
            "Epoch 188/10000\n",
            "1/1 [==============================] - 1s 580ms/step - loss: 54.7893 - root_mean_squared_error: 7.4020 - exp_rmse_score_fn: 0.4770 - val_loss: 82.3152 - val_root_mean_squared_error: 9.0728 - val_exp_rmse_score_fn: 0.4036\n",
            "Epoch 189/10000\n",
            "1/1 [==============================] - 1s 555ms/step - loss: 54.6848 - root_mean_squared_error: 7.3949 - exp_rmse_score_fn: 0.4774 - val_loss: 82.0944 - val_root_mean_squared_error: 9.0606 - val_exp_rmse_score_fn: 0.4041\n",
            "Epoch 190/10000\n",
            "1/1 [==============================] - 1s 553ms/step - loss: 54.5888 - root_mean_squared_error: 7.3884 - exp_rmse_score_fn: 0.4777 - val_loss: 81.8717 - val_root_mean_squared_error: 9.0483 - val_exp_rmse_score_fn: 0.4046\n",
            "Epoch 191/10000\n",
            "1/1 [==============================] - 1s 576ms/step - loss: 54.5438 - root_mean_squared_error: 7.3854 - exp_rmse_score_fn: 0.4778 - val_loss: 82.0747 - val_root_mean_squared_error: 9.0595 - val_exp_rmse_score_fn: 0.4042\n",
            "Epoch 192/10000\n",
            "1/1 [==============================] - 1s 584ms/step - loss: 54.4848 - root_mean_squared_error: 7.3814 - exp_rmse_score_fn: 0.4780 - val_loss: 81.7430 - val_root_mean_squared_error: 9.0412 - val_exp_rmse_score_fn: 0.4049\n",
            "Epoch 193/10000\n",
            "1/1 [==============================] - 1s 578ms/step - loss: 54.3934 - root_mean_squared_error: 7.3752 - exp_rmse_score_fn: 0.4783 - val_loss: 81.6981 - val_root_mean_squared_error: 9.0387 - val_exp_rmse_score_fn: 0.4050\n",
            "Epoch 194/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 54.3211 - root_mean_squared_error: 7.3703 - exp_rmse_score_fn: 0.4785 - val_loss: 81.7712 - val_root_mean_squared_error: 9.0427 - val_exp_rmse_score_fn: 0.4048\n",
            "Epoch 195/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 54.2771 - root_mean_squared_error: 7.3673 - exp_rmse_score_fn: 0.4787 - val_loss: 81.4761 - val_root_mean_squared_error: 9.0264 - val_exp_rmse_score_fn: 0.4055\n",
            "Epoch 196/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 54.2190 - root_mean_squared_error: 7.3634 - exp_rmse_score_fn: 0.4789 - val_loss: 81.5806 - val_root_mean_squared_error: 9.0322 - val_exp_rmse_score_fn: 0.4053\n",
            "Epoch 197/10000\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 54.1438 - root_mean_squared_error: 7.3582 - exp_rmse_score_fn: 0.4791 - val_loss: 81.4711 - val_root_mean_squared_error: 9.0261 - val_exp_rmse_score_fn: 0.4055\n",
            "Epoch 198/10000\n",
            "1/1 [==============================] - 1s 555ms/step - loss: 54.0811 - root_mean_squared_error: 7.3540 - exp_rmse_score_fn: 0.4793 - val_loss: 81.3073 - val_root_mean_squared_error: 9.0171 - val_exp_rmse_score_fn: 0.4059\n",
            "Epoch 199/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 54.0409 - root_mean_squared_error: 7.3513 - exp_rmse_score_fn: 0.4794 - val_loss: 81.4703 - val_root_mean_squared_error: 9.0261 - val_exp_rmse_score_fn: 0.4055\n",
            "Epoch 200/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 54.0038 - root_mean_squared_error: 7.3487 - exp_rmse_score_fn: 0.4796 - val_loss: 81.1813 - val_root_mean_squared_error: 9.0101 - val_exp_rmse_score_fn: 0.4062\n",
            "Epoch 201/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 53.9441 - root_mean_squared_error: 7.3447 - exp_rmse_score_fn: 0.4798 - val_loss: 81.2301 - val_root_mean_squared_error: 9.0128 - val_exp_rmse_score_fn: 0.4061\n",
            "Epoch 202/10000\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 53.8797 - root_mean_squared_error: 7.3403 - exp_rmse_score_fn: 0.4800 - val_loss: 81.1773 - val_root_mean_squared_error: 9.0098 - val_exp_rmse_score_fn: 0.4062\n",
            "Epoch 203/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 53.8342 - root_mean_squared_error: 7.3372 - exp_rmse_score_fn: 0.4801 - val_loss: 81.0022 - val_root_mean_squared_error: 9.0001 - val_exp_rmse_score_fn: 0.4066\n",
            "Epoch 204/10000\n",
            "1/1 [==============================] - 1s 546ms/step - loss: 53.8008 - root_mean_squared_error: 7.3349 - exp_rmse_score_fn: 0.4802 - val_loss: 81.1521 - val_root_mean_squared_error: 9.0084 - val_exp_rmse_score_fn: 0.4062\n",
            "Epoch 205/10000\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 53.7646 - root_mean_squared_error: 7.3324 - exp_rmse_score_fn: 0.4803 - val_loss: 80.9055 - val_root_mean_squared_error: 8.9947 - val_exp_rmse_score_fn: 0.4068\n",
            "Epoch 206/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 53.7165 - root_mean_squared_error: 7.3292 - exp_rmse_score_fn: 0.4805 - val_loss: 80.9739 - val_root_mean_squared_error: 8.9986 - val_exp_rmse_score_fn: 0.4066\n",
            "Epoch 207/10000\n",
            "1/1 [==============================] - 1s 583ms/step - loss: 53.6672 - root_mean_squared_error: 7.3258 - exp_rmse_score_fn: 0.4807 - val_loss: 80.8903 - val_root_mean_squared_error: 8.9939 - val_exp_rmse_score_fn: 0.4068\n",
            "Epoch 208/10000\n",
            "1/1 [==============================] - 1s 582ms/step - loss: 53.6266 - root_mean_squared_error: 7.3230 - exp_rmse_score_fn: 0.4808 - val_loss: 80.7787 - val_root_mean_squared_error: 8.9877 - val_exp_rmse_score_fn: 0.4071\n",
            "Epoch 209/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 53.5954 - root_mean_squared_error: 7.3209 - exp_rmse_score_fn: 0.4809 - val_loss: 80.8792 - val_root_mean_squared_error: 8.9933 - val_exp_rmse_score_fn: 0.4068\n",
            "Epoch 210/10000\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 53.5667 - root_mean_squared_error: 7.3189 - exp_rmse_score_fn: 0.4810 - val_loss: 80.6588 - val_root_mean_squared_error: 8.9810 - val_exp_rmse_score_fn: 0.4073\n",
            "Epoch 211/10000\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 53.5346 - root_mean_squared_error: 7.3167 - exp_rmse_score_fn: 0.4811 - val_loss: 80.7769 - val_root_mean_squared_error: 8.9876 - val_exp_rmse_score_fn: 0.4071\n",
            "Epoch 212/10000\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 53.4978 - root_mean_squared_error: 7.3142 - exp_rmse_score_fn: 0.4812 - val_loss: 80.5775 - val_root_mean_squared_error: 8.9765 - val_exp_rmse_score_fn: 0.4075\n",
            "Epoch 213/10000\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 53.4602 - root_mean_squared_error: 7.3116 - exp_rmse_score_fn: 0.4813 - val_loss: 80.6229 - val_root_mean_squared_error: 8.9790 - val_exp_rmse_score_fn: 0.4074\n",
            "Epoch 214/10000\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 53.4254 - root_mean_squared_error: 7.3093 - exp_rmse_score_fn: 0.4815 - val_loss: 80.5530 - val_root_mean_squared_error: 8.9751 - val_exp_rmse_score_fn: 0.4076\n",
            "Epoch 215/10000\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 53.3947 - root_mean_squared_error: 7.3072 - exp_rmse_score_fn: 0.4816 - val_loss: 80.4851 - val_root_mean_squared_error: 8.9713 - val_exp_rmse_score_fn: 0.4077\n",
            "Epoch 216/10000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 53.3677 - root_mean_squared_error: 7.3053 - exp_rmse_score_fn: 0.4817 - val_loss: 80.5315 - val_root_mean_squared_error: 8.9739 - val_exp_rmse_score_fn: 0.4076\n",
            "Epoch 217/10000\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 53.3433 - root_mean_squared_error: 7.3036 - exp_rmse_score_fn: 0.4817 - val_loss: 80.3845 - val_root_mean_squared_error: 8.9657 - val_exp_rmse_score_fn: 0.4080\n",
            "Epoch 218/10000\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 53.3185 - root_mean_squared_error: 7.3019 - exp_rmse_score_fn: 0.4818 - val_loss: 80.4924 - val_root_mean_squared_error: 8.9718 - val_exp_rmse_score_fn: 0.4077\n",
            "Epoch 219/10000\n",
            "1/1 [==============================] - 1s 590ms/step - loss: 53.2934 - root_mean_squared_error: 7.3002 - exp_rmse_score_fn: 0.4819 - val_loss: 80.3204 - val_root_mean_squared_error: 8.9622 - val_exp_rmse_score_fn: 0.4081\n",
            "Epoch 220/10000\n",
            "1/1 [==============================] - 1s 558ms/step - loss: 53.2677 - root_mean_squared_error: 7.2985 - exp_rmse_score_fn: 0.4820 - val_loss: 80.3931 - val_root_mean_squared_error: 8.9662 - val_exp_rmse_score_fn: 0.4079\n",
            "Epoch 221/10000\n",
            "1/1 [==============================] - 1s 586ms/step - loss: 53.2429 - root_mean_squared_error: 7.2968 - exp_rmse_score_fn: 0.4821 - val_loss: 80.2580 - val_root_mean_squared_error: 8.9587 - val_exp_rmse_score_fn: 0.4083\n",
            "Epoch 222/10000\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 53.2188 - root_mean_squared_error: 7.2951 - exp_rmse_score_fn: 0.4821 - val_loss: 80.3123 - val_root_mean_squared_error: 8.9617 - val_exp_rmse_score_fn: 0.4081\n",
            "Epoch 223/10000\n",
            "1/1 [==============================] - 1s 571ms/step - loss: 53.1957 - root_mean_squared_error: 7.2935 - exp_rmse_score_fn: 0.4822 - val_loss: 80.2106 - val_root_mean_squared_error: 8.9560 - val_exp_rmse_score_fn: 0.4084\n",
            "Epoch 224/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 53.1730 - root_mean_squared_error: 7.2920 - exp_rmse_score_fn: 0.4823 - val_loss: 80.2313 - val_root_mean_squared_error: 8.9572 - val_exp_rmse_score_fn: 0.4083\n",
            "Epoch 225/10000\n",
            "1/1 [==============================] - 1s 570ms/step - loss: 53.1510 - root_mean_squared_error: 7.2905 - exp_rmse_score_fn: 0.4824 - val_loss: 80.1705 - val_root_mean_squared_error: 8.9538 - val_exp_rmse_score_fn: 0.4085\n",
            "Epoch 226/10000\n",
            "1/1 [==============================] - 1s 585ms/step - loss: 53.1299 - root_mean_squared_error: 7.2890 - exp_rmse_score_fn: 0.4824 - val_loss: 80.1543 - val_root_mean_squared_error: 8.9529 - val_exp_rmse_score_fn: 0.4085\n",
            "Epoch 227/10000\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 53.1106 - root_mean_squared_error: 7.2877 - exp_rmse_score_fn: 0.4825 - val_loss: 80.1369 - val_root_mean_squared_error: 8.9519 - val_exp_rmse_score_fn: 0.4085\n",
            "Epoch 228/10000\n",
            "1/1 [==============================] - 1s 562ms/step - loss: 53.0915 - root_mean_squared_error: 7.2864 - exp_rmse_score_fn: 0.4826 - val_loss: 80.0903 - val_root_mean_squared_error: 8.9493 - val_exp_rmse_score_fn: 0.4086\n",
            "Epoch 229/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 53.0730 - root_mean_squared_error: 7.2851 - exp_rmse_score_fn: 0.4826 - val_loss: 80.0831 - val_root_mean_squared_error: 8.9489 - val_exp_rmse_score_fn: 0.4087\n",
            "Epoch 230/10000\n",
            "1/1 [==============================] - 1s 586ms/step - loss: 53.0546 - root_mean_squared_error: 7.2839 - exp_rmse_score_fn: 0.4827 - val_loss: 80.0233 - val_root_mean_squared_error: 8.9456 - val_exp_rmse_score_fn: 0.4088\n",
            "Epoch 231/10000\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 53.0364 - root_mean_squared_error: 7.2826 - exp_rmse_score_fn: 0.4827 - val_loss: 80.0444 - val_root_mean_squared_error: 8.9468 - val_exp_rmse_score_fn: 0.4087\n",
            "Epoch 232/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 53.0213 - root_mean_squared_error: 7.2816 - exp_rmse_score_fn: 0.4828 - val_loss: 79.9648 - val_root_mean_squared_error: 8.9423 - val_exp_rmse_score_fn: 0.4089\n",
            "Epoch 233/10000\n",
            "1/1 [==============================] - 1s 571ms/step - loss: 53.0083 - root_mean_squared_error: 7.2807 - exp_rmse_score_fn: 0.4828 - val_loss: 80.0644 - val_root_mean_squared_error: 8.9479 - val_exp_rmse_score_fn: 0.4087\n",
            "Epoch 234/10000\n",
            "1/1 [==============================] - 1s 581ms/step - loss: 52.9999 - root_mean_squared_error: 7.2801 - exp_rmse_score_fn: 0.4829 - val_loss: 79.8906 - val_root_mean_squared_error: 8.9382 - val_exp_rmse_score_fn: 0.4091\n",
            "Epoch 235/10000\n",
            "1/1 [==============================] - 1s 552ms/step - loss: 52.9974 - root_mean_squared_error: 7.2799 - exp_rmse_score_fn: 0.4829 - val_loss: 80.1628 - val_root_mean_squared_error: 8.9534 - val_exp_rmse_score_fn: 0.4085\n",
            "Epoch 236/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 53.0038 - root_mean_squared_error: 7.2804 - exp_rmse_score_fn: 0.4829 - val_loss: 79.8088 - val_root_mean_squared_error: 8.9336 - val_exp_rmse_score_fn: 0.4093\n",
            "Epoch 237/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 53.0140 - root_mean_squared_error: 7.2811 - exp_rmse_score_fn: 0.4828 - val_loss: 80.2408 - val_root_mean_squared_error: 8.9577 - val_exp_rmse_score_fn: 0.4083\n",
            "Epoch 238/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 53.0191 - root_mean_squared_error: 7.2814 - exp_rmse_score_fn: 0.4828 - val_loss: 79.7540 - val_root_mean_squared_error: 8.9305 - val_exp_rmse_score_fn: 0.4094\n",
            "Epoch 239/10000\n",
            "1/1 [==============================] - 1s 587ms/step - loss: 52.9860 - root_mean_squared_error: 7.2792 - exp_rmse_score_fn: 0.4829 - val_loss: 80.0226 - val_root_mean_squared_error: 8.9455 - val_exp_rmse_score_fn: 0.4088\n",
            "Epoch 240/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 52.9341 - root_mean_squared_error: 7.2756 - exp_rmse_score_fn: 0.4831 - val_loss: 79.8276 - val_root_mean_squared_error: 8.9346 - val_exp_rmse_score_fn: 0.4092\n",
            "Epoch 241/10000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 52.8922 - root_mean_squared_error: 7.2727 - exp_rmse_score_fn: 0.4832 - val_loss: 79.7533 - val_root_mean_squared_error: 8.9305 - val_exp_rmse_score_fn: 0.4094\n",
            "Epoch 242/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 52.8839 - root_mean_squared_error: 7.2721 - exp_rmse_score_fn: 0.4833 - val_loss: 79.9921 - val_root_mean_squared_error: 8.9438 - val_exp_rmse_score_fn: 0.4089\n",
            "Epoch 243/10000\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 52.8938 - root_mean_squared_error: 7.2728 - exp_rmse_score_fn: 0.4832 - val_loss: 79.7108 - val_root_mean_squared_error: 8.9281 - val_exp_rmse_score_fn: 0.4095\n",
            "Epoch 244/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 52.8944 - root_mean_squared_error: 7.2729 - exp_rmse_score_fn: 0.4832 - val_loss: 79.9323 - val_root_mean_squared_error: 8.9405 - val_exp_rmse_score_fn: 0.4090\n",
            "Epoch 245/10000\n",
            "1/1 [==============================] - 1s 588ms/step - loss: 52.8740 - root_mean_squared_error: 7.2715 - exp_rmse_score_fn: 0.4833 - val_loss: 79.7383 - val_root_mean_squared_error: 8.9296 - val_exp_rmse_score_fn: 0.4094\n",
            "Epoch 246/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 52.8355 - root_mean_squared_error: 7.2688 - exp_rmse_score_fn: 0.4834 - val_loss: 79.7442 - val_root_mean_squared_error: 8.9300 - val_exp_rmse_score_fn: 0.4094\n",
            "Epoch 247/10000\n",
            "1/1 [==============================] - 1s 559ms/step - loss: 52.8158 - root_mean_squared_error: 7.2674 - exp_rmse_score_fn: 0.4835 - val_loss: 79.8262 - val_root_mean_squared_error: 8.9346 - val_exp_rmse_score_fn: 0.4092\n",
            "Epoch 248/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 52.8206 - root_mean_squared_error: 7.2678 - exp_rmse_score_fn: 0.4835 - val_loss: 79.6564 - val_root_mean_squared_error: 8.9250 - val_exp_rmse_score_fn: 0.4096\n",
            "Epoch 249/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 52.8214 - root_mean_squared_error: 7.2678 - exp_rmse_score_fn: 0.4835 - val_loss: 79.8544 - val_root_mean_squared_error: 8.9361 - val_exp_rmse_score_fn: 0.4092\n",
            "Epoch 250/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 52.8044 - root_mean_squared_error: 7.2667 - exp_rmse_score_fn: 0.4835 - val_loss: 79.6306 - val_root_mean_squared_error: 8.9236 - val_exp_rmse_score_fn: 0.4097\n",
            "Epoch 251/10000\n",
            "1/1 [==============================] - 1s 556ms/step - loss: 52.7800 - root_mean_squared_error: 7.2650 - exp_rmse_score_fn: 0.4836 - val_loss: 79.7221 - val_root_mean_squared_error: 8.9287 - val_exp_rmse_score_fn: 0.4095\n",
            "Epoch 252/10000\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 52.7625 - root_mean_squared_error: 7.2638 - exp_rmse_score_fn: 0.4837 - val_loss: 79.7126 - val_root_mean_squared_error: 8.9282 - val_exp_rmse_score_fn: 0.4095\n",
            "Epoch 253/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 52.7515 - root_mean_squared_error: 7.2630 - exp_rmse_score_fn: 0.4837 - val_loss: 79.5969 - val_root_mean_squared_error: 8.9217 - val_exp_rmse_score_fn: 0.4098\n",
            "Epoch 254/10000\n",
            "1/1 [==============================] - 1s 562ms/step - loss: 52.7483 - root_mean_squared_error: 7.2628 - exp_rmse_score_fn: 0.4837 - val_loss: 79.7892 - val_root_mean_squared_error: 8.9325 - val_exp_rmse_score_fn: 0.4093\n",
            "Epoch 255/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 52.7463 - root_mean_squared_error: 7.2627 - exp_rmse_score_fn: 0.4837 - val_loss: 79.5498 - val_root_mean_squared_error: 8.9191 - val_exp_rmse_score_fn: 0.4099\n",
            "Epoch 256/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 52.7342 - root_mean_squared_error: 7.2618 - exp_rmse_score_fn: 0.4838 - val_loss: 79.7147 - val_root_mean_squared_error: 8.9283 - val_exp_rmse_score_fn: 0.4095\n",
            "Epoch 257/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 52.7171 - root_mean_squared_error: 7.2607 - exp_rmse_score_fn: 0.4838 - val_loss: 79.5871 - val_root_mean_squared_error: 8.9212 - val_exp_rmse_score_fn: 0.4098\n",
            "Epoch 258/10000\n",
            "1/1 [==============================] - 1s 561ms/step - loss: 52.7016 - root_mean_squared_error: 7.2596 - exp_rmse_score_fn: 0.4839 - val_loss: 79.5950 - val_root_mean_squared_error: 8.9216 - val_exp_rmse_score_fn: 0.4098\n",
            "Epoch 259/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 52.6909 - root_mean_squared_error: 7.2589 - exp_rmse_score_fn: 0.4839 - val_loss: 79.6361 - val_root_mean_squared_error: 8.9239 - val_exp_rmse_score_fn: 0.4097\n",
            "Epoch 260/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 52.6805 - root_mean_squared_error: 7.2581 - exp_rmse_score_fn: 0.4839 - val_loss: 79.5448 - val_root_mean_squared_error: 8.9188 - val_exp_rmse_score_fn: 0.4099\n",
            "Epoch 261/10000\n",
            "1/1 [==============================] - 1s 561ms/step - loss: 52.6702 - root_mean_squared_error: 7.2574 - exp_rmse_score_fn: 0.4840 - val_loss: 79.6263 - val_root_mean_squared_error: 8.9234 - val_exp_rmse_score_fn: 0.4097\n",
            "Epoch 262/10000\n",
            "1/1 [==============================] - 1s 584ms/step - loss: 52.6640 - root_mean_squared_error: 7.2570 - exp_rmse_score_fn: 0.4840 - val_loss: 79.5419 - val_root_mean_squared_error: 8.9186 - val_exp_rmse_score_fn: 0.4099\n",
            "Epoch 263/10000\n",
            "1/1 [==============================] - 1s 586ms/step - loss: 52.6615 - root_mean_squared_error: 7.2568 - exp_rmse_score_fn: 0.4840 - val_loss: 79.6260 - val_root_mean_squared_error: 8.9233 - val_exp_rmse_score_fn: 0.4097\n",
            "Epoch 264/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 52.6557 - root_mean_squared_error: 7.2564 - exp_rmse_score_fn: 0.4840 - val_loss: 79.4997 - val_root_mean_squared_error: 8.9163 - val_exp_rmse_score_fn: 0.4100\n",
            "Epoch 265/10000\n",
            "1/1 [==============================] - 1s 549ms/step - loss: 52.6444 - root_mean_squared_error: 7.2556 - exp_rmse_score_fn: 0.4841 - val_loss: 79.6320 - val_root_mean_squared_error: 8.9237 - val_exp_rmse_score_fn: 0.4097\n",
            "Epoch 266/10000\n",
            "1/1 [==============================] - 1s 582ms/step - loss: 52.6345 - root_mean_squared_error: 7.2550 - exp_rmse_score_fn: 0.4841 - val_loss: 79.4560 - val_root_mean_squared_error: 8.9138 - val_exp_rmse_score_fn: 0.4101\n",
            "Epoch 267/10000\n",
            "1/1 [==============================] - 1s 561ms/step - loss: 52.6250 - root_mean_squared_error: 7.2543 - exp_rmse_score_fn: 0.4841 - val_loss: 79.5893 - val_root_mean_squared_error: 8.9213 - val_exp_rmse_score_fn: 0.4098\n",
            "Epoch 268/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 52.6127 - root_mean_squared_error: 7.2535 - exp_rmse_score_fn: 0.4842 - val_loss: 79.4689 - val_root_mean_squared_error: 8.9145 - val_exp_rmse_score_fn: 0.4101\n",
            "Epoch 269/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 52.5989 - root_mean_squared_error: 7.2525 - exp_rmse_score_fn: 0.4842 - val_loss: 79.5007 - val_root_mean_squared_error: 8.9163 - val_exp_rmse_score_fn: 0.4100\n",
            "Epoch 270/10000\n",
            "1/1 [==============================] - 1s 554ms/step - loss: 52.5881 - root_mean_squared_error: 7.2518 - exp_rmse_score_fn: 0.4842 - val_loss: 79.4972 - val_root_mean_squared_error: 8.9161 - val_exp_rmse_score_fn: 0.4100\n",
            "Epoch 271/10000\n",
            "1/1 [==============================] - 1s 596ms/step - loss: 52.5809 - root_mean_squared_error: 7.2513 - exp_rmse_score_fn: 0.4843 - val_loss: 79.4460 - val_root_mean_squared_error: 8.9132 - val_exp_rmse_score_fn: 0.4101\n",
            "Epoch 272/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 52.5745 - root_mean_squared_error: 7.2508 - exp_rmse_score_fn: 0.4843 - val_loss: 79.4962 - val_root_mean_squared_error: 8.9161 - val_exp_rmse_score_fn: 0.4100\n",
            "Epoch 273/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 52.5672 - root_mean_squared_error: 7.2503 - exp_rmse_score_fn: 0.4843 - val_loss: 79.4335 - val_root_mean_squared_error: 8.9125 - val_exp_rmse_score_fn: 0.4101\n",
            "Epoch 274/10000\n",
            "1/1 [==============================] - 1s 559ms/step - loss: 52.5578 - root_mean_squared_error: 7.2497 - exp_rmse_score_fn: 0.4843 - val_loss: 79.4557 - val_root_mean_squared_error: 8.9138 - val_exp_rmse_score_fn: 0.4101\n",
            "Epoch 275/10000\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 52.5481 - root_mean_squared_error: 7.2490 - exp_rmse_score_fn: 0.4844 - val_loss: 79.4516 - val_root_mean_squared_error: 8.9136 - val_exp_rmse_score_fn: 0.4101\n",
            "Epoch 276/10000\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 52.5399 - root_mean_squared_error: 7.2484 - exp_rmse_score_fn: 0.4844 - val_loss: 79.4105 - val_root_mean_squared_error: 8.9113 - val_exp_rmse_score_fn: 0.4102\n",
            "Epoch 277/10000\n",
            "1/1 [==============================] - 1s 555ms/step - loss: 52.5330 - root_mean_squared_error: 7.2480 - exp_rmse_score_fn: 0.4844 - val_loss: 79.4631 - val_root_mean_squared_error: 8.9142 - val_exp_rmse_score_fn: 0.4101\n",
            "Epoch 278/10000\n",
            "1/1 [==============================] - 1s 584ms/step - loss: 52.5261 - root_mean_squared_error: 7.2475 - exp_rmse_score_fn: 0.4844 - val_loss: 79.3860 - val_root_mean_squared_error: 8.9099 - val_exp_rmse_score_fn: 0.4103\n",
            "Epoch 279/10000\n",
            "1/1 [==============================] - 1s 558ms/step - loss: 52.5181 - root_mean_squared_error: 7.2469 - exp_rmse_score_fn: 0.4845 - val_loss: 79.4515 - val_root_mean_squared_error: 8.9136 - val_exp_rmse_score_fn: 0.4101\n",
            "Epoch 280/10000\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 52.5098 - root_mean_squared_error: 7.2464 - exp_rmse_score_fn: 0.4845 - val_loss: 79.3562 - val_root_mean_squared_error: 8.9082 - val_exp_rmse_score_fn: 0.4103\n",
            "Epoch 281/10000\n",
            "1/1 [==============================] - 1s 571ms/step - loss: 52.5034 - root_mean_squared_error: 7.2459 - exp_rmse_score_fn: 0.4845 - val_loss: 79.4503 - val_root_mean_squared_error: 8.9135 - val_exp_rmse_score_fn: 0.4101\n",
            "Epoch 282/10000\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 52.5047 - root_mean_squared_error: 7.2460 - exp_rmse_score_fn: 0.4845 - val_loss: 79.3399 - val_root_mean_squared_error: 8.9073 - val_exp_rmse_score_fn: 0.4104\n",
            "Epoch 283/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 52.5261 - root_mean_squared_error: 7.2475 - exp_rmse_score_fn: 0.4844 - val_loss: 79.6273 - val_root_mean_squared_error: 8.9234 - val_exp_rmse_score_fn: 0.4097\n",
            "Epoch 284/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 52.5948 - root_mean_squared_error: 7.2522 - exp_rmse_score_fn: 0.4842 - val_loss: 79.2666 - val_root_mean_squared_error: 8.9032 - val_exp_rmse_score_fn: 0.4105\n",
            "Epoch 285/10000\n",
            "1/1 [==============================] - 1s 561ms/step - loss: 52.6179 - root_mean_squared_error: 7.2538 - exp_rmse_score_fn: 0.4841 - val_loss: 79.9670 - val_root_mean_squared_error: 8.9424 - val_exp_rmse_score_fn: 0.4089\n",
            "Epoch 286/10000\n",
            "1/1 [==============================] - 1s 558ms/step - loss: 52.6976 - root_mean_squared_error: 7.2593 - exp_rmse_score_fn: 0.4839 - val_loss: 79.2157 - val_root_mean_squared_error: 8.9003 - val_exp_rmse_score_fn: 0.4106\n",
            "Epoch 287/10000\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 52.6745 - root_mean_squared_error: 7.2577 - exp_rmse_score_fn: 0.4840 - val_loss: 79.6772 - val_root_mean_squared_error: 8.9262 - val_exp_rmse_score_fn: 0.4096\n",
            "Epoch 288/10000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 52.5498 - root_mean_squared_error: 7.2491 - exp_rmse_score_fn: 0.4844 - val_loss: 79.3757 - val_root_mean_squared_error: 8.9093 - val_exp_rmse_score_fn: 0.4103\n",
            "Epoch 289/10000\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 52.4599 - root_mean_squared_error: 7.2429 - exp_rmse_score_fn: 0.4847 - val_loss: 79.1893 - val_root_mean_squared_error: 8.8988 - val_exp_rmse_score_fn: 0.4107\n",
            "Epoch 290/10000\n",
            "1/1 [==============================] - 1s 553ms/step - loss: 52.5024 - root_mean_squared_error: 7.2459 - exp_rmse_score_fn: 0.4845 - val_loss: 79.6837 - val_root_mean_squared_error: 8.9266 - val_exp_rmse_score_fn: 0.4096\n",
            "Epoch 291/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 52.5415 - root_mean_squared_error: 7.2486 - exp_rmse_score_fn: 0.4844 - val_loss: 79.2737 - val_root_mean_squared_error: 8.9036 - val_exp_rmse_score_fn: 0.4105\n",
            "Epoch 292/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 52.5126 - root_mean_squared_error: 7.2466 - exp_rmse_score_fn: 0.4845 - val_loss: 79.3481 - val_root_mean_squared_error: 8.9078 - val_exp_rmse_score_fn: 0.4103\n",
            "Epoch 293/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 52.4747 - root_mean_squared_error: 7.2439 - exp_rmse_score_fn: 0.4846 - val_loss: 79.4224 - val_root_mean_squared_error: 8.9119 - val_exp_rmse_score_fn: 0.4102\n",
            "Epoch 294/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 52.4359 - root_mean_squared_error: 7.2413 - exp_rmse_score_fn: 0.4847 - val_loss: 79.3172 - val_root_mean_squared_error: 8.9060 - val_exp_rmse_score_fn: 0.4104\n",
            "Epoch 295/10000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 52.5374 - root_mean_squared_error: 7.2483 - exp_rmse_score_fn: 0.4844 - val_loss: 79.5212 - val_root_mean_squared_error: 8.9175 - val_exp_rmse_score_fn: 0.4099\n",
            "Epoch 296/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 52.5098 - root_mean_squared_error: 7.2464 - exp_rmse_score_fn: 0.4845 - val_loss: 79.2413 - val_root_mean_squared_error: 8.9018 - val_exp_rmse_score_fn: 0.4106\n",
            "Epoch 297/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 52.4455 - root_mean_squared_error: 7.2419 - exp_rmse_score_fn: 0.4847 - val_loss: 79.3631 - val_root_mean_squared_error: 8.9086 - val_exp_rmse_score_fn: 0.4103\n",
            "Epoch 298/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 52.4807 - root_mean_squared_error: 7.2444 - exp_rmse_score_fn: 0.4846 - val_loss: 79.5298 - val_root_mean_squared_error: 8.9179 - val_exp_rmse_score_fn: 0.4099\n",
            "Epoch 299/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 52.4507 - root_mean_squared_error: 7.2423 - exp_rmse_score_fn: 0.4847 - val_loss: 79.1497 - val_root_mean_squared_error: 8.8966 - val_exp_rmse_score_fn: 0.4108\n",
            "Epoch 300/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 52.4708 - root_mean_squared_error: 7.2437 - exp_rmse_score_fn: 0.4846 - val_loss: 79.3563 - val_root_mean_squared_error: 8.9082 - val_exp_rmse_score_fn: 0.4103\n",
            "Epoch 301/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 52.3878 - root_mean_squared_error: 7.2379 - exp_rmse_score_fn: 0.4849 - val_loss: 79.4657 - val_root_mean_squared_error: 8.9144 - val_exp_rmse_score_fn: 0.4101\n",
            "Epoch 302/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 52.4201 - root_mean_squared_error: 7.2402 - exp_rmse_score_fn: 0.4848 - val_loss: 79.1349 - val_root_mean_squared_error: 8.8958 - val_exp_rmse_score_fn: 0.4108\n",
            "Epoch 303/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 52.4209 - root_mean_squared_error: 7.2402 - exp_rmse_score_fn: 0.4848 - val_loss: 79.3466 - val_root_mean_squared_error: 8.9077 - val_exp_rmse_score_fn: 0.4103\n",
            "Epoch 304/10000\n",
            "1/1 [==============================] - 1s 570ms/step - loss: 52.3904 - root_mean_squared_error: 7.2381 - exp_rmse_score_fn: 0.4849 - val_loss: 79.3489 - val_root_mean_squared_error: 8.9078 - val_exp_rmse_score_fn: 0.4103\n",
            "Epoch 305/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 52.3826 - root_mean_squared_error: 7.2376 - exp_rmse_score_fn: 0.4849 - val_loss: 79.2004 - val_root_mean_squared_error: 8.8995 - val_exp_rmse_score_fn: 0.4107\n",
            "Epoch 306/10000\n",
            "1/1 [==============================] - 1s 552ms/step - loss: 52.3656 - root_mean_squared_error: 7.2364 - exp_rmse_score_fn: 0.4850 - val_loss: 79.3413 - val_root_mean_squared_error: 8.9074 - val_exp_rmse_score_fn: 0.4104\n",
            "Epoch 307/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 52.3906 - root_mean_squared_error: 7.2381 - exp_rmse_score_fn: 0.4849 - val_loss: 79.1853 - val_root_mean_squared_error: 8.8986 - val_exp_rmse_score_fn: 0.4107\n",
            "Epoch 308/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 52.3477 - root_mean_squared_error: 7.2352 - exp_rmse_score_fn: 0.4850 - val_loss: 79.2772 - val_root_mean_squared_error: 8.9038 - val_exp_rmse_score_fn: 0.4105\n",
            "Epoch 309/10000\n",
            "1/1 [==============================] - 1s 562ms/step - loss: 52.3563 - root_mean_squared_error: 7.2358 - exp_rmse_score_fn: 0.4850 - val_loss: 79.3105 - val_root_mean_squared_error: 8.9056 - val_exp_rmse_score_fn: 0.4104\n",
            "Epoch 310/10000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 52.3493 - root_mean_squared_error: 7.2353 - exp_rmse_score_fn: 0.4850 - val_loss: 79.1232 - val_root_mean_squared_error: 8.8951 - val_exp_rmse_score_fn: 0.4109\n",
            "Epoch 311/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 52.3500 - root_mean_squared_error: 7.2353 - exp_rmse_score_fn: 0.4850 - val_loss: 79.3146 - val_root_mean_squared_error: 8.9059 - val_exp_rmse_score_fn: 0.4104\n",
            "Epoch 312/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 52.3370 - root_mean_squared_error: 7.2344 - exp_rmse_score_fn: 0.4851 - val_loss: 79.2463 - val_root_mean_squared_error: 8.9020 - val_exp_rmse_score_fn: 0.4106\n",
            "Epoch 313/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 52.3184 - root_mean_squared_error: 7.2331 - exp_rmse_score_fn: 0.4851 - val_loss: 79.1296 - val_root_mean_squared_error: 8.8955 - val_exp_rmse_score_fn: 0.4108\n",
            "Epoch 314/10000\n",
            "1/1 [==============================] - 1s 576ms/step - loss: 52.3319 - root_mean_squared_error: 7.2341 - exp_rmse_score_fn: 0.4851 - val_loss: 79.3157 - val_root_mean_squared_error: 8.9059 - val_exp_rmse_score_fn: 0.4104\n",
            "Epoch 315/10000\n",
            "1/1 [==============================] - 1s 554ms/step - loss: 52.3189 - root_mean_squared_error: 7.2332 - exp_rmse_score_fn: 0.4851 - val_loss: 79.2011 - val_root_mean_squared_error: 8.8995 - val_exp_rmse_score_fn: 0.4107\n",
            "Epoch 316/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 52.3121 - root_mean_squared_error: 7.2327 - exp_rmse_score_fn: 0.4852 - val_loss: 79.1777 - val_root_mean_squared_error: 8.8982 - val_exp_rmse_score_fn: 0.4107\n",
            "Epoch 317/10000\n",
            "1/1 [==============================] - 1s 576ms/step - loss: 52.3021 - root_mean_squared_error: 7.2320 - exp_rmse_score_fn: 0.4852 - val_loss: 79.2450 - val_root_mean_squared_error: 8.9020 - val_exp_rmse_score_fn: 0.4106\n",
            "Epoch 318/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 52.2979 - root_mean_squared_error: 7.2317 - exp_rmse_score_fn: 0.4852 - val_loss: 79.1749 - val_root_mean_squared_error: 8.8980 - val_exp_rmse_score_fn: 0.4107\n",
            "Epoch 319/10000\n",
            "1/1 [==============================] - 1s 578ms/step - loss: 52.3022 - root_mean_squared_error: 7.2320 - exp_rmse_score_fn: 0.4852 - val_loss: 79.2369 - val_root_mean_squared_error: 8.9015 - val_exp_rmse_score_fn: 0.4106\n",
            "Epoch 320/10000\n",
            "1/1 [==============================] - 1s 577ms/step - loss: 52.2860 - root_mean_squared_error: 7.2309 - exp_rmse_score_fn: 0.4853 - val_loss: 79.1465 - val_root_mean_squared_error: 8.8964 - val_exp_rmse_score_fn: 0.4108\n",
            "Epoch 321/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 52.2830 - root_mean_squared_error: 7.2307 - exp_rmse_score_fn: 0.4853 - val_loss: 79.1699 - val_root_mean_squared_error: 8.8977 - val_exp_rmse_score_fn: 0.4107\n",
            "Epoch 322/10000\n",
            "1/1 [==============================] - 1s 576ms/step - loss: 52.2749 - root_mean_squared_error: 7.2301 - exp_rmse_score_fn: 0.4853 - val_loss: 79.2438 - val_root_mean_squared_error: 8.9019 - val_exp_rmse_score_fn: 0.4106\n",
            "Epoch 323/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 52.2738 - root_mean_squared_error: 7.2301 - exp_rmse_score_fn: 0.4853 - val_loss: 79.1027 - val_root_mean_squared_error: 8.8940 - val_exp_rmse_score_fn: 0.4109\n",
            "Epoch 324/10000\n",
            "1/1 [==============================] - 1s 570ms/step - loss: 52.2702 - root_mean_squared_error: 7.2298 - exp_rmse_score_fn: 0.4853 - val_loss: 79.1901 - val_root_mean_squared_error: 8.8989 - val_exp_rmse_score_fn: 0.4107\n",
            "Epoch 325/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 52.2587 - root_mean_squared_error: 7.2290 - exp_rmse_score_fn: 0.4853 - val_loss: 79.1911 - val_root_mean_squared_error: 8.8989 - val_exp_rmse_score_fn: 0.4107\n",
            "Epoch 326/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 52.2551 - root_mean_squared_error: 7.2288 - exp_rmse_score_fn: 0.4854 - val_loss: 79.1253 - val_root_mean_squared_error: 8.8952 - val_exp_rmse_score_fn: 0.4109\n",
            "Epoch 327/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 52.2489 - root_mean_squared_error: 7.2283 - exp_rmse_score_fn: 0.4854 - val_loss: 79.1888 - val_root_mean_squared_error: 8.8988 - val_exp_rmse_score_fn: 0.4107\n",
            "Epoch 328/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 52.2466 - root_mean_squared_error: 7.2282 - exp_rmse_score_fn: 0.4854 - val_loss: 79.1312 - val_root_mean_squared_error: 8.8956 - val_exp_rmse_score_fn: 0.4108\n",
            "Epoch 329/10000\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 52.2417 - root_mean_squared_error: 7.2278 - exp_rmse_score_fn: 0.4854 - val_loss: 79.1761 - val_root_mean_squared_error: 8.8981 - val_exp_rmse_score_fn: 0.4107\n",
            "Epoch 330/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 52.2332 - root_mean_squared_error: 7.2273 - exp_rmse_score_fn: 0.4854 - val_loss: 79.1299 - val_root_mean_squared_error: 8.8955 - val_exp_rmse_score_fn: 0.4108\n",
            "Epoch 331/10000\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 52.2297 - root_mean_squared_error: 7.2270 - exp_rmse_score_fn: 0.4854 - val_loss: 79.1257 - val_root_mean_squared_error: 8.8953 - val_exp_rmse_score_fn: 0.4109\n",
            "Epoch 332/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 52.2238 - root_mean_squared_error: 7.2266 - exp_rmse_score_fn: 0.4855 - val_loss: 79.1790 - val_root_mean_squared_error: 8.8983 - val_exp_rmse_score_fn: 0.4107\n",
            "Epoch 333/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 52.2211 - root_mean_squared_error: 7.2264 - exp_rmse_score_fn: 0.4855 - val_loss: 79.0864 - val_root_mean_squared_error: 8.8931 - val_exp_rmse_score_fn: 0.4109\n",
            "Epoch 334/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 52.2171 - root_mean_squared_error: 7.2261 - exp_rmse_score_fn: 0.4855 - val_loss: 79.1509 - val_root_mean_squared_error: 8.8967 - val_exp_rmse_score_fn: 0.4108\n",
            "Epoch 335/10000\n",
            "1/1 [==============================] - 1s 577ms/step - loss: 52.2103 - root_mean_squared_error: 7.2257 - exp_rmse_score_fn: 0.4855 - val_loss: 79.1310 - val_root_mean_squared_error: 8.8956 - val_exp_rmse_score_fn: 0.4108\n",
            "Epoch 336/10000\n",
            "1/1 [==============================] - 1s 571ms/step - loss: 52.2064 - root_mean_squared_error: 7.2254 - exp_rmse_score_fn: 0.4855 - val_loss: 79.1112 - val_root_mean_squared_error: 8.8944 - val_exp_rmse_score_fn: 0.4109\n",
            "Epoch 337/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 52.2013 - root_mean_squared_error: 7.2250 - exp_rmse_score_fn: 0.4855 - val_loss: 79.1316 - val_root_mean_squared_error: 8.8956 - val_exp_rmse_score_fn: 0.4108\n",
            "Epoch 338/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 52.1969 - root_mean_squared_error: 7.2247 - exp_rmse_score_fn: 0.4855 - val_loss: 79.1089 - val_root_mean_squared_error: 8.8943 - val_exp_rmse_score_fn: 0.4109\n",
            "Epoch 339/10000\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 52.1939 - root_mean_squared_error: 7.2245 - exp_rmse_score_fn: 0.4856 - val_loss: 79.1329 - val_root_mean_squared_error: 8.8957 - val_exp_rmse_score_fn: 0.4108\n",
            "Epoch 340/10000\n",
            "1/1 [==============================] - 1s 576ms/step - loss: 52.1883 - root_mean_squared_error: 7.2241 - exp_rmse_score_fn: 0.4856 - val_loss: 79.0822 - val_root_mean_squared_error: 8.8928 - val_exp_rmse_score_fn: 0.4110\n",
            "Epoch 341/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 52.1842 - root_mean_squared_error: 7.2239 - exp_rmse_score_fn: 0.4856 - val_loss: 79.1286 - val_root_mean_squared_error: 8.8954 - val_exp_rmse_score_fn: 0.4108\n",
            "Epoch 342/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 52.1793 - root_mean_squared_error: 7.2235 - exp_rmse_score_fn: 0.4856 - val_loss: 79.0985 - val_root_mean_squared_error: 8.8937 - val_exp_rmse_score_fn: 0.4109\n",
            "Epoch 343/10000\n",
            "1/1 [==============================] - 1s 561ms/step - loss: 52.1739 - root_mean_squared_error: 7.2232 - exp_rmse_score_fn: 0.4856 - val_loss: 79.0845 - val_root_mean_squared_error: 8.8929 - val_exp_rmse_score_fn: 0.4109\n",
            "Epoch 344/10000\n",
            "1/1 [==============================] - 1s 554ms/step - loss: 52.1698 - root_mean_squared_error: 7.2229 - exp_rmse_score_fn: 0.4856 - val_loss: 79.1069 - val_root_mean_squared_error: 8.8942 - val_exp_rmse_score_fn: 0.4109\n",
            "Epoch 345/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 52.1653 - root_mean_squared_error: 7.2226 - exp_rmse_score_fn: 0.4857 - val_loss: 79.0792 - val_root_mean_squared_error: 8.8926 - val_exp_rmse_score_fn: 0.4110\n",
            "Epoch 346/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 52.1610 - root_mean_squared_error: 7.2223 - exp_rmse_score_fn: 0.4857 - val_loss: 79.0935 - val_root_mean_squared_error: 8.8935 - val_exp_rmse_score_fn: 0.4109\n",
            "Epoch 347/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 52.1570 - root_mean_squared_error: 7.2220 - exp_rmse_score_fn: 0.4857 - val_loss: 79.0616 - val_root_mean_squared_error: 8.8917 - val_exp_rmse_score_fn: 0.4110\n",
            "Epoch 348/10000\n",
            "1/1 [==============================] - 1s 556ms/step - loss: 52.1520 - root_mean_squared_error: 7.2216 - exp_rmse_score_fn: 0.4857 - val_loss: 79.0960 - val_root_mean_squared_error: 8.8936 - val_exp_rmse_score_fn: 0.4109\n",
            "Epoch 349/10000\n",
            "1/1 [==============================] - 1s 582ms/step - loss: 52.1476 - root_mean_squared_error: 7.2213 - exp_rmse_score_fn: 0.4857 - val_loss: 79.0528 - val_root_mean_squared_error: 8.8912 - val_exp_rmse_score_fn: 0.4110\n",
            "Epoch 350/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 52.1429 - root_mean_squared_error: 7.2210 - exp_rmse_score_fn: 0.4857 - val_loss: 79.0819 - val_root_mean_squared_error: 8.8928 - val_exp_rmse_score_fn: 0.4110\n",
            "Epoch 351/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 52.1381 - root_mean_squared_error: 7.2207 - exp_rmse_score_fn: 0.4857 - val_loss: 79.0693 - val_root_mean_squared_error: 8.8921 - val_exp_rmse_score_fn: 0.4110\n",
            "Epoch 352/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 52.1342 - root_mean_squared_error: 7.2204 - exp_rmse_score_fn: 0.4858 - val_loss: 79.0617 - val_root_mean_squared_error: 8.8917 - val_exp_rmse_score_fn: 0.4110\n",
            "Epoch 353/10000\n",
            "1/1 [==============================] - 1s 590ms/step - loss: 52.1302 - root_mean_squared_error: 7.2201 - exp_rmse_score_fn: 0.4858 - val_loss: 79.0592 - val_root_mean_squared_error: 8.8915 - val_exp_rmse_score_fn: 0.4110\n",
            "Epoch 354/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 52.1260 - root_mean_squared_error: 7.2198 - exp_rmse_score_fn: 0.4858 - val_loss: 79.0554 - val_root_mean_squared_error: 8.8913 - val_exp_rmse_score_fn: 0.4110\n",
            "Epoch 355/10000\n",
            "1/1 [==============================] - 1s 555ms/step - loss: 52.1220 - root_mean_squared_error: 7.2196 - exp_rmse_score_fn: 0.4858 - val_loss: 79.0467 - val_root_mean_squared_error: 8.8908 - val_exp_rmse_score_fn: 0.4110\n",
            "Epoch 356/10000\n",
            "1/1 [==============================] - 1s 582ms/step - loss: 52.1182 - root_mean_squared_error: 7.2193 - exp_rmse_score_fn: 0.4858 - val_loss: 79.0491 - val_root_mean_squared_error: 8.8910 - val_exp_rmse_score_fn: 0.4110\n",
            "Epoch 357/10000\n",
            "1/1 [==============================] - 1s 553ms/step - loss: 52.1140 - root_mean_squared_error: 7.2190 - exp_rmse_score_fn: 0.4858 - val_loss: 79.0502 - val_root_mean_squared_error: 8.8910 - val_exp_rmse_score_fn: 0.4110\n",
            "Epoch 358/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 52.1100 - root_mean_squared_error: 7.2187 - exp_rmse_score_fn: 0.4858 - val_loss: 79.0263 - val_root_mean_squared_error: 8.8897 - val_exp_rmse_score_fn: 0.4111\n",
            "Epoch 359/10000\n",
            "1/1 [==============================] - 1s 585ms/step - loss: 52.1061 - root_mean_squared_error: 7.2185 - exp_rmse_score_fn: 0.4859 - val_loss: 79.0571 - val_root_mean_squared_error: 8.8914 - val_exp_rmse_score_fn: 0.4110\n",
            "Epoch 360/10000\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 52.1020 - root_mean_squared_error: 7.2182 - exp_rmse_score_fn: 0.4859 - val_loss: 79.0170 - val_root_mean_squared_error: 8.8892 - val_exp_rmse_score_fn: 0.4111\n",
            "Epoch 361/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 52.0976 - root_mean_squared_error: 7.2179 - exp_rmse_score_fn: 0.4859 - val_loss: 79.0507 - val_root_mean_squared_error: 8.8910 - val_exp_rmse_score_fn: 0.4110\n",
            "Epoch 362/10000\n",
            "1/1 [==============================] - 1s 576ms/step - loss: 52.0935 - root_mean_squared_error: 7.2176 - exp_rmse_score_fn: 0.4859 - val_loss: 79.0057 - val_root_mean_squared_error: 8.8885 - val_exp_rmse_score_fn: 0.4111\n",
            "Epoch 363/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 52.0902 - root_mean_squared_error: 7.2174 - exp_rmse_score_fn: 0.4859 - val_loss: 79.0681 - val_root_mean_squared_error: 8.8920 - val_exp_rmse_score_fn: 0.4110\n",
            "Epoch 364/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 52.0877 - root_mean_squared_error: 7.2172 - exp_rmse_score_fn: 0.4859 - val_loss: 78.9748 - val_root_mean_squared_error: 8.8868 - val_exp_rmse_score_fn: 0.4112\n",
            "Epoch 365/10000\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 52.0870 - root_mean_squared_error: 7.2171 - exp_rmse_score_fn: 0.4859 - val_loss: 79.1160 - val_root_mean_squared_error: 8.8947 - val_exp_rmse_score_fn: 0.4109\n",
            "Epoch 366/10000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 52.0900 - root_mean_squared_error: 7.2173 - exp_rmse_score_fn: 0.4859 - val_loss: 78.9210 - val_root_mean_squared_error: 8.8837 - val_exp_rmse_score_fn: 0.4113\n",
            "Epoch 367/10000\n",
            "1/1 [==============================] - 1s 584ms/step - loss: 52.1006 - root_mean_squared_error: 7.2181 - exp_rmse_score_fn: 0.4859 - val_loss: 79.2374 - val_root_mean_squared_error: 8.9015 - val_exp_rmse_score_fn: 0.4106\n",
            "Epoch 368/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 52.1248 - root_mean_squared_error: 7.2198 - exp_rmse_score_fn: 0.4858 - val_loss: 78.8795 - val_root_mean_squared_error: 8.8814 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 369/10000\n",
            "1/1 [==============================] - 1s 576ms/step - loss: 52.1620 - root_mean_squared_error: 7.2223 - exp_rmse_score_fn: 0.4857 - val_loss: 79.4473 - val_root_mean_squared_error: 8.9133 - val_exp_rmse_score_fn: 0.4101\n",
            "Epoch 370/10000\n",
            "1/1 [==============================] - 1s 587ms/step - loss: 52.2224 - root_mean_squared_error: 7.2265 - exp_rmse_score_fn: 0.4855 - val_loss: 78.8615 - val_root_mean_squared_error: 8.8804 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 371/10000\n",
            "1/1 [==============================] - 1s 646ms/step - loss: 52.2343 - root_mean_squared_error: 7.2273 - exp_rmse_score_fn: 0.4854 - val_loss: 79.4491 - val_root_mean_squared_error: 8.9134 - val_exp_rmse_score_fn: 0.4101\n",
            "Epoch 372/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 52.2145 - root_mean_squared_error: 7.2260 - exp_rmse_score_fn: 0.4855 - val_loss: 78.8691 - val_root_mean_squared_error: 8.8808 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 373/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 52.1188 - root_mean_squared_error: 7.2193 - exp_rmse_score_fn: 0.4858 - val_loss: 79.0344 - val_root_mean_squared_error: 8.8901 - val_exp_rmse_score_fn: 0.4111\n",
            "Epoch 374/10000\n",
            "1/1 [==============================] - 1s 562ms/step - loss: 52.0549 - root_mean_squared_error: 7.2149 - exp_rmse_score_fn: 0.4860 - val_loss: 79.0833 - val_root_mean_squared_error: 8.8929 - val_exp_rmse_score_fn: 0.4109\n",
            "Epoch 375/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 52.0566 - root_mean_squared_error: 7.2150 - exp_rmse_score_fn: 0.4860 - val_loss: 78.8684 - val_root_mean_squared_error: 8.8808 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 376/10000\n",
            "1/1 [==============================] - 1s 578ms/step - loss: 52.0994 - root_mean_squared_error: 7.2180 - exp_rmse_score_fn: 0.4859 - val_loss: 79.2894 - val_root_mean_squared_error: 8.9045 - val_exp_rmse_score_fn: 0.4105\n",
            "Epoch 377/10000\n",
            "1/1 [==============================] - 1s 550ms/step - loss: 52.1346 - root_mean_squared_error: 7.2204 - exp_rmse_score_fn: 0.4858 - val_loss: 78.8679 - val_root_mean_squared_error: 8.8808 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 378/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 52.0992 - root_mean_squared_error: 7.2180 - exp_rmse_score_fn: 0.4859 - val_loss: 79.0934 - val_root_mean_squared_error: 8.8934 - val_exp_rmse_score_fn: 0.4109\n",
            "Epoch 379/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 52.0494 - root_mean_squared_error: 7.2145 - exp_rmse_score_fn: 0.4860 - val_loss: 78.9845 - val_root_mean_squared_error: 8.8873 - val_exp_rmse_score_fn: 0.4112\n",
            "Epoch 380/10000\n",
            "1/1 [==============================] - 1s 570ms/step - loss: 52.0280 - root_mean_squared_error: 7.2130 - exp_rmse_score_fn: 0.4861 - val_loss: 78.8986 - val_root_mean_squared_error: 8.8825 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 381/10000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 52.0450 - root_mean_squared_error: 7.2142 - exp_rmse_score_fn: 0.4861 - val_loss: 79.1784 - val_root_mean_squared_error: 8.8982 - val_exp_rmse_score_fn: 0.4107\n",
            "Epoch 382/10000\n",
            "1/1 [==============================] - 1s 581ms/step - loss: 52.0716 - root_mean_squared_error: 7.2161 - exp_rmse_score_fn: 0.4860 - val_loss: 78.8588 - val_root_mean_squared_error: 8.8802 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 383/10000\n",
            "1/1 [==============================] - 1s 576ms/step - loss: 52.0654 - root_mean_squared_error: 7.2156 - exp_rmse_score_fn: 0.4860 - val_loss: 79.1008 - val_root_mean_squared_error: 8.8939 - val_exp_rmse_score_fn: 0.4109\n",
            "Epoch 384/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 52.0383 - root_mean_squared_error: 7.2138 - exp_rmse_score_fn: 0.4861 - val_loss: 78.9309 - val_root_mean_squared_error: 8.8843 - val_exp_rmse_score_fn: 0.4113\n",
            "Epoch 385/10000\n",
            "1/1 [==============================] - 1s 577ms/step - loss: 52.0131 - root_mean_squared_error: 7.2120 - exp_rmse_score_fn: 0.4862 - val_loss: 78.9155 - val_root_mean_squared_error: 8.8834 - val_exp_rmse_score_fn: 0.4113\n",
            "Epoch 386/10000\n",
            "1/1 [==============================] - 1s 551ms/step - loss: 52.0093 - root_mean_squared_error: 7.2117 - exp_rmse_score_fn: 0.4862 - val_loss: 79.0682 - val_root_mean_squared_error: 8.8920 - val_exp_rmse_score_fn: 0.4110\n",
            "Epoch 387/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 52.0207 - root_mean_squared_error: 7.2125 - exp_rmse_score_fn: 0.4861 - val_loss: 78.8662 - val_root_mean_squared_error: 8.8807 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 388/10000\n",
            "1/1 [==============================] - 1s 590ms/step - loss: 52.0296 - root_mean_squared_error: 7.2132 - exp_rmse_score_fn: 0.4861 - val_loss: 79.0927 - val_root_mean_squared_error: 8.8934 - val_exp_rmse_score_fn: 0.4109\n",
            "Epoch 389/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 52.0277 - root_mean_squared_error: 7.2130 - exp_rmse_score_fn: 0.4861 - val_loss: 78.8876 - val_root_mean_squared_error: 8.8819 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 390/10000\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 52.0107 - root_mean_squared_error: 7.2118 - exp_rmse_score_fn: 0.4862 - val_loss: 78.9896 - val_root_mean_squared_error: 8.8876 - val_exp_rmse_score_fn: 0.4112\n",
            "Epoch 391/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 51.9941 - root_mean_squared_error: 7.2107 - exp_rmse_score_fn: 0.4862 - val_loss: 78.9483 - val_root_mean_squared_error: 8.8853 - val_exp_rmse_score_fn: 0.4113\n",
            "Epoch 392/10000\n",
            "1/1 [==============================] - 1s 587ms/step - loss: 51.9850 - root_mean_squared_error: 7.2101 - exp_rmse_score_fn: 0.4863 - val_loss: 78.9078 - val_root_mean_squared_error: 8.8830 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 393/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 51.9853 - root_mean_squared_error: 7.2101 - exp_rmse_score_fn: 0.4863 - val_loss: 79.0051 - val_root_mean_squared_error: 8.8885 - val_exp_rmse_score_fn: 0.4111\n",
            "Epoch 394/10000\n",
            "1/1 [==============================] - 1s 562ms/step - loss: 51.9909 - root_mean_squared_error: 7.2105 - exp_rmse_score_fn: 0.4862 - val_loss: 78.8739 - val_root_mean_squared_error: 8.8811 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 395/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 51.9953 - root_mean_squared_error: 7.2108 - exp_rmse_score_fn: 0.4862 - val_loss: 79.0318 - val_root_mean_squared_error: 8.8900 - val_exp_rmse_score_fn: 0.4111\n",
            "Epoch 396/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 52.0008 - root_mean_squared_error: 7.2112 - exp_rmse_score_fn: 0.4862 - val_loss: 78.8695 - val_root_mean_squared_error: 8.8808 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 397/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 51.9936 - root_mean_squared_error: 7.2107 - exp_rmse_score_fn: 0.4862 - val_loss: 79.0077 - val_root_mean_squared_error: 8.8886 - val_exp_rmse_score_fn: 0.4111\n",
            "Epoch 398/10000\n",
            "1/1 [==============================] - 1s 576ms/step - loss: 51.9863 - root_mean_squared_error: 7.2102 - exp_rmse_score_fn: 0.4863 - val_loss: 78.8617 - val_root_mean_squared_error: 8.8804 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 399/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 51.9748 - root_mean_squared_error: 7.2094 - exp_rmse_score_fn: 0.4863 - val_loss: 78.9642 - val_root_mean_squared_error: 8.8862 - val_exp_rmse_score_fn: 0.4112\n",
            "Epoch 400/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 51.9657 - root_mean_squared_error: 7.2087 - exp_rmse_score_fn: 0.4863 - val_loss: 78.9003 - val_root_mean_squared_error: 8.8826 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 401/10000\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 51.9594 - root_mean_squared_error: 7.2083 - exp_rmse_score_fn: 0.4863 - val_loss: 78.9041 - val_root_mean_squared_error: 8.8828 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 402/10000\n",
            "1/1 [==============================] - 1s 556ms/step - loss: 51.9558 - root_mean_squared_error: 7.2080 - exp_rmse_score_fn: 0.4864 - val_loss: 78.9383 - val_root_mean_squared_error: 8.8847 - val_exp_rmse_score_fn: 0.4113\n",
            "Epoch 403/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 51.9538 - root_mean_squared_error: 7.2079 - exp_rmse_score_fn: 0.4864 - val_loss: 78.8769 - val_root_mean_squared_error: 8.8813 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 404/10000\n",
            "1/1 [==============================] - 1s 558ms/step - loss: 51.9522 - root_mean_squared_error: 7.2078 - exp_rmse_score_fn: 0.4864 - val_loss: 78.9457 - val_root_mean_squared_error: 8.8851 - val_exp_rmse_score_fn: 0.4113\n",
            "Epoch 405/10000\n",
            "1/1 [==============================] - 1s 582ms/step - loss: 51.9518 - root_mean_squared_error: 7.2078 - exp_rmse_score_fn: 0.4864 - val_loss: 78.8735 - val_root_mean_squared_error: 8.8811 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 406/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 51.9536 - root_mean_squared_error: 7.2079 - exp_rmse_score_fn: 0.4864 - val_loss: 78.9526 - val_root_mean_squared_error: 8.8855 - val_exp_rmse_score_fn: 0.4113\n",
            "Epoch 407/10000\n",
            "1/1 [==============================] - 1s 577ms/step - loss: 51.9584 - root_mean_squared_error: 7.2082 - exp_rmse_score_fn: 0.4864 - val_loss: 78.8484 - val_root_mean_squared_error: 8.8797 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 408/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 51.9563 - root_mean_squared_error: 7.2081 - exp_rmse_score_fn: 0.4864 - val_loss: 79.0004 - val_root_mean_squared_error: 8.8882 - val_exp_rmse_score_fn: 0.4111\n",
            "Epoch 409/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 51.9581 - root_mean_squared_error: 7.2082 - exp_rmse_score_fn: 0.4864 - val_loss: 78.8057 - val_root_mean_squared_error: 8.8773 - val_exp_rmse_score_fn: 0.4116\n",
            "Epoch 410/10000\n",
            "1/1 [==============================] - 1s 561ms/step - loss: 51.9582 - root_mean_squared_error: 7.2082 - exp_rmse_score_fn: 0.4864 - val_loss: 79.0276 - val_root_mean_squared_error: 8.8897 - val_exp_rmse_score_fn: 0.4111\n",
            "Epoch 411/10000\n",
            "1/1 [==============================] - 1s 552ms/step - loss: 51.9596 - root_mean_squared_error: 7.2083 - exp_rmse_score_fn: 0.4863 - val_loss: 78.8074 - val_root_mean_squared_error: 8.8774 - val_exp_rmse_score_fn: 0.4116\n",
            "Epoch 412/10000\n",
            "1/1 [==============================] - 1s 578ms/step - loss: 51.9570 - root_mean_squared_error: 7.2081 - exp_rmse_score_fn: 0.4864 - val_loss: 79.0042 - val_root_mean_squared_error: 8.8884 - val_exp_rmse_score_fn: 0.4111\n",
            "Epoch 413/10000\n",
            "1/1 [==============================] - 1s 556ms/step - loss: 51.9568 - root_mean_squared_error: 7.2081 - exp_rmse_score_fn: 0.4864 - val_loss: 78.8201 - val_root_mean_squared_error: 8.8781 - val_exp_rmse_score_fn: 0.4116\n",
            "Epoch 414/10000\n",
            "1/1 [==============================] - 1s 571ms/step - loss: 51.9461 - root_mean_squared_error: 7.2074 - exp_rmse_score_fn: 0.4864 - val_loss: 78.9704 - val_root_mean_squared_error: 8.8865 - val_exp_rmse_score_fn: 0.4112\n",
            "Epoch 415/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 51.9382 - root_mean_squared_error: 7.2068 - exp_rmse_score_fn: 0.4864 - val_loss: 78.8256 - val_root_mean_squared_error: 8.8784 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 416/10000\n",
            "1/1 [==============================] - 1s 553ms/step - loss: 51.9282 - root_mean_squared_error: 7.2061 - exp_rmse_score_fn: 0.4865 - val_loss: 78.9386 - val_root_mean_squared_error: 8.8847 - val_exp_rmse_score_fn: 0.4113\n",
            "Epoch 417/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 51.9207 - root_mean_squared_error: 7.2056 - exp_rmse_score_fn: 0.4865 - val_loss: 78.8412 - val_root_mean_squared_error: 8.8793 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 418/10000\n",
            "1/1 [==============================] - 1s 577ms/step - loss: 51.9146 - root_mean_squared_error: 7.2052 - exp_rmse_score_fn: 0.4865 - val_loss: 78.8943 - val_root_mean_squared_error: 8.8822 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 419/10000\n",
            "1/1 [==============================] - 1s 577ms/step - loss: 51.9101 - root_mean_squared_error: 7.2049 - exp_rmse_score_fn: 0.4865 - val_loss: 78.8629 - val_root_mean_squared_error: 8.8805 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 420/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 51.9066 - root_mean_squared_error: 7.2046 - exp_rmse_score_fn: 0.4865 - val_loss: 78.8625 - val_root_mean_squared_error: 8.8805 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 421/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 51.9036 - root_mean_squared_error: 7.2044 - exp_rmse_score_fn: 0.4865 - val_loss: 78.8678 - val_root_mean_squared_error: 8.8808 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 422/10000\n",
            "1/1 [==============================] - 1s 576ms/step - loss: 51.9006 - root_mean_squared_error: 7.2042 - exp_rmse_score_fn: 0.4865 - val_loss: 78.8603 - val_root_mean_squared_error: 8.8803 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 423/10000\n",
            "1/1 [==============================] - 1s 586ms/step - loss: 51.8974 - root_mean_squared_error: 7.2040 - exp_rmse_score_fn: 0.4866 - val_loss: 78.8561 - val_root_mean_squared_error: 8.8801 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 424/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 51.8945 - root_mean_squared_error: 7.2038 - exp_rmse_score_fn: 0.4866 - val_loss: 78.8677 - val_root_mean_squared_error: 8.8807 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 425/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 51.8916 - root_mean_squared_error: 7.2036 - exp_rmse_score_fn: 0.4866 - val_loss: 78.8419 - val_root_mean_squared_error: 8.8793 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 426/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 51.8888 - root_mean_squared_error: 7.2034 - exp_rmse_score_fn: 0.4866 - val_loss: 78.8724 - val_root_mean_squared_error: 8.8810 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 427/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 51.8861 - root_mean_squared_error: 7.2032 - exp_rmse_score_fn: 0.4866 - val_loss: 78.8331 - val_root_mean_squared_error: 8.8788 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 428/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 51.8835 - root_mean_squared_error: 7.2030 - exp_rmse_score_fn: 0.4866 - val_loss: 78.8639 - val_root_mean_squared_error: 8.8805 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 429/10000\n",
            "1/1 [==============================] - 1s 558ms/step - loss: 51.8812 - root_mean_squared_error: 7.2029 - exp_rmse_score_fn: 0.4866 - val_loss: 78.8319 - val_root_mean_squared_error: 8.8787 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 430/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 51.8802 - root_mean_squared_error: 7.2028 - exp_rmse_score_fn: 0.4866 - val_loss: 78.8707 - val_root_mean_squared_error: 8.8809 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 431/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 51.8818 - root_mean_squared_error: 7.2029 - exp_rmse_score_fn: 0.4866 - val_loss: 78.8097 - val_root_mean_squared_error: 8.8775 - val_exp_rmse_score_fn: 0.4116\n",
            "Epoch 432/10000\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 51.8872 - root_mean_squared_error: 7.2033 - exp_rmse_score_fn: 0.4866 - val_loss: 78.9441 - val_root_mean_squared_error: 8.8851 - val_exp_rmse_score_fn: 0.4113\n",
            "Epoch 433/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 51.9047 - root_mean_squared_error: 7.2045 - exp_rmse_score_fn: 0.4865 - val_loss: 78.7503 - val_root_mean_squared_error: 8.8741 - val_exp_rmse_score_fn: 0.4117\n",
            "Epoch 434/10000\n",
            "1/1 [==============================] - 1s 577ms/step - loss: 51.9201 - root_mean_squared_error: 7.2056 - exp_rmse_score_fn: 0.4865 - val_loss: 79.1364 - val_root_mean_squared_error: 8.8959 - val_exp_rmse_score_fn: 0.4108\n",
            "Epoch 435/10000\n",
            "1/1 [==============================] - 1s 570ms/step - loss: 51.9676 - root_mean_squared_error: 7.2089 - exp_rmse_score_fn: 0.4863 - val_loss: 78.7031 - val_root_mean_squared_error: 8.8715 - val_exp_rmse_score_fn: 0.4118\n",
            "Epoch 436/10000\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 52.0018 - root_mean_squared_error: 7.2112 - exp_rmse_score_fn: 0.4862 - val_loss: 79.3268 - val_root_mean_squared_error: 8.9066 - val_exp_rmse_score_fn: 0.4104\n",
            "Epoch 437/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 52.0596 - root_mean_squared_error: 7.2152 - exp_rmse_score_fn: 0.4860 - val_loss: 78.6902 - val_root_mean_squared_error: 8.8707 - val_exp_rmse_score_fn: 0.4119\n",
            "Epoch 438/10000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 52.0114 - root_mean_squared_error: 7.2119 - exp_rmse_score_fn: 0.4862 - val_loss: 79.1082 - val_root_mean_squared_error: 8.8943 - val_exp_rmse_score_fn: 0.4109\n",
            "Epoch 439/10000\n",
            "1/1 [==============================] - 1s 582ms/step - loss: 51.9565 - root_mean_squared_error: 7.2081 - exp_rmse_score_fn: 0.4864 - val_loss: 78.7494 - val_root_mean_squared_error: 8.8741 - val_exp_rmse_score_fn: 0.4117\n",
            "Epoch 440/10000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 51.8742 - root_mean_squared_error: 7.2024 - exp_rmse_score_fn: 0.4866 - val_loss: 78.7732 - val_root_mean_squared_error: 8.8754 - val_exp_rmse_score_fn: 0.4117\n",
            "Epoch 441/10000\n",
            "1/1 [==============================] - 1s 586ms/step - loss: 51.8540 - root_mean_squared_error: 7.2010 - exp_rmse_score_fn: 0.4867 - val_loss: 78.9736 - val_root_mean_squared_error: 8.8867 - val_exp_rmse_score_fn: 0.4112\n",
            "Epoch 442/10000\n",
            "1/1 [==============================] - 1s 588ms/step - loss: 51.8803 - root_mean_squared_error: 7.2028 - exp_rmse_score_fn: 0.4866 - val_loss: 78.7131 - val_root_mean_squared_error: 8.8720 - val_exp_rmse_score_fn: 0.4118\n",
            "Epoch 443/10000\n",
            "1/1 [==============================] - 1s 585ms/step - loss: 51.9187 - root_mean_squared_error: 7.2055 - exp_rmse_score_fn: 0.4865 - val_loss: 79.1037 - val_root_mean_squared_error: 8.8940 - val_exp_rmse_score_fn: 0.4109\n",
            "Epoch 444/10000\n",
            "1/1 [==============================] - 1s 576ms/step - loss: 51.9593 - root_mean_squared_error: 7.2083 - exp_rmse_score_fn: 0.4863 - val_loss: 78.6951 - val_root_mean_squared_error: 8.8710 - val_exp_rmse_score_fn: 0.4118\n",
            "Epoch 445/10000\n",
            "1/1 [==============================] - 1s 583ms/step - loss: 51.8896 - root_mean_squared_error: 7.2034 - exp_rmse_score_fn: 0.4866 - val_loss: 78.9159 - val_root_mean_squared_error: 8.8835 - val_exp_rmse_score_fn: 0.4113\n",
            "Epoch 446/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 51.8575 - root_mean_squared_error: 7.2012 - exp_rmse_score_fn: 0.4867 - val_loss: 78.8257 - val_root_mean_squared_error: 8.8784 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 447/10000\n",
            "1/1 [==============================] - 1s 555ms/step - loss: 51.8625 - root_mean_squared_error: 7.2016 - exp_rmse_score_fn: 0.4867 - val_loss: 78.7103 - val_root_mean_squared_error: 8.8719 - val_exp_rmse_score_fn: 0.4118\n",
            "Epoch 448/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 51.8753 - root_mean_squared_error: 7.2024 - exp_rmse_score_fn: 0.4866 - val_loss: 79.0933 - val_root_mean_squared_error: 8.8934 - val_exp_rmse_score_fn: 0.4109\n",
            "Epoch 449/10000\n",
            "1/1 [==============================] - 1s 561ms/step - loss: 51.9073 - root_mean_squared_error: 7.2047 - exp_rmse_score_fn: 0.4865 - val_loss: 78.6639 - val_root_mean_squared_error: 8.8693 - val_exp_rmse_score_fn: 0.4119\n",
            "Epoch 450/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 51.8932 - root_mean_squared_error: 7.2037 - exp_rmse_score_fn: 0.4866 - val_loss: 78.9358 - val_root_mean_squared_error: 8.8846 - val_exp_rmse_score_fn: 0.4113\n",
            "Epoch 451/10000\n",
            "1/1 [==============================] - 1s 584ms/step - loss: 51.8618 - root_mean_squared_error: 7.2015 - exp_rmse_score_fn: 0.4867 - val_loss: 78.8210 - val_root_mean_squared_error: 8.8781 - val_exp_rmse_score_fn: 0.4116\n",
            "Epoch 452/10000\n",
            "1/1 [==============================] - 1s 553ms/step - loss: 51.8425 - root_mean_squared_error: 7.2002 - exp_rmse_score_fn: 0.4867 - val_loss: 78.7373 - val_root_mean_squared_error: 8.8734 - val_exp_rmse_score_fn: 0.4117\n",
            "Epoch 453/10000\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 51.8459 - root_mean_squared_error: 7.2004 - exp_rmse_score_fn: 0.4867 - val_loss: 78.8905 - val_root_mean_squared_error: 8.8820 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 454/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 51.8329 - root_mean_squared_error: 7.1995 - exp_rmse_score_fn: 0.4868 - val_loss: 78.7611 - val_root_mean_squared_error: 8.8747 - val_exp_rmse_score_fn: 0.4117\n",
            "Epoch 455/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 51.8385 - root_mean_squared_error: 7.1999 - exp_rmse_score_fn: 0.4868 - val_loss: 78.8770 - val_root_mean_squared_error: 8.8813 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 456/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 51.8702 - root_mean_squared_error: 7.2021 - exp_rmse_score_fn: 0.4867 - val_loss: 78.7640 - val_root_mean_squared_error: 8.8749 - val_exp_rmse_score_fn: 0.4117\n",
            "Epoch 457/10000\n",
            "1/1 [==============================] - 1s 578ms/step - loss: 51.8240 - root_mean_squared_error: 7.1989 - exp_rmse_score_fn: 0.4868 - val_loss: 78.8720 - val_root_mean_squared_error: 8.8810 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 458/10000\n",
            "1/1 [==============================] - 1s 571ms/step - loss: 51.8252 - root_mean_squared_error: 7.1990 - exp_rmse_score_fn: 0.4868 - val_loss: 78.7959 - val_root_mean_squared_error: 8.8767 - val_exp_rmse_score_fn: 0.4116\n",
            "Epoch 459/10000\n",
            "1/1 [==============================] - 1s 559ms/step - loss: 51.8461 - root_mean_squared_error: 7.2004 - exp_rmse_score_fn: 0.4867 - val_loss: 78.7594 - val_root_mean_squared_error: 8.8747 - val_exp_rmse_score_fn: 0.4117\n",
            "Epoch 460/10000\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 51.8185 - root_mean_squared_error: 7.1985 - exp_rmse_score_fn: 0.4868 - val_loss: 78.9509 - val_root_mean_squared_error: 8.8854 - val_exp_rmse_score_fn: 0.4113\n",
            "Epoch 461/10000\n",
            "1/1 [==============================] - 1s 583ms/step - loss: 51.8373 - root_mean_squared_error: 7.1998 - exp_rmse_score_fn: 0.4868 - val_loss: 78.7016 - val_root_mean_squared_error: 8.8714 - val_exp_rmse_score_fn: 0.4118\n",
            "Epoch 462/10000\n",
            "1/1 [==============================] - 1s 552ms/step - loss: 51.8523 - root_mean_squared_error: 7.2009 - exp_rmse_score_fn: 0.4867 - val_loss: 78.8259 - val_root_mean_squared_error: 8.8784 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 463/10000\n",
            "1/1 [==============================] - 1s 578ms/step - loss: 51.8061 - root_mean_squared_error: 7.1976 - exp_rmse_score_fn: 0.4869 - val_loss: 78.8960 - val_root_mean_squared_error: 8.8823 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 464/10000\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 51.8433 - root_mean_squared_error: 7.2002 - exp_rmse_score_fn: 0.4867 - val_loss: 78.7570 - val_root_mean_squared_error: 8.8745 - val_exp_rmse_score_fn: 0.4117\n",
            "Epoch 465/10000\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 51.8886 - root_mean_squared_error: 7.2034 - exp_rmse_score_fn: 0.4866 - val_loss: 78.7803 - val_root_mean_squared_error: 8.8758 - val_exp_rmse_score_fn: 0.4116\n",
            "Epoch 466/10000\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 51.8180 - root_mean_squared_error: 7.1985 - exp_rmse_score_fn: 0.4868 - val_loss: 79.0185 - val_root_mean_squared_error: 8.8892 - val_exp_rmse_score_fn: 0.4111\n",
            "Epoch 467/10000\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 51.9663 - root_mean_squared_error: 7.2088 - exp_rmse_score_fn: 0.4863 - val_loss: 78.9229 - val_root_mean_squared_error: 8.8839 - val_exp_rmse_score_fn: 0.4113\n",
            "Epoch 468/10000\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 51.9574 - root_mean_squared_error: 7.2082 - exp_rmse_score_fn: 0.4864 - val_loss: 78.7361 - val_root_mean_squared_error: 8.8733 - val_exp_rmse_score_fn: 0.4118\n",
            "Epoch 469/10000\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 52.0084 - root_mean_squared_error: 7.2117 - exp_rmse_score_fn: 0.4862 - val_loss: 79.0489 - val_root_mean_squared_error: 8.8909 - val_exp_rmse_score_fn: 0.4110\n",
            "Epoch 470/10000\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 51.8851 - root_mean_squared_error: 7.2031 - exp_rmse_score_fn: 0.4866 - val_loss: 79.0245 - val_root_mean_squared_error: 8.8896 - val_exp_rmse_score_fn: 0.4111\n",
            "Epoch 471/10000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 52.1006 - root_mean_squared_error: 7.2181 - exp_rmse_score_fn: 0.4859 - val_loss: 79.0380 - val_root_mean_squared_error: 8.8903 - val_exp_rmse_score_fn: 0.4111\n",
            "Epoch 472/10000\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 51.9802 - root_mean_squared_error: 7.2097 - exp_rmse_score_fn: 0.4863 - val_loss: 78.7909 - val_root_mean_squared_error: 8.8764 - val_exp_rmse_score_fn: 0.4116\n",
            "Epoch 473/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 52.0676 - root_mean_squared_error: 7.2158 - exp_rmse_score_fn: 0.4860 - val_loss: 79.0421 - val_root_mean_squared_error: 8.8906 - val_exp_rmse_score_fn: 0.4110\n",
            "Epoch 474/10000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 52.0346 - root_mean_squared_error: 7.2135 - exp_rmse_score_fn: 0.4861 - val_loss: 78.7868 - val_root_mean_squared_error: 8.8762 - val_exp_rmse_score_fn: 0.4116\n",
            "Epoch 475/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 51.8752 - root_mean_squared_error: 7.2024 - exp_rmse_score_fn: 0.4866 - val_loss: 78.8468 - val_root_mean_squared_error: 8.8796 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 476/10000\n",
            "1/1 [==============================] - 1s 583ms/step - loss: 51.9538 - root_mean_squared_error: 7.2079 - exp_rmse_score_fn: 0.4864 - val_loss: 79.2352 - val_root_mean_squared_error: 8.9014 - val_exp_rmse_score_fn: 0.4106\n",
            "Epoch 477/10000\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 52.0032 - root_mean_squared_error: 7.2113 - exp_rmse_score_fn: 0.4862 - val_loss: 78.7840 - val_root_mean_squared_error: 8.8760 - val_exp_rmse_score_fn: 0.4116\n",
            "Epoch 478/10000\n",
            "1/1 [==============================] - 1s 581ms/step - loss: 51.9122 - root_mean_squared_error: 7.2050 - exp_rmse_score_fn: 0.4865 - val_loss: 78.8390 - val_root_mean_squared_error: 8.8791 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 479/10000\n",
            "1/1 [==============================] - 1s 571ms/step - loss: 51.8958 - root_mean_squared_error: 7.2039 - exp_rmse_score_fn: 0.4866 - val_loss: 78.7719 - val_root_mean_squared_error: 8.8754 - val_exp_rmse_score_fn: 0.4117\n",
            "Epoch 480/10000\n",
            "1/1 [==============================] - 1s 578ms/step - loss: 51.9533 - root_mean_squared_error: 7.2079 - exp_rmse_score_fn: 0.4864 - val_loss: 78.6599 - val_root_mean_squared_error: 8.8690 - val_exp_rmse_score_fn: 0.4119\n",
            "Epoch 481/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 51.9018 - root_mean_squared_error: 7.2043 - exp_rmse_score_fn: 0.4865 - val_loss: 79.0073 - val_root_mean_squared_error: 8.8886 - val_exp_rmse_score_fn: 0.4111\n",
            "Epoch 482/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 51.8650 - root_mean_squared_error: 7.2017 - exp_rmse_score_fn: 0.4867 - val_loss: 78.9040 - val_root_mean_squared_error: 8.8828 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 483/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 51.9132 - root_mean_squared_error: 7.2051 - exp_rmse_score_fn: 0.4865 - val_loss: 78.9356 - val_root_mean_squared_error: 8.8846 - val_exp_rmse_score_fn: 0.4113\n",
            "Epoch 484/10000\n",
            "1/1 [==============================] - 1s 587ms/step - loss: 51.8579 - root_mean_squared_error: 7.2012 - exp_rmse_score_fn: 0.4867 - val_loss: 78.7357 - val_root_mean_squared_error: 8.8733 - val_exp_rmse_score_fn: 0.4118\n",
            "Epoch 485/10000\n",
            "1/1 [==============================] - 1s 571ms/step - loss: 51.8186 - root_mean_squared_error: 7.1985 - exp_rmse_score_fn: 0.4868 - val_loss: 78.6902 - val_root_mean_squared_error: 8.8708 - val_exp_rmse_score_fn: 0.4119\n",
            "Epoch 486/10000\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 51.8635 - root_mean_squared_error: 7.2016 - exp_rmse_score_fn: 0.4867 - val_loss: 78.8444 - val_root_mean_squared_error: 8.8794 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 487/10000\n",
            "1/1 [==============================] - 1s 583ms/step - loss: 51.8321 - root_mean_squared_error: 7.1995 - exp_rmse_score_fn: 0.4868 - val_loss: 78.7032 - val_root_mean_squared_error: 8.8715 - val_exp_rmse_score_fn: 0.4118\n",
            "Epoch 488/10000\n",
            "1/1 [==============================] - 1s 570ms/step - loss: 51.8025 - root_mean_squared_error: 7.1974 - exp_rmse_score_fn: 0.4869 - val_loss: 78.9175 - val_root_mean_squared_error: 8.8836 - val_exp_rmse_score_fn: 0.4113\n",
            "Epoch 489/10000\n",
            "1/1 [==============================] - 1s 577ms/step - loss: 51.8329 - root_mean_squared_error: 7.1995 - exp_rmse_score_fn: 0.4868 - val_loss: 78.7835 - val_root_mean_squared_error: 8.8760 - val_exp_rmse_score_fn: 0.4116\n",
            "Epoch 490/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 51.7816 - root_mean_squared_error: 7.1959 - exp_rmse_score_fn: 0.4869 - val_loss: 78.6787 - val_root_mean_squared_error: 8.8701 - val_exp_rmse_score_fn: 0.4119\n",
            "Epoch 491/10000\n",
            "1/1 [==============================] - 1s 578ms/step - loss: 51.8279 - root_mean_squared_error: 7.1992 - exp_rmse_score_fn: 0.4868 - val_loss: 78.9116 - val_root_mean_squared_error: 8.8832 - val_exp_rmse_score_fn: 0.4113\n",
            "Epoch 492/10000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 51.7909 - root_mean_squared_error: 7.1966 - exp_rmse_score_fn: 0.4869 - val_loss: 78.7447 - val_root_mean_squared_error: 8.8738 - val_exp_rmse_score_fn: 0.4117\n",
            "Epoch 493/10000\n",
            "1/1 [==============================] - 1s 580ms/step - loss: 51.8241 - root_mean_squared_error: 7.1989 - exp_rmse_score_fn: 0.4868 - val_loss: 78.8723 - val_root_mean_squared_error: 8.8810 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 494/10000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 51.8296 - root_mean_squared_error: 7.1993 - exp_rmse_score_fn: 0.4868 - val_loss: 78.7075 - val_root_mean_squared_error: 8.8717 - val_exp_rmse_score_fn: 0.4118\n",
            "Epoch 495/10000\n",
            "1/1 [==============================] - 1s 596ms/step - loss: 51.7934 - root_mean_squared_error: 7.1968 - exp_rmse_score_fn: 0.4869 - val_loss: 78.8478 - val_root_mean_squared_error: 8.8796 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 496/10000\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 51.8212 - root_mean_squared_error: 7.1987 - exp_rmse_score_fn: 0.4868 - val_loss: 78.8375 - val_root_mean_squared_error: 8.8791 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 497/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 51.7820 - root_mean_squared_error: 7.1960 - exp_rmse_score_fn: 0.4869 - val_loss: 78.6045 - val_root_mean_squared_error: 8.8659 - val_exp_rmse_score_fn: 0.4121\n",
            "Epoch 498/10000\n",
            "1/1 [==============================] - 1s 577ms/step - loss: 51.8264 - root_mean_squared_error: 7.1991 - exp_rmse_score_fn: 0.4868 - val_loss: 79.0556 - val_root_mean_squared_error: 8.8913 - val_exp_rmse_score_fn: 0.4110\n",
            "Epoch 499/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 51.8063 - root_mean_squared_error: 7.1977 - exp_rmse_score_fn: 0.4869 - val_loss: 78.7531 - val_root_mean_squared_error: 8.8743 - val_exp_rmse_score_fn: 0.4117\n",
            "Epoch 500/10000\n",
            "1/1 [==============================] - 1s 562ms/step - loss: 51.7797 - root_mean_squared_error: 7.1958 - exp_rmse_score_fn: 0.4870 - val_loss: 78.7178 - val_root_mean_squared_error: 8.8723 - val_exp_rmse_score_fn: 0.4118\n",
            "Epoch 501/10000\n",
            "1/1 [==============================] - 1s 559ms/step - loss: 51.7791 - root_mean_squared_error: 7.1958 - exp_rmse_score_fn: 0.4870 - val_loss: 78.7634 - val_root_mean_squared_error: 8.8749 - val_exp_rmse_score_fn: 0.4117\n",
            "Epoch 502/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 51.7650 - root_mean_squared_error: 7.1948 - exp_rmse_score_fn: 0.4870 - val_loss: 78.7556 - val_root_mean_squared_error: 8.8744 - val_exp_rmse_score_fn: 0.4117\n",
            "Epoch 503/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 51.8125 - root_mean_squared_error: 7.1981 - exp_rmse_score_fn: 0.4868 - val_loss: 78.9668 - val_root_mean_squared_error: 8.8863 - val_exp_rmse_score_fn: 0.4112\n",
            "Epoch 504/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 51.7991 - root_mean_squared_error: 7.1972 - exp_rmse_score_fn: 0.4869 - val_loss: 78.5881 - val_root_mean_squared_error: 8.8650 - val_exp_rmse_score_fn: 0.4121\n",
            "Epoch 505/10000\n",
            "1/1 [==============================] - 1s 581ms/step - loss: 51.8049 - root_mean_squared_error: 7.1976 - exp_rmse_score_fn: 0.4869 - val_loss: 78.8727 - val_root_mean_squared_error: 8.8810 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 506/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 51.7601 - root_mean_squared_error: 7.1944 - exp_rmse_score_fn: 0.4870 - val_loss: 78.7483 - val_root_mean_squared_error: 8.8740 - val_exp_rmse_score_fn: 0.4117\n",
            "Epoch 507/10000\n",
            "1/1 [==============================] - 1s 586ms/step - loss: 51.7389 - root_mean_squared_error: 7.1930 - exp_rmse_score_fn: 0.4871 - val_loss: 78.6157 - val_root_mean_squared_error: 8.8665 - val_exp_rmse_score_fn: 0.4120\n",
            "Epoch 508/10000\n",
            "1/1 [==============================] - 1s 561ms/step - loss: 51.7630 - root_mean_squared_error: 7.1947 - exp_rmse_score_fn: 0.4870 - val_loss: 78.8679 - val_root_mean_squared_error: 8.8808 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 509/10000\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 51.7611 - root_mean_squared_error: 7.1945 - exp_rmse_score_fn: 0.4870 - val_loss: 78.7017 - val_root_mean_squared_error: 8.8714 - val_exp_rmse_score_fn: 0.4118\n",
            "Epoch 510/10000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 51.7844 - root_mean_squared_error: 7.1961 - exp_rmse_score_fn: 0.4869 - val_loss: 78.8541 - val_root_mean_squared_error: 8.8800 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 511/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 51.7524 - root_mean_squared_error: 7.1939 - exp_rmse_score_fn: 0.4870 - val_loss: 78.6102 - val_root_mean_squared_error: 8.8662 - val_exp_rmse_score_fn: 0.4120\n",
            "Epoch 512/10000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 51.7451 - root_mean_squared_error: 7.1934 - exp_rmse_score_fn: 0.4871 - val_loss: 78.7552 - val_root_mean_squared_error: 8.8744 - val_exp_rmse_score_fn: 0.4117\n",
            "Epoch 513/10000\n",
            "1/1 [==============================] - 1s 592ms/step - loss: 51.7233 - root_mean_squared_error: 7.1919 - exp_rmse_score_fn: 0.4871 - val_loss: 78.8015 - val_root_mean_squared_error: 8.8770 - val_exp_rmse_score_fn: 0.4116\n",
            "Epoch 514/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 51.7236 - root_mean_squared_error: 7.1919 - exp_rmse_score_fn: 0.4871 - val_loss: 78.6076 - val_root_mean_squared_error: 8.8661 - val_exp_rmse_score_fn: 0.4121\n",
            "Epoch 515/10000\n",
            "1/1 [==============================] - 1s 554ms/step - loss: 51.7410 - root_mean_squared_error: 7.1931 - exp_rmse_score_fn: 0.4871 - val_loss: 78.8153 - val_root_mean_squared_error: 8.8778 - val_exp_rmse_score_fn: 0.4116\n",
            "Epoch 516/10000\n",
            "1/1 [==============================] - 1s 582ms/step - loss: 51.7279 - root_mean_squared_error: 7.1922 - exp_rmse_score_fn: 0.4871 - val_loss: 78.6862 - val_root_mean_squared_error: 8.8705 - val_exp_rmse_score_fn: 0.4119\n",
            "Epoch 517/10000\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 51.7366 - root_mean_squared_error: 7.1928 - exp_rmse_score_fn: 0.4871 - val_loss: 78.7445 - val_root_mean_squared_error: 8.8738 - val_exp_rmse_score_fn: 0.4117\n",
            "Epoch 518/10000\n",
            "1/1 [==============================] - 1s 593ms/step - loss: 51.7162 - root_mean_squared_error: 7.1914 - exp_rmse_score_fn: 0.4872 - val_loss: 78.6727 - val_root_mean_squared_error: 8.8698 - val_exp_rmse_score_fn: 0.4119\n",
            "Epoch 519/10000\n",
            "1/1 [==============================] - 1s 580ms/step - loss: 51.7132 - root_mean_squared_error: 7.1912 - exp_rmse_score_fn: 0.4872 - val_loss: 78.7340 - val_root_mean_squared_error: 8.8732 - val_exp_rmse_score_fn: 0.4118\n",
            "Epoch 520/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 51.7123 - root_mean_squared_error: 7.1911 - exp_rmse_score_fn: 0.4872 - val_loss: 78.7938 - val_root_mean_squared_error: 8.8766 - val_exp_rmse_score_fn: 0.4116\n",
            "Epoch 521/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 51.7076 - root_mean_squared_error: 7.1908 - exp_rmse_score_fn: 0.4872 - val_loss: 78.6071 - val_root_mean_squared_error: 8.8661 - val_exp_rmse_score_fn: 0.4121\n",
            "Epoch 522/10000\n",
            "1/1 [==============================] - 1s 571ms/step - loss: 51.7180 - root_mean_squared_error: 7.1915 - exp_rmse_score_fn: 0.4872 - val_loss: 78.8058 - val_root_mean_squared_error: 8.8773 - val_exp_rmse_score_fn: 0.4116\n",
            "Epoch 523/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 51.7097 - root_mean_squared_error: 7.1909 - exp_rmse_score_fn: 0.4872 - val_loss: 78.6659 - val_root_mean_squared_error: 8.8694 - val_exp_rmse_score_fn: 0.4119\n",
            "Epoch 524/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 51.7079 - root_mean_squared_error: 7.1908 - exp_rmse_score_fn: 0.4872 - val_loss: 78.7143 - val_root_mean_squared_error: 8.8721 - val_exp_rmse_score_fn: 0.4118\n",
            "Epoch 525/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 51.7023 - root_mean_squared_error: 7.1904 - exp_rmse_score_fn: 0.4872 - val_loss: 78.6773 - val_root_mean_squared_error: 8.8700 - val_exp_rmse_score_fn: 0.4119\n",
            "Epoch 526/10000\n",
            "1/1 [==============================] - 1s 558ms/step - loss: 51.6930 - root_mean_squared_error: 7.1898 - exp_rmse_score_fn: 0.4872 - val_loss: 78.7084 - val_root_mean_squared_error: 8.8718 - val_exp_rmse_score_fn: 0.4118\n",
            "Epoch 527/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 51.7012 - root_mean_squared_error: 7.1904 - exp_rmse_score_fn: 0.4872 - val_loss: 78.7470 - val_root_mean_squared_error: 8.8740 - val_exp_rmse_score_fn: 0.4117\n",
            "Epoch 528/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 51.6971 - root_mean_squared_error: 7.1901 - exp_rmse_score_fn: 0.4872 - val_loss: 78.6010 - val_root_mean_squared_error: 8.8657 - val_exp_rmse_score_fn: 0.4121\n",
            "Epoch 529/10000\n",
            "1/1 [==============================] - 1s 570ms/step - loss: 51.7022 - root_mean_squared_error: 7.1904 - exp_rmse_score_fn: 0.4872 - val_loss: 78.8262 - val_root_mean_squared_error: 8.8784 - val_exp_rmse_score_fn: 0.4115\n",
            "Epoch 530/10000\n",
            "1/1 [==============================] - 1s 585ms/step - loss: 51.7031 - root_mean_squared_error: 7.1905 - exp_rmse_score_fn: 0.4872 - val_loss: 78.6368 - val_root_mean_squared_error: 8.8677 - val_exp_rmse_score_fn: 0.4120\n",
            "Epoch 531/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 51.6900 - root_mean_squared_error: 7.1896 - exp_rmse_score_fn: 0.4873 - val_loss: 78.6947 - val_root_mean_squared_error: 8.8710 - val_exp_rmse_score_fn: 0.4118\n",
            "Epoch 532/10000\n",
            "1/1 [==============================] - 1s 584ms/step - loss: 51.6907 - root_mean_squared_error: 7.1896 - exp_rmse_score_fn: 0.4873 - val_loss: 78.6786 - val_root_mean_squared_error: 8.8701 - val_exp_rmse_score_fn: 0.4119\n",
            "Epoch 533/10000\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 51.6794 - root_mean_squared_error: 7.1888 - exp_rmse_score_fn: 0.4873 - val_loss: 78.6785 - val_root_mean_squared_error: 8.8701 - val_exp_rmse_score_fn: 0.4119\n",
            "Epoch 534/10000\n",
            "1/1 [==============================] - 1s 583ms/step - loss: 51.6830 - root_mean_squared_error: 7.1891 - exp_rmse_score_fn: 0.4873 - val_loss: 78.7249 - val_root_mean_squared_error: 8.8727 - val_exp_rmse_score_fn: 0.4118\n",
            "Epoch 535/10000\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 51.6860 - root_mean_squared_error: 7.1893 - exp_rmse_score_fn: 0.4873 - val_loss: 78.6094 - val_root_mean_squared_error: 8.8662 - val_exp_rmse_score_fn: 0.4120\n",
            "Epoch 536/10000\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 51.6841 - root_mean_squared_error: 7.1892 - exp_rmse_score_fn: 0.4873 - val_loss: 78.7960 - val_root_mean_squared_error: 8.8767 - val_exp_rmse_score_fn: 0.4116\n",
            "Epoch 537/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 51.6894 - root_mean_squared_error: 7.1895 - exp_rmse_score_fn: 0.4873 - val_loss: 78.6084 - val_root_mean_squared_error: 8.8661 - val_exp_rmse_score_fn: 0.4120\n",
            "Epoch 538/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 51.6781 - root_mean_squared_error: 7.1887 - exp_rmse_score_fn: 0.4873 - val_loss: 78.6916 - val_root_mean_squared_error: 8.8708 - val_exp_rmse_score_fn: 0.4119\n",
            "Epoch 539/10000\n",
            "1/1 [==============================] - 1s 570ms/step - loss: 51.6745 - root_mean_squared_error: 7.1885 - exp_rmse_score_fn: 0.4873 - val_loss: 78.6778 - val_root_mean_squared_error: 8.8700 - val_exp_rmse_score_fn: 0.4119\n",
            "Epoch 540/10000\n",
            "1/1 [==============================] - 1s 554ms/step - loss: 51.6705 - root_mean_squared_error: 7.1882 - exp_rmse_score_fn: 0.4873 - val_loss: 78.6566 - val_root_mean_squared_error: 8.8689 - val_exp_rmse_score_fn: 0.4119\n",
            "Epoch 541/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 51.6656 - root_mean_squared_error: 7.1879 - exp_rmse_score_fn: 0.4873 - val_loss: 78.6716 - val_root_mean_squared_error: 8.8697 - val_exp_rmse_score_fn: 0.4119\n",
            "Epoch 542/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 51.6676 - root_mean_squared_error: 7.1880 - exp_rmse_score_fn: 0.4873 - val_loss: 78.6344 - val_root_mean_squared_error: 8.8676 - val_exp_rmse_score_fn: 0.4120\n",
            "Epoch 543/10000\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 51.6656 - root_mean_squared_error: 7.1879 - exp_rmse_score_fn: 0.4873 - val_loss: 78.7217 - val_root_mean_squared_error: 8.8725 - val_exp_rmse_score_fn: 0.4118\n",
            "Epoch 544/10000\n",
            "1/1 [==============================] - 1s 561ms/step - loss: 51.6653 - root_mean_squared_error: 7.1879 - exp_rmse_score_fn: 0.4873 - val_loss: 78.5946 - val_root_mean_squared_error: 8.8654 - val_exp_rmse_score_fn: 0.4121\n",
            "Epoch 545/10000\n",
            "1/1 [==============================] - 1s 559ms/step - loss: 51.6663 - root_mean_squared_error: 7.1879 - exp_rmse_score_fn: 0.4873 - val_loss: 78.7303 - val_root_mean_squared_error: 8.8730 - val_exp_rmse_score_fn: 0.4118\n",
            "Epoch 546/10000\n",
            "1/1 [==============================] - 1s 580ms/step - loss: 51.6646 - root_mean_squared_error: 7.1878 - exp_rmse_score_fn: 0.4873 - val_loss: 78.6123 - val_root_mean_squared_error: 8.8664 - val_exp_rmse_score_fn: 0.4120\n",
            "Epoch 547/10000\n",
            "1/1 [==============================] - 1s 552ms/step - loss: 51.6641 - root_mean_squared_error: 7.1878 - exp_rmse_score_fn: 0.4873 - val_loss: 78.7128 - val_root_mean_squared_error: 8.8720 - val_exp_rmse_score_fn: 0.4118\n",
            "Epoch 548/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 51.6635 - root_mean_squared_error: 7.1877 - exp_rmse_score_fn: 0.4873 - val_loss: 78.5958 - val_root_mean_squared_error: 8.8654 - val_exp_rmse_score_fn: 0.4121\n",
            "Epoch 549/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 51.6594 - root_mean_squared_error: 7.1874 - exp_rmse_score_fn: 0.4874 - val_loss: 78.7336 - val_root_mean_squared_error: 8.8732 - val_exp_rmse_score_fn: 0.4118\n",
            "Epoch 550/10000\n",
            "1/1 [==============================] - 1s 589ms/step - loss: 51.6584 - root_mean_squared_error: 7.1874 - exp_rmse_score_fn: 0.4874 - val_loss: 78.5972 - val_root_mean_squared_error: 8.8655 - val_exp_rmse_score_fn: 0.4121\n",
            "Epoch 551/10000\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 51.6542 - root_mean_squared_error: 7.1871 - exp_rmse_score_fn: 0.4874 - val_loss: 78.6824 - val_root_mean_squared_error: 8.8703 - val_exp_rmse_score_fn: 0.4119\n",
            "Epoch 552/10000\n",
            "1/1 [==============================] - 1s 587ms/step - loss: 51.6513 - root_mean_squared_error: 7.1869 - exp_rmse_score_fn: 0.4874 - val_loss: 78.6216 - val_root_mean_squared_error: 8.8669 - val_exp_rmse_score_fn: 0.4120\n",
            "Epoch 553/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 51.6498 - root_mean_squared_error: 7.1868 - exp_rmse_score_fn: 0.4874 - val_loss: 78.6625 - val_root_mean_squared_error: 8.8692 - val_exp_rmse_score_fn: 0.4119\n",
            "Epoch 554/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 51.6470 - root_mean_squared_error: 7.1866 - exp_rmse_score_fn: 0.4874 - val_loss: 78.6029 - val_root_mean_squared_error: 8.8658 - val_exp_rmse_score_fn: 0.4121\n",
            "1937/1937 [==============================] - 3s 1ms/step - loss: 78.5878 - root_mean_squared_error: 8.8650 - exp_rmse_score_fn: 0.8983\n",
            "1937/1937 [==============================] - 3s 1ms/step\n",
            " predict_hat shape: (61982, 1)\n",
            "Numpy rmse: 8.864992844622183 res: 0.41209586096056405\n",
            "Tensor mse_res:78.58808898925781 rmse: 8.864992141723633 res: 0.4120958745479584 mult:-1\n",
            " fold: 0 exp_rmse_score: 0.41209586096056405 scr2: 0.4120958745479584 eval_results: [78.58782958984375, 8.864977836608887, 0.8983370661735535] fold_results: [[78.58782958984375, 8.864977836608887, 0.8983370661735535]]  \n",
            "MAX_SALE: 1\n",
            "starting categorical feature with input shape: (247928, 33)\n",
            "[Pipeline]  (step 1 of 4) Processing categoricaltransformer, total=   0.2s\n",
            "starting feature with input shape: (247928, 33)\n",
            "[Pipeline]  (step 2 of 4) Processing featuretransformers, total=   0.1s\n",
            "starting avg price feature with input shape: (247928, 45)\n",
            "[Pipeline]  (step 3 of 4) Processing avgpricetransformer, total=   1.1s\n",
            "starting fill na imputer with input shape:  (247928, 59)\n",
            "[Pipeline] ..... (step 4 of 4) Processing fillnaimputer, total=   0.0s\n",
            "starting categorical feature with input shape: (61982, 33)\n",
            "starting feature with input shape: (61982, 33)\n",
            "starting avg price feature with input shape: (61982, 45)\n",
            "starting fill na imputer with input shape:  (61982, 59)\n",
            "Epoch 1/10000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 169.6365 - root_mean_squared_error: 13.0245 - exp_rmse_score_fn: 0.2719 - val_loss: 164.3656 - val_root_mean_squared_error: 12.8205 - val_exp_rmse_score_fn: 0.2775\n",
            "Epoch 2/10000\n",
            "1/1 [==============================] - 1s 635ms/step - loss: 168.3110 - root_mean_squared_error: 12.9735 - exp_rmse_score_fn: 0.2733 - val_loss: 163.2302 - val_root_mean_squared_error: 12.7762 - val_exp_rmse_score_fn: 0.2787\n",
            "Epoch 3/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 167.1460 - root_mean_squared_error: 12.9285 - exp_rmse_score_fn: 0.2745 - val_loss: 162.2181 - val_root_mean_squared_error: 12.7365 - val_exp_rmse_score_fn: 0.2798\n",
            "Epoch 4/10000\n",
            "1/1 [==============================] - 1s 589ms/step - loss: 166.1069 - root_mean_squared_error: 12.8882 - exp_rmse_score_fn: 0.2756 - val_loss: 161.3186 - val_root_mean_squared_error: 12.7011 - val_exp_rmse_score_fn: 0.2808\n",
            "Epoch 5/10000\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 165.1850 - root_mean_squared_error: 12.8524 - exp_rmse_score_fn: 0.2766 - val_loss: 160.4961 - val_root_mean_squared_error: 12.6687 - val_exp_rmse_score_fn: 0.2817\n",
            "Epoch 6/10000\n",
            "1/1 [==============================] - 1s 602ms/step - loss: 164.3428 - root_mean_squared_error: 12.8196 - exp_rmse_score_fn: 0.2775 - val_loss: 159.7326 - val_root_mean_squared_error: 12.6385 - val_exp_rmse_score_fn: 0.2826\n",
            "Epoch 7/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 163.5601 - root_mean_squared_error: 12.7891 - exp_rmse_score_fn: 0.2783 - val_loss: 159.0118 - val_root_mean_squared_error: 12.6100 - val_exp_rmse_score_fn: 0.2834\n",
            "Epoch 8/10000\n",
            "1/1 [==============================] - 1s 582ms/step - loss: 162.8194 - root_mean_squared_error: 12.7601 - exp_rmse_score_fn: 0.2791 - val_loss: 158.3008 - val_root_mean_squared_error: 12.5818 - val_exp_rmse_score_fn: 0.2842\n",
            "Epoch 9/10000\n",
            "1/1 [==============================] - 1s 571ms/step - loss: 162.0875 - root_mean_squared_error: 12.7314 - exp_rmse_score_fn: 0.2800 - val_loss: 157.5994 - val_root_mean_squared_error: 12.5539 - val_exp_rmse_score_fn: 0.2850\n",
            "Epoch 10/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 161.3644 - root_mean_squared_error: 12.7029 - exp_rmse_score_fn: 0.2807 - val_loss: 156.8951 - val_root_mean_squared_error: 12.5258 - val_exp_rmse_score_fn: 0.2858\n",
            "Epoch 11/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 160.6379 - root_mean_squared_error: 12.6743 - exp_rmse_score_fn: 0.2816 - val_loss: 156.1757 - val_root_mean_squared_error: 12.4970 - val_exp_rmse_score_fn: 0.2866\n",
            "Epoch 12/10000\n",
            "1/1 [==============================] - 1s 585ms/step - loss: 159.8952 - root_mean_squared_error: 12.6450 - exp_rmse_score_fn: 0.2824 - val_loss: 155.4339 - val_root_mean_squared_error: 12.4673 - val_exp_rmse_score_fn: 0.2874\n",
            "Epoch 13/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 159.1306 - root_mean_squared_error: 12.6147 - exp_rmse_score_fn: 0.2832 - val_loss: 154.6604 - val_root_mean_squared_error: 12.4363 - val_exp_rmse_score_fn: 0.2883\n",
            "Epoch 14/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 158.3336 - root_mean_squared_error: 12.5831 - exp_rmse_score_fn: 0.2841 - val_loss: 153.8429 - val_root_mean_squared_error: 12.4033 - val_exp_rmse_score_fn: 0.2893\n",
            "Epoch 15/10000\n",
            "1/1 [==============================] - 1s 577ms/step - loss: 157.4925 - root_mean_squared_error: 12.5496 - exp_rmse_score_fn: 0.2851 - val_loss: 152.9744 - val_root_mean_squared_error: 12.3683 - val_exp_rmse_score_fn: 0.2903\n",
            "Epoch 16/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 156.6002 - root_mean_squared_error: 12.5140 - exp_rmse_score_fn: 0.2861 - val_loss: 152.0452 - val_root_mean_squared_error: 12.3307 - val_exp_rmse_score_fn: 0.2914\n",
            "Epoch 17/10000\n",
            "1/1 [==============================] - 1s 582ms/step - loss: 155.6460 - root_mean_squared_error: 12.4758 - exp_rmse_score_fn: 0.2872 - val_loss: 151.0617 - val_root_mean_squared_error: 12.2907 - val_exp_rmse_score_fn: 0.2926\n",
            "Epoch 18/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 154.6381 - root_mean_squared_error: 12.4354 - exp_rmse_score_fn: 0.2884 - val_loss: 150.0219 - val_root_mean_squared_error: 12.2483 - val_exp_rmse_score_fn: 0.2938\n",
            "Epoch 19/10000\n",
            "1/1 [==============================] - 1s 586ms/step - loss: 153.5744 - root_mean_squared_error: 12.3925 - exp_rmse_score_fn: 0.2896 - val_loss: 148.9292 - val_root_mean_squared_error: 12.2037 - val_exp_rmse_score_fn: 0.2951\n",
            "Epoch 20/10000\n",
            "1/1 [==============================] - 1s 583ms/step - loss: 152.4576 - root_mean_squared_error: 12.3474 - exp_rmse_score_fn: 0.2909 - val_loss: 147.7832 - val_root_mean_squared_error: 12.1566 - val_exp_rmse_score_fn: 0.2965\n",
            "Epoch 21/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 151.2876 - root_mean_squared_error: 12.2999 - exp_rmse_score_fn: 0.2923 - val_loss: 146.5833 - val_root_mean_squared_error: 12.1072 - val_exp_rmse_score_fn: 0.2980\n",
            "Epoch 22/10000\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 150.0620 - root_mean_squared_error: 12.2500 - exp_rmse_score_fn: 0.2938 - val_loss: 145.3335 - val_root_mean_squared_error: 12.0554 - val_exp_rmse_score_fn: 0.2995\n",
            "Epoch 23/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 148.7859 - root_mean_squared_error: 12.1978 - exp_rmse_score_fn: 0.2953 - val_loss: 144.0427 - val_root_mean_squared_error: 12.0018 - val_exp_rmse_score_fn: 0.3011\n",
            "Epoch 24/10000\n",
            "1/1 [==============================] - 1s 590ms/step - loss: 147.4679 - root_mean_squared_error: 12.1436 - exp_rmse_score_fn: 0.2969 - val_loss: 142.7214 - val_root_mean_squared_error: 11.9466 - val_exp_rmse_score_fn: 0.3028\n",
            "Epoch 25/10000\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 146.1192 - root_mean_squared_error: 12.0880 - exp_rmse_score_fn: 0.2986 - val_loss: 141.3680 - val_root_mean_squared_error: 11.8898 - val_exp_rmse_score_fn: 0.3045\n",
            "Epoch 26/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 144.7376 - root_mean_squared_error: 12.0307 - exp_rmse_score_fn: 0.3003 - val_loss: 139.9883 - val_root_mean_squared_error: 11.8317 - val_exp_rmse_score_fn: 0.3063\n",
            "Epoch 27/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 143.3288 - root_mean_squared_error: 11.9720 - exp_rmse_score_fn: 0.3020 - val_loss: 138.5990 - val_root_mean_squared_error: 11.7728 - val_exp_rmse_score_fn: 0.3081\n",
            "Epoch 28/10000\n",
            "1/1 [==============================] - 1s 576ms/step - loss: 141.9098 - root_mean_squared_error: 11.9126 - exp_rmse_score_fn: 0.3038 - val_loss: 137.2108 - val_root_mean_squared_error: 11.7137 - val_exp_rmse_score_fn: 0.3099\n",
            "Epoch 29/10000\n",
            "1/1 [==============================] - 1s 590ms/step - loss: 140.4910 - root_mean_squared_error: 11.8529 - exp_rmse_score_fn: 0.3057 - val_loss: 135.8360 - val_root_mean_squared_error: 11.6549 - val_exp_rmse_score_fn: 0.3118\n",
            "Epoch 30/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 139.0839 - root_mean_squared_error: 11.7934 - exp_rmse_score_fn: 0.3075 - val_loss: 134.4873 - val_root_mean_squared_error: 11.5969 - val_exp_rmse_score_fn: 0.3136\n",
            "Epoch 31/10000\n",
            "1/1 [==============================] - 1s 576ms/step - loss: 137.7022 - root_mean_squared_error: 11.7347 - exp_rmse_score_fn: 0.3093 - val_loss: 133.1854 - val_root_mean_squared_error: 11.5406 - val_exp_rmse_score_fn: 0.3154\n",
            "Epoch 32/10000\n",
            "1/1 [==============================] - 1s 578ms/step - loss: 136.3665 - root_mean_squared_error: 11.6776 - exp_rmse_score_fn: 0.3111 - val_loss: 131.9378 - val_root_mean_squared_error: 11.4864 - val_exp_rmse_score_fn: 0.3171\n",
            "Epoch 33/10000\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 135.0856 - root_mean_squared_error: 11.6226 - exp_rmse_score_fn: 0.3128 - val_loss: 130.7456 - val_root_mean_squared_error: 11.4344 - val_exp_rmse_score_fn: 0.3187\n",
            "Epoch 34/10000\n",
            "1/1 [==============================] - 1s 588ms/step - loss: 133.8612 - root_mean_squared_error: 11.5698 - exp_rmse_score_fn: 0.3144 - val_loss: 129.6264 - val_root_mean_squared_error: 11.3854 - val_exp_rmse_score_fn: 0.3203\n",
            "Epoch 35/10000\n",
            "1/1 [==============================] - 1s 580ms/step - loss: 132.7119 - root_mean_squared_error: 11.5201 - exp_rmse_score_fn: 0.3160 - val_loss: 128.5714 - val_root_mean_squared_error: 11.3389 - val_exp_rmse_score_fn: 0.3218\n",
            "Epoch 36/10000\n",
            "1/1 [==============================] - 1s 591ms/step - loss: 131.6297 - root_mean_squared_error: 11.4730 - exp_rmse_score_fn: 0.3175 - val_loss: 127.5881 - val_root_mean_squared_error: 11.2955 - val_exp_rmse_score_fn: 0.3232\n",
            "Epoch 37/10000\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 130.6201 - root_mean_squared_error: 11.4289 - exp_rmse_score_fn: 0.3189 - val_loss: 126.6703 - val_root_mean_squared_error: 11.2548 - val_exp_rmse_score_fn: 0.3245\n",
            "Epoch 38/10000\n",
            "1/1 [==============================] - 1s 584ms/step - loss: 129.6776 - root_mean_squared_error: 11.3876 - exp_rmse_score_fn: 0.3202 - val_loss: 125.7859 - val_root_mean_squared_error: 11.2154 - val_exp_rmse_score_fn: 0.3258\n",
            "Epoch 39/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 128.7716 - root_mean_squared_error: 11.3478 - exp_rmse_score_fn: 0.3215 - val_loss: 124.9345 - val_root_mean_squared_error: 11.1774 - val_exp_rmse_score_fn: 0.3270\n",
            "Epoch 40/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 127.9020 - root_mean_squared_error: 11.3094 - exp_rmse_score_fn: 0.3227 - val_loss: 124.0946 - val_root_mean_squared_error: 11.1398 - val_exp_rmse_score_fn: 0.3283\n",
            "Epoch 41/10000\n",
            "1/1 [==============================] - 1s 580ms/step - loss: 127.0496 - root_mean_squared_error: 11.2716 - exp_rmse_score_fn: 0.3240 - val_loss: 123.2495 - val_root_mean_squared_error: 11.1018 - val_exp_rmse_score_fn: 0.3295\n",
            "Epoch 42/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 126.1989 - root_mean_squared_error: 11.2338 - exp_rmse_score_fn: 0.3252 - val_loss: 122.3775 - val_root_mean_squared_error: 11.0624 - val_exp_rmse_score_fn: 0.3308\n",
            "Epoch 43/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 125.3249 - root_mean_squared_error: 11.1949 - exp_rmse_score_fn: 0.3264 - val_loss: 121.4601 - val_root_mean_squared_error: 11.0209 - val_exp_rmse_score_fn: 0.3322\n",
            "Epoch 44/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 124.4079 - root_mean_squared_error: 11.1538 - exp_rmse_score_fn: 0.3278 - val_loss: 120.5196 - val_root_mean_squared_error: 10.9781 - val_exp_rmse_score_fn: 0.3336\n",
            "Epoch 45/10000\n",
            "1/1 [==============================] - 1s 590ms/step - loss: 123.4678 - root_mean_squared_error: 11.1116 - exp_rmse_score_fn: 0.3292 - val_loss: 119.5558 - val_root_mean_squared_error: 10.9342 - val_exp_rmse_score_fn: 0.3351\n",
            "Epoch 46/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 122.5051 - root_mean_squared_error: 11.0682 - exp_rmse_score_fn: 0.3306 - val_loss: 118.6028 - val_root_mean_squared_error: 10.8905 - val_exp_rmse_score_fn: 0.3365\n",
            "Epoch 47/10000\n",
            "1/1 [==============================] - 1s 581ms/step - loss: 121.5517 - root_mean_squared_error: 11.0251 - exp_rmse_score_fn: 0.3320 - val_loss: 117.6669 - val_root_mean_squared_error: 10.8474 - val_exp_rmse_score_fn: 0.3380\n",
            "Epoch 48/10000\n",
            "1/1 [==============================] - 1s 561ms/step - loss: 120.6144 - root_mean_squared_error: 10.9825 - exp_rmse_score_fn: 0.3335 - val_loss: 116.7665 - val_root_mean_squared_error: 10.8059 - val_exp_rmse_score_fn: 0.3394\n",
            "Epoch 49/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 119.7089 - root_mean_squared_error: 10.9412 - exp_rmse_score_fn: 0.3348 - val_loss: 115.8911 - val_root_mean_squared_error: 10.7653 - val_exp_rmse_score_fn: 0.3408\n",
            "Epoch 50/10000\n",
            "1/1 [==============================] - 1s 577ms/step - loss: 118.8218 - root_mean_squared_error: 10.9005 - exp_rmse_score_fn: 0.3362 - val_loss: 115.0628 - val_root_mean_squared_error: 10.7267 - val_exp_rmse_score_fn: 0.3421\n",
            "Epoch 51/10000\n",
            "1/1 [==============================] - 1s 585ms/step - loss: 117.9759 - root_mean_squared_error: 10.8617 - exp_rmse_score_fn: 0.3375 - val_loss: 114.2865 - val_root_mean_squared_error: 10.6905 - val_exp_rmse_score_fn: 0.3433\n",
            "Epoch 52/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 117.1759 - root_mean_squared_error: 10.8248 - exp_rmse_score_fn: 0.3388 - val_loss: 113.5506 - val_root_mean_squared_error: 10.6560 - val_exp_rmse_score_fn: 0.3445\n",
            "Epoch 53/10000\n",
            "1/1 [==============================] - 1s 594ms/step - loss: 116.4118 - root_mean_squared_error: 10.7894 - exp_rmse_score_fn: 0.3400 - val_loss: 112.8546 - val_root_mean_squared_error: 10.6233 - val_exp_rmse_score_fn: 0.3456\n",
            "Epoch 54/10000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 115.6844 - root_mean_squared_error: 10.7557 - exp_rmse_score_fn: 0.3411 - val_loss: 112.1927 - val_root_mean_squared_error: 10.5921 - val_exp_rmse_score_fn: 0.3467\n",
            "Epoch 55/10000\n",
            "1/1 [==============================] - 1s 571ms/step - loss: 114.9880 - root_mean_squared_error: 10.7232 - exp_rmse_score_fn: 0.3422 - val_loss: 111.5682 - val_root_mean_squared_error: 10.5626 - val_exp_rmse_score_fn: 0.3478\n",
            "Epoch 56/10000\n",
            "1/1 [==============================] - 1s 570ms/step - loss: 114.3270 - root_mean_squared_error: 10.6924 - exp_rmse_score_fn: 0.3433 - val_loss: 110.9833 - val_root_mean_squared_error: 10.5349 - val_exp_rmse_score_fn: 0.3487\n",
            "Epoch 57/10000\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 113.7054 - root_mean_squared_error: 10.6633 - exp_rmse_score_fn: 0.3443 - val_loss: 110.4370 - val_root_mean_squared_error: 10.5089 - val_exp_rmse_score_fn: 0.3496\n",
            "Epoch 58/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 113.1214 - root_mean_squared_error: 10.6359 - exp_rmse_score_fn: 0.3452 - val_loss: 109.9250 - val_root_mean_squared_error: 10.4845 - val_exp_rmse_score_fn: 0.3505\n",
            "Epoch 59/10000\n",
            "1/1 [==============================] - 1s 585ms/step - loss: 112.5705 - root_mean_squared_error: 10.6099 - exp_rmse_score_fn: 0.3461 - val_loss: 109.4417 - val_root_mean_squared_error: 10.4614 - val_exp_rmse_score_fn: 0.3513\n",
            "Epoch 60/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 112.0486 - root_mean_squared_error: 10.5853 - exp_rmse_score_fn: 0.3470 - val_loss: 108.9980 - val_root_mean_squared_error: 10.4402 - val_exp_rmse_score_fn: 0.3520\n",
            "Epoch 61/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 111.5671 - root_mean_squared_error: 10.5625 - exp_rmse_score_fn: 0.3478 - val_loss: 108.5870 - val_root_mean_squared_error: 10.4205 - val_exp_rmse_score_fn: 0.3527\n",
            "Epoch 62/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 111.1180 - root_mean_squared_error: 10.5413 - exp_rmse_score_fn: 0.3485 - val_loss: 108.2008 - val_root_mean_squared_error: 10.4020 - val_exp_rmse_score_fn: 0.3534\n",
            "Epoch 63/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 110.6939 - root_mean_squared_error: 10.5211 - exp_rmse_score_fn: 0.3492 - val_loss: 107.8315 - val_root_mean_squared_error: 10.3842 - val_exp_rmse_score_fn: 0.3540\n",
            "Epoch 64/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 110.2874 - root_mean_squared_error: 10.5018 - exp_rmse_score_fn: 0.3499 - val_loss: 107.4698 - val_root_mean_squared_error: 10.3668 - val_exp_rmse_score_fn: 0.3546\n",
            "Epoch 65/10000\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 109.8902 - root_mean_squared_error: 10.4829 - exp_rmse_score_fn: 0.3505 - val_loss: 107.1144 - val_root_mean_squared_error: 10.3496 - val_exp_rmse_score_fn: 0.3552\n",
            "Epoch 66/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 109.5024 - root_mean_squared_error: 10.4643 - exp_rmse_score_fn: 0.3512 - val_loss: 106.7595 - val_root_mean_squared_error: 10.3324 - val_exp_rmse_score_fn: 0.3559\n",
            "Epoch 67/10000\n",
            "1/1 [==============================] - 1s 592ms/step - loss: 109.1207 - root_mean_squared_error: 10.4461 - exp_rmse_score_fn: 0.3518 - val_loss: 106.4020 - val_root_mean_squared_error: 10.3151 - val_exp_rmse_score_fn: 0.3565\n",
            "Epoch 68/10000\n",
            "1/1 [==============================] - 1s 571ms/step - loss: 108.7396 - root_mean_squared_error: 10.4278 - exp_rmse_score_fn: 0.3525 - val_loss: 106.0319 - val_root_mean_squared_error: 10.2972 - val_exp_rmse_score_fn: 0.3571\n",
            "Epoch 69/10000\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 108.3512 - root_mean_squared_error: 10.4092 - exp_rmse_score_fn: 0.3531 - val_loss: 105.6569 - val_root_mean_squared_error: 10.2790 - val_exp_rmse_score_fn: 0.3578\n",
            "Epoch 70/10000\n",
            "1/1 [==============================] - 1s 576ms/step - loss: 107.9648 - root_mean_squared_error: 10.3906 - exp_rmse_score_fn: 0.3538 - val_loss: 105.2710 - val_root_mean_squared_error: 10.2602 - val_exp_rmse_score_fn: 0.3584\n",
            "Epoch 71/10000\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 107.5733 - root_mean_squared_error: 10.3718 - exp_rmse_score_fn: 0.3545 - val_loss: 104.8732 - val_root_mean_squared_error: 10.2408 - val_exp_rmse_score_fn: 0.3591\n",
            "Epoch 72/10000\n",
            "1/1 [==============================] - 1s 591ms/step - loss: 107.1764 - root_mean_squared_error: 10.3526 - exp_rmse_score_fn: 0.3551 - val_loss: 104.4641 - val_root_mean_squared_error: 10.2208 - val_exp_rmse_score_fn: 0.3598\n",
            "Epoch 73/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 106.7754 - root_mean_squared_error: 10.3332 - exp_rmse_score_fn: 0.3558 - val_loss: 104.0592 - val_root_mean_squared_error: 10.2009 - val_exp_rmse_score_fn: 0.3606\n",
            "Epoch 74/10000\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 106.3791 - root_mean_squared_error: 10.3140 - exp_rmse_score_fn: 0.3565 - val_loss: 103.6452 - val_root_mean_squared_error: 10.1806 - val_exp_rmse_score_fn: 0.3613\n",
            "Epoch 75/10000\n",
            "1/1 [==============================] - 1s 570ms/step - loss: 105.9742 - root_mean_squared_error: 10.2944 - exp_rmse_score_fn: 0.3572 - val_loss: 103.2199 - val_root_mean_squared_error: 10.1597 - val_exp_rmse_score_fn: 0.3621\n",
            "Epoch 76/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 105.5587 - root_mean_squared_error: 10.2742 - exp_rmse_score_fn: 0.3579 - val_loss: 102.7912 - val_root_mean_squared_error: 10.1386 - val_exp_rmse_score_fn: 0.3628\n",
            "Epoch 77/10000\n",
            "1/1 [==============================] - 1s 577ms/step - loss: 105.1392 - root_mean_squared_error: 10.2537 - exp_rmse_score_fn: 0.3587 - val_loss: 102.3623 - val_root_mean_squared_error: 10.1174 - val_exp_rmse_score_fn: 0.3636\n",
            "Epoch 78/10000\n",
            "1/1 [==============================] - 1s 561ms/step - loss: 104.7166 - root_mean_squared_error: 10.2331 - exp_rmse_score_fn: 0.3594 - val_loss: 101.9260 - val_root_mean_squared_error: 10.0958 - val_exp_rmse_score_fn: 0.3644\n",
            "Epoch 79/10000\n",
            "1/1 [==============================] - 1s 585ms/step - loss: 104.2838 - root_mean_squared_error: 10.2119 - exp_rmse_score_fn: 0.3602 - val_loss: 101.4722 - val_root_mean_squared_error: 10.0733 - val_exp_rmse_score_fn: 0.3652\n",
            "Epoch 80/10000\n",
            "1/1 [==============================] - 1s 584ms/step - loss: 103.8345 - root_mean_squared_error: 10.1899 - exp_rmse_score_fn: 0.3610 - val_loss: 101.0162 - val_root_mean_squared_error: 10.0507 - val_exp_rmse_score_fn: 0.3660\n",
            "Epoch 81/10000\n",
            "1/1 [==============================] - 1s 591ms/step - loss: 103.3830 - root_mean_squared_error: 10.1677 - exp_rmse_score_fn: 0.3618 - val_loss: 100.5520 - val_root_mean_squared_error: 10.0276 - val_exp_rmse_score_fn: 0.3669\n",
            "Epoch 82/10000\n",
            "1/1 [==============================] - 1s 570ms/step - loss: 102.9202 - root_mean_squared_error: 10.1450 - exp_rmse_score_fn: 0.3626 - val_loss: 100.0797 - val_root_mean_squared_error: 10.0040 - val_exp_rmse_score_fn: 0.3677\n",
            "Epoch 83/10000\n",
            "1/1 [==============================] - 1s 591ms/step - loss: 102.4460 - root_mean_squared_error: 10.1216 - exp_rmse_score_fn: 0.3634 - val_loss: 99.6049 - val_root_mean_squared_error: 9.9802 - val_exp_rmse_score_fn: 0.3686\n",
            "Epoch 84/10000\n",
            "1/1 [==============================] - 1s 584ms/step - loss: 101.9643 - root_mean_squared_error: 10.0977 - exp_rmse_score_fn: 0.3643 - val_loss: 99.1309 - val_root_mean_squared_error: 9.9565 - val_exp_rmse_score_fn: 0.3695\n",
            "Epoch 85/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 101.4794 - root_mean_squared_error: 10.0737 - exp_rmse_score_fn: 0.3652 - val_loss: 98.6468 - val_root_mean_squared_error: 9.9321 - val_exp_rmse_score_fn: 0.3704\n",
            "Epoch 86/10000\n",
            "1/1 [==============================] - 1s 585ms/step - loss: 100.9819 - root_mean_squared_error: 10.0490 - exp_rmse_score_fn: 0.3661 - val_loss: 98.1503 - val_root_mean_squared_error: 9.9071 - val_exp_rmse_score_fn: 0.3713\n",
            "Epoch 87/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 100.4699 - root_mean_squared_error: 10.0235 - exp_rmse_score_fn: 0.3670 - val_loss: 97.6476 - val_root_mean_squared_error: 9.8817 - val_exp_rmse_score_fn: 0.3723\n",
            "Epoch 88/10000\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 99.9496 - root_mean_squared_error: 9.9975 - exp_rmse_score_fn: 0.3680 - val_loss: 97.1290 - val_root_mean_squared_error: 9.8554 - val_exp_rmse_score_fn: 0.3732\n",
            "Epoch 89/10000\n",
            "1/1 [==============================] - 1s 582ms/step - loss: 99.4129 - root_mean_squared_error: 9.9706 - exp_rmse_score_fn: 0.3690 - val_loss: 96.5944 - val_root_mean_squared_error: 9.8282 - val_exp_rmse_score_fn: 0.3743\n",
            "Epoch 90/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 98.8600 - root_mean_squared_error: 9.9428 - exp_rmse_score_fn: 0.3700 - val_loss: 96.0391 - val_root_mean_squared_error: 9.8000 - val_exp_rmse_score_fn: 0.3753\n",
            "Epoch 91/10000\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 98.2887 - root_mean_squared_error: 9.9141 - exp_rmse_score_fn: 0.3711 - val_loss: 95.4724 - val_root_mean_squared_error: 9.7710 - val_exp_rmse_score_fn: 0.3764\n",
            "Epoch 92/10000\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 97.7053 - root_mean_squared_error: 9.8846 - exp_rmse_score_fn: 0.3721 - val_loss: 94.8921 - val_root_mean_squared_error: 9.7413 - val_exp_rmse_score_fn: 0.3775\n",
            "Epoch 93/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 97.1083 - root_mean_squared_error: 9.8544 - exp_rmse_score_fn: 0.3733 - val_loss: 94.2916 - val_root_mean_squared_error: 9.7104 - val_exp_rmse_score_fn: 0.3787\n",
            "Epoch 94/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 96.4935 - root_mean_squared_error: 9.8231 - exp_rmse_score_fn: 0.3744 - val_loss: 93.6735 - val_root_mean_squared_error: 9.6785 - val_exp_rmse_score_fn: 0.3799\n",
            "Epoch 95/10000\n",
            "1/1 [==============================] - 1s 587ms/step - loss: 95.8665 - root_mean_squared_error: 9.7911 - exp_rmse_score_fn: 0.3756 - val_loss: 93.0435 - val_root_mean_squared_error: 9.6459 - val_exp_rmse_score_fn: 0.3811\n",
            "Epoch 96/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 95.2306 - root_mean_squared_error: 9.7586 - exp_rmse_score_fn: 0.3769 - val_loss: 92.3973 - val_root_mean_squared_error: 9.6124 - val_exp_rmse_score_fn: 0.3824\n",
            "Epoch 97/10000\n",
            "1/1 [==============================] - 1s 611ms/step - loss: 94.5832 - root_mean_squared_error: 9.7254 - exp_rmse_score_fn: 0.3781 - val_loss: 91.7330 - val_root_mean_squared_error: 9.5777 - val_exp_rmse_score_fn: 0.3837\n",
            "Epoch 98/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 93.9198 - root_mean_squared_error: 9.6912 - exp_rmse_score_fn: 0.3794 - val_loss: 91.0634 - val_root_mean_squared_error: 9.5427 - val_exp_rmse_score_fn: 0.3851\n",
            "Epoch 99/10000\n",
            "1/1 [==============================] - 1s 577ms/step - loss: 93.2473 - root_mean_squared_error: 9.6565 - exp_rmse_score_fn: 0.3807 - val_loss: 90.3793 - val_root_mean_squared_error: 9.5068 - val_exp_rmse_score_fn: 0.3865\n",
            "Epoch 100/10000\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 92.5579 - root_mean_squared_error: 9.6207 - exp_rmse_score_fn: 0.3821 - val_loss: 89.6953 - val_root_mean_squared_error: 9.4708 - val_exp_rmse_score_fn: 0.3879\n",
            "Epoch 101/10000\n",
            "1/1 [==============================] - 1s 559ms/step - loss: 91.8675 - root_mean_squared_error: 9.5848 - exp_rmse_score_fn: 0.3835 - val_loss: 89.0118 - val_root_mean_squared_error: 9.4346 - val_exp_rmse_score_fn: 0.3893\n",
            "Epoch 102/10000\n",
            "1/1 [==============================] - 1s 583ms/step - loss: 91.1744 - root_mean_squared_error: 9.5485 - exp_rmse_score_fn: 0.3849 - val_loss: 88.3140 - val_root_mean_squared_error: 9.3976 - val_exp_rmse_score_fn: 0.3907\n",
            "Epoch 103/10000\n",
            "1/1 [==============================] - 1s 577ms/step - loss: 90.4660 - root_mean_squared_error: 9.5114 - exp_rmse_score_fn: 0.3863 - val_loss: 87.6199 - val_root_mean_squared_error: 9.3605 - val_exp_rmse_score_fn: 0.3922\n",
            "Epoch 104/10000\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 89.7579 - root_mean_squared_error: 9.4741 - exp_rmse_score_fn: 0.3877 - val_loss: 86.9351 - val_root_mean_squared_error: 9.3239 - val_exp_rmse_score_fn: 0.3936\n",
            "Epoch 105/10000\n",
            "1/1 [==============================] - 1s 580ms/step - loss: 89.0512 - root_mean_squared_error: 9.4367 - exp_rmse_score_fn: 0.3892 - val_loss: 86.2476 - val_root_mean_squared_error: 9.2870 - val_exp_rmse_score_fn: 0.3951\n",
            "Epoch 106/10000\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 88.3414 - root_mean_squared_error: 9.3990 - exp_rmse_score_fn: 0.3907 - val_loss: 85.5674 - val_root_mean_squared_error: 9.2503 - val_exp_rmse_score_fn: 0.3965\n",
            "Epoch 107/10000\n",
            "1/1 [==============================] - 1s 626ms/step - loss: 87.6353 - root_mean_squared_error: 9.3614 - exp_rmse_score_fn: 0.3921 - val_loss: 84.8848 - val_root_mean_squared_error: 9.2133 - val_exp_rmse_score_fn: 0.3980\n",
            "Epoch 108/10000\n",
            "1/1 [==============================] - 1s 580ms/step - loss: 86.9243 - root_mean_squared_error: 9.3233 - exp_rmse_score_fn: 0.3936 - val_loss: 84.2053 - val_root_mean_squared_error: 9.1763 - val_exp_rmse_score_fn: 0.3995\n",
            "Epoch 109/10000\n",
            "1/1 [==============================] - 1s 577ms/step - loss: 86.2178 - root_mean_squared_error: 9.2854 - exp_rmse_score_fn: 0.3951 - val_loss: 83.5464 - val_root_mean_squared_error: 9.1404 - val_exp_rmse_score_fn: 0.4009\n",
            "Epoch 110/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 85.5380 - root_mean_squared_error: 9.2487 - exp_rmse_score_fn: 0.3966 - val_loss: 82.8997 - val_root_mean_squared_error: 9.1049 - val_exp_rmse_score_fn: 0.4023\n",
            "Epoch 111/10000\n",
            "1/1 [==============================] - 1s 592ms/step - loss: 84.8671 - root_mean_squared_error: 9.2123 - exp_rmse_score_fn: 0.3980 - val_loss: 82.2779 - val_root_mean_squared_error: 9.0707 - val_exp_rmse_score_fn: 0.4037\n",
            "Epoch 112/10000\n",
            "1/1 [==============================] - 1s 603ms/step - loss: 84.2172 - root_mean_squared_error: 9.1770 - exp_rmse_score_fn: 0.3994 - val_loss: 81.6633 - val_root_mean_squared_error: 9.0368 - val_exp_rmse_score_fn: 0.4051\n",
            "Epoch 113/10000\n",
            "1/1 [==============================] - 1s 582ms/step - loss: 83.5759 - root_mean_squared_error: 9.1420 - exp_rmse_score_fn: 0.4008 - val_loss: 81.0700 - val_root_mean_squared_error: 9.0039 - val_exp_rmse_score_fn: 0.4064\n",
            "Epoch 114/10000\n",
            "1/1 [==============================] - 1s 585ms/step - loss: 82.9537 - root_mean_squared_error: 9.1079 - exp_rmse_score_fn: 0.4022 - val_loss: 80.4967 - val_root_mean_squared_error: 8.9720 - val_exp_rmse_score_fn: 0.4077\n",
            "Epoch 115/10000\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 82.3518 - root_mean_squared_error: 9.0748 - exp_rmse_score_fn: 0.4035 - val_loss: 79.9404 - val_root_mean_squared_error: 8.9409 - val_exp_rmse_score_fn: 0.4090\n",
            "Epoch 116/10000\n",
            "1/1 [==============================] - 1s 578ms/step - loss: 81.7693 - root_mean_squared_error: 9.0426 - exp_rmse_score_fn: 0.4048 - val_loss: 79.3998 - val_root_mean_squared_error: 8.9107 - val_exp_rmse_score_fn: 0.4102\n",
            "Epoch 117/10000\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 81.2059 - root_mean_squared_error: 9.0114 - exp_rmse_score_fn: 0.4061 - val_loss: 78.8768 - val_root_mean_squared_error: 8.8813 - val_exp_rmse_score_fn: 0.4114\n",
            "Epoch 118/10000\n",
            "1/1 [==============================] - 1s 578ms/step - loss: 80.6543 - root_mean_squared_error: 8.9808 - exp_rmse_score_fn: 0.4074 - val_loss: 78.3685 - val_root_mean_squared_error: 8.8526 - val_exp_rmse_score_fn: 0.4126\n",
            "Epoch 119/10000\n",
            "1/1 [==============================] - 1s 582ms/step - loss: 80.1311 - root_mean_squared_error: 8.9516 - exp_rmse_score_fn: 0.4085 - val_loss: 77.8825 - val_root_mean_squared_error: 8.8251 - val_exp_rmse_score_fn: 0.4137\n",
            "Epoch 120/10000\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 79.6261 - root_mean_squared_error: 8.9233 - exp_rmse_score_fn: 0.4097 - val_loss: 77.4212 - val_root_mean_squared_error: 8.7989 - val_exp_rmse_score_fn: 0.4148\n",
            "Epoch 121/10000\n",
            "1/1 [==============================] - 1s 576ms/step - loss: 79.1387 - root_mean_squared_error: 8.8960 - exp_rmse_score_fn: 0.4108 - val_loss: 76.9711 - val_root_mean_squared_error: 8.7733 - val_exp_rmse_score_fn: 0.4159\n",
            "Epoch 122/10000\n",
            "1/1 [==============================] - 1s 582ms/step - loss: 78.6647 - root_mean_squared_error: 8.8693 - exp_rmse_score_fn: 0.4119 - val_loss: 76.5405 - val_root_mean_squared_error: 8.7487 - val_exp_rmse_score_fn: 0.4169\n",
            "Epoch 123/10000\n",
            "1/1 [==============================] - 1s 585ms/step - loss: 78.2136 - root_mean_squared_error: 8.8438 - exp_rmse_score_fn: 0.4130 - val_loss: 76.1405 - val_root_mean_squared_error: 8.7259 - val_exp_rmse_score_fn: 0.4179\n",
            "Epoch 124/10000\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 77.7906 - root_mean_squared_error: 8.8199 - exp_rmse_score_fn: 0.4140 - val_loss: 75.7539 - val_root_mean_squared_error: 8.7037 - val_exp_rmse_score_fn: 0.4188\n",
            "Epoch 125/10000\n",
            "1/1 [==============================] - 1s 598ms/step - loss: 77.3794 - root_mean_squared_error: 8.7966 - exp_rmse_score_fn: 0.4149 - val_loss: 75.3908 - val_root_mean_squared_error: 8.6828 - val_exp_rmse_score_fn: 0.4197\n",
            "Epoch 126/10000\n",
            "1/1 [==============================] - 1s 590ms/step - loss: 76.9910 - root_mean_squared_error: 8.7745 - exp_rmse_score_fn: 0.4158 - val_loss: 75.0236 - val_root_mean_squared_error: 8.6616 - val_exp_rmse_score_fn: 0.4206\n",
            "Epoch 127/10000\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 76.6012 - root_mean_squared_error: 8.7522 - exp_rmse_score_fn: 0.4168 - val_loss: 74.6661 - val_root_mean_squared_error: 8.6410 - val_exp_rmse_score_fn: 0.4214\n",
            "Epoch 128/10000\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 76.2252 - root_mean_squared_error: 8.7307 - exp_rmse_score_fn: 0.4177 - val_loss: 74.3249 - val_root_mean_squared_error: 8.6212 - val_exp_rmse_score_fn: 0.4223\n",
            "Epoch 129/10000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-0d4a0ccb29ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_scr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_valid_processed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_column_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0mregressor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_scr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapply_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0mfinal_scr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-84-0d4a0ccb29ce>\u001b[0m in \u001b[0;36mapply_cross_validation\u001b[0;34m(lr0, num_iter, cv)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0mnorm_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_processed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_column_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_processed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_column_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train_processed_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_train_processed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m       \u001b[0;31m#mse, rmse=regressor.evaluate(df_valid_processed[all_column_names].values,df_valid_processed_label.values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0;31m#fold_results.append(np.exp(-rmse*MAX_SALE/10))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_validate, cross_val_score\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import KFold\n",
        "# CV \n",
        "def apply_cross_validation(lr0=0.001,num_iter=100,cv=5):\n",
        "    \n",
        "    seed_everything()\n",
        "    #regressor, fit_params=create_lgb_regressor(num_iter)\n",
        "    #regressor, fit_params=create_catboost_regressor(num_iter)\n",
        "        \n",
        "    col_ids=df_train_all_merged.collection_id.unique()\n",
        "    print(f\"col_ids: {col_ids}\")\n",
        "    pred_results=np.zeros(len(df_train_all_merged))\n",
        "    y_true=np.zeros(len(df_train_all_merged))\n",
        "    fold_results=[]\n",
        "\n",
        "    res=None\n",
        "    kf = KFold(n_splits=cv, shuffle=True, random_state=MY_SEED)\n",
        "    \n",
        "    #for i, (train_index, test_index) in enumerate(kf.split(col_ids)):            \n",
        "      #print(f\"Fold {i}: train collections: {col_ids[train_index]} test collections: {col_ids[test_index]}\")\n",
        "      #train_col_ids=df_train_all_merged.collection_id.isin(col_ids[train_index])\n",
        "      #test_col_ids=df_train_all_merged.collection_id.isin(col_ids[test_index])\n",
        "      ###print(f\"test_col_ids: {test_col_ids}\")\n",
        "      #df_train_processed=df_train_all_merged[train_col_ids].copy()           \n",
        "      #df_valid_processed=df_train_all_merged[test_col_ids].copy()\n",
        "      #df_train_processed_label=df_train_all_merged_label[train_col_ids]\n",
        "      #df_valid_processed_label=df_train_all_merged_label[test_col_ids]\n",
        "   \n",
        "    for i, (train_index, test_index) in enumerate(kf.split(df_train_all_merged)):            \n",
        "      print(f\"MAX_SALE: {MAX_SALE}\")\n",
        "      df_train_processed=df_train_all_merged.iloc[train_index].copy()     \n",
        "      df_valid_processed=df_train_all_merged.iloc[test_index].copy()\n",
        "      df_train_processed_label=df_train_all_merged_label.iloc[train_index]\n",
        "      df_valid_processed_label=df_train_all_merged_label.iloc[test_index]\n",
        "\n",
        "      preprocessing=createPreprocessing()\n",
        "      df_train_processed=preprocessing.fit_transform(df_train_processed)\n",
        "      df_valid_processed=preprocessing.transform(df_valid_processed)\n",
        "\n",
        "\n",
        "      #model, fit_params=create_lgb_regressor(num_iter)\n",
        "      #model, fit_params=create_catboost_regressor(num_iter)\n",
        "      regressor, fit_params, norm_layer=create_mlp_regressor(lr0,num_iter)\n",
        "      if i==0:\n",
        "        tf.keras.utils.plot_model(regressor, \"my_nft.png\", show_shapes=True)\n",
        "        print(regressor.summary())\n",
        "\n",
        "      lgb_valid = [(df_train_processed[all_column_names].values,df_train_processed_label.values),\n",
        "                  (df_valid_processed[all_column_names].values,df_valid_processed_label.values)]\n",
        "      #fit_params['regressior__eval_set']=lgb_valid   \n",
        "      fit_params['validation_data']=(df_valid_processed[all_column_names].values,df_valid_processed_label.values)   \n",
        "      #lr_scdeduler=tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
        "     \n",
        "      def exponential_decay(lr0=0.01, s=5):\n",
        "        def exponential_decay_fn(epoch):\n",
        "          return lr0*0.1**(epoch/s)\n",
        "        return exponential_decay_fn\n",
        "      \n",
        "      exponential_decay_fn =exponential_decay(lr0=lr0, s=10)\n",
        "\n",
        "      lr_scdeduler=tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
        "      early_stopping_cb = tf.keras.callbacks.EarlyStopping( monitor=\"val_root_mean_squared_error\", patience=50, restore_best_weights=True)\n",
        "\n",
        "      norm_layer.adapt(df_train_processed[all_column_names].to_numpy())\n",
        "      history=regressor.fit(df_train_processed[all_column_names].to_numpy(), df_train_processed_label.to_numpy(),  **fit_params, callbacks=[early_stopping_cb], batch_size=df_train_processed.shape[0])  \n",
        "      #mse, rmse=regressor.evaluate(df_valid_processed[all_column_names].values,df_valid_processed_label.values)\n",
        "      #fold_results.append(np.exp(-rmse*MAX_SALE/10))\n",
        "      eval_results=regressor.evaluate(df_valid_processed[all_column_names].to_numpy(),df_valid_processed_label.to_numpy())\n",
        "      fold_results.append(eval_results)\n",
        "      predict_hat=regressor.predict(df_valid_processed[all_column_names].to_numpy())\n",
        "      print(f\" predict_hat shape: {predict_hat.shape}\")\n",
        "      predict_hat=predict_hat[:,0]*MAX_SALE\n",
        "      pred_results[test_index]=predict_hat*MAX_SALE\n",
        "      y_true[test_index]=df_valid_processed_label*MAX_SALE\n",
        "\n",
        "      scr=exp_rmse_score(df_valid_processed_label,predict_hat)\n",
        "      my_exp_rmse_score=create_exp_rmse_score(mult=-1, log=True)\n",
        "      scr2=my_exp_rmse_score(df_valid_processed_label,predict_hat)\n",
        "\n",
        "      #scr=exp_rmse_score(df_valid_processed_label[test_col_ids],df_valid_processed_label[test_col_ids])\n",
        "      print(f\" fold: {i} exp_rmse_score: {scr} scr2: {scr2} eval_results: {eval_results} fold_results: {fold_results}  \")\n",
        "      #predict_hat[:,1]*MAX_SALE      \n",
        "      #break;\n",
        "\n",
        "      #return regressor, pred_results, y_true, 0, fold_results, df_valid_processed[all_column_names], df_valid_processed_label\n",
        "\n",
        "    \n",
        "    final_scr=exp_rmse_score(y_true, pred_results)\n",
        "    print(f\" final exp_rmse_score: {final_scr}\")\n",
        "\n",
        "    #res=cross_validate(regressor,df_train[all_column_names],df_train_label,  fit_params=fit_params,scoring=make_scorer(exp_rmse_score), cv=cv, verbose=1)    \n",
        "    #res=cross_val_score(regressor,df_train_processed[all_column_names],df_train_label,  fit_params=fit_params, scoring=make_scorer(exp_rmse_score, greater_is_better=True), cv=cv)    \n",
        "    return regressor, pred_results, y_true, final_scr, fold_results, df_valid_processed[all_column_names]\n",
        "\n",
        "regressor,pred_results, y_true, final_scr, fold_results, df_v, v_label=apply_cross_validation(lr0=0.001,num_iter=10000,cv=5)\n",
        "final_scr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfs"
      ],
      "metadata": {
        "id": "ivluD10JRUld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8CEoKi_bDDP"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_validate, cross_val_score\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import KFold\n",
        "# CV \n",
        "def apply_cross_validation(num_iter=100,cv=5):\n",
        "    seed_everything()\n",
        "    #regressor, fit_params=create_lgb_regressor(num_iter)\n",
        "    #regressor, fit_params=create_catboost_regressor(num_iter)\n",
        "        \n",
        "    col_ids=df_train_all_merged.collection_id.unique()\n",
        "    print(f\"col_ids: {col_ids}\")\n",
        "    pred_results=np.ones(len(df_train_all_merged))*100\n",
        "    y_true=np.zeros(len(df_train_all_merged))\n",
        "    fold_results=[]\n",
        "\n",
        "    res=None\n",
        "    kf = KFold(n_splits=cv, shuffle=True, random_state=MY_SEED)\n",
        "    #for i, (train_index, test_index) in enumerate(kf.split(col_ids)):                \n",
        "      #print(f\"Fold {i}: train collections: {col_ids[train_index]} test collections: {col_ids[test_index]}\")\n",
        "      #train_col_ids=df_train_all_merged.collection_id.isin(col_ids[train_index])\n",
        "      #test_col_ids=df_train_all_merged.collection_id.isin(col_ids[test_index])\n",
        "\n",
        "    for i, (train_index, test_index) in enumerate(kf.split(df_train_all_merged)):            \n",
        "      df_train_processed=df_train_all_merged.iloc[train_index].copy()     \n",
        "      df_valid_processed=df_train_all_merged.iloc[test_index].copy()\n",
        "      df_train_processed_label=df_train_all_merged_label.iloc[train_index]\n",
        "      df_valid_processed_label=df_train_all_merged_label.iloc[test_index]\n",
        "\n",
        "\n",
        "      preprocessing=createPreprocessing()\n",
        "      df_train_processed=preprocessing.fit_transform(df_train_processed)\n",
        "      df_valid_processed=preprocessing.transform(df_valid_processed)\n",
        "\n",
        "      #model, fit_params=create_lgb_regressor(num_iter)\n",
        "      regressor, fit_params=create_catboost_regressor(num_iter)\n",
        "      #regressor, fit_params, norm_layer=create_mlp_regressor(num_iter)\n",
        "     \n",
        "\n",
        "      lgb_valid = [(df_train_processed[all_column_names],df_train_processed_label),\n",
        "                  (df_valid_processed[all_column_names],df_valid_processed_label)]\n",
        "      #fit_params['regressior__eval_set']=lgb_valid   \n",
        "      fit_params['eval_set']=(df_valid_processed[all_column_names],df_valid_processed_label)   \n",
        "      regressor=regressor.fit(df_train_processed[all_column_names], df_train_processed_label,  **fit_params)  \n",
        "\n",
        "      predict_hat=regressor.predict(df_valid_processed[all_column_names])\n",
        "      #print(predict_hat.shape)\n",
        "      #print(predict_hat)\n",
        "      #pred_results[test_index]=predict_hat*MAX_SALE\n",
        "      #y_true[test_index]=df_valid_processed_label[test_index]*MAX_SALE\n",
        "      pred_results[test_index]=np.exp(predict_hat)\n",
        "      y_true[test_index]=np.exp(df_valid_processed_label[test_index])\n",
        "\n",
        "      scr=exp_rmse_score(y_true[test_index],predict_hat)\n",
        "      #scr=exp_rmse_score(df_valid_processed_label[test_col_ids],df_valid_processed_label[test_col_ids])\n",
        "      print(f\" fold: {i} exp_rmse_score: {scr}  \")\n",
        "      \n",
        "      #XXX\n",
        "      break;\n",
        "\n",
        "    \n",
        "    final_scr=exp_rmse_score(y_true, pred_results)\n",
        "    print(f\" final exp_rmse_score: {final_scr}\")\n",
        "\n",
        "    #res=cross_validate(regressor,df_train[all_column_names],df_train_label,  fit_params=fit_params,scoring=make_scorer(exp_rmse_score), cv=cv, verbose=1)    \n",
        "    #res=cross_val_score(regressor,df_train_processed[all_column_names],df_train_label,  fit_params=fit_params, scoring=make_scorer(exp_rmse_score, greater_is_better=True), cv=cv)    \n",
        "    return regressor, pred_results, y_true, final_scr, fold_results, df_valid_processed[all_column_names]\n",
        "\n",
        "regressor,pred_results, y_true, final_scr, fold_results, df_v=apply_cross_validation(num_iter=500,cv=10)\n",
        "final_scr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_processed=df_train_all_merged.copy()     \n",
        "df_train_all_processed_label=df_train_all_merged_label.values\n",
        "\n",
        "preprocessing=createPreprocessing()\n",
        "df_train_all_processed=preprocessing.fit_transform(df_train_processed)"
      ],
      "metadata": {
        "id": "mOCLiYJhmFmg",
        "outputId": "9356ff81-9c82-45e2-b4ef-7642bd75c437",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting categorical feature with input shape: (309910, 33)\n",
            "[Pipeline]  (step 1 of 4) Processing categoricaltransformer, total=   0.2s\n",
            "starting feature with input shape: (309910, 33)\n",
            "[Pipeline]  (step 2 of 4) Processing featuretransformers, total=   0.1s\n",
            "starting avg price feature with input shape: (309910, 45)\n",
            "[Pipeline]  (step 3 of 4) Processing avgpricetransformer, total=   1.9s\n",
            "starting fill na imputer with input shape:  (309910, 59)\n",
            "[Pipeline] ..... (step 4 of 4) Processing fillnaimputer, total=   0.1s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "3altyg_l-rtO",
        "outputId": "1f67764b-7ca2-4eee-9ee8-6fa093ce0edc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 164.8824 - root_mean_squared_error: 12.8407 - exp_rmse_score_fn: 0.2769\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 164.3374 - root_mean_squared_error: 12.8194 - exp_rmse_score_fn: 0.2775\n"
          ]
        }
      ],
      "source": [
        "regressor, fit_params, norm_layer=create_mlp_regressor(lr0=0.001,num_iter=10)\n",
        "#lr_scdeduler=tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3, monitor=\"root_mean_squared_error\")\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping( monitor=\"root_mean_squared_error\", patience=10, restore_best_weights=True)\n",
        "\n",
        "norm_layer.adapt(df_train_all_processed[all_column_names].to_numpy())\n",
        "#history=regressor.fit(df_train_all_processed[all_column_names].to_numpy(), df_train_all_processed_label.to_numpy(),  **fit_params, callbacks=[early_stopping_cb, lr_scdeduler])  \n",
        "history=regressor.fit(df_train_all_processed[all_column_names].to_numpy(), df_train_all_processed_label,  **fit_params, callbacks=[early_stopping_cb], batch_size=309910)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdZ0hyrP1FvK"
      },
      "outputs": [],
      "source": [
        "#regressor, fit_params=create_catboost_regressor(2000)\n",
        "#regressor, fit_params=create_lgb_regressor(100)\n",
        "#regressor.fit(df_train_all_processed[all_column_names], df_train_all_processed_label,**fit_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "8khyHq0tQ8Pn",
        "outputId": "47ca7e63-b735-40be-d750-3b9e5e62e12f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9685/9685 [==============================] - 11s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "final_train_pred_results=regressor.predict(df_train_all_processed[all_column_names])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.histogram(final_train_pred_results)"
      ],
      "metadata": {
        "id": "2lE_LJuE4FaX",
        "outputId": "a67edc0f-71ab-4f1c-9701-d9e40321d305",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([302273,   1768,   1628,   1067,    437,    264,    274,    857,\n",
              "           619,    723]),\n",
              " array([ -1.4501765,  11.704668 ,  24.859512 ,  38.014355 ,  51.1692   ,\n",
              "         64.32404  ,  77.47889  ,  90.633736 , 103.788574 , 116.94342  ,\n",
              "        130.09827  ], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.histogram(final_train_pred_results)"
      ],
      "metadata": {
        "id": "HGeSCZc74X4X",
        "outputId": "a7975d17-6850-461a-c09d-17d3871729ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([302273,   1768,   1628,   1067,    437,    264,    274,    857,\n",
              "           619,    723]),\n",
              " array([ -1.4501765,  11.704668 ,  24.859512 ,  38.014355 ,  51.1692   ,\n",
              "         64.32404  ,  77.47889  ,  90.633736 , 103.788574 , 116.94342  ,\n",
              "        130.09827  ], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "90ZgnDrDRQ2S",
        "outputId": "22baa833-8851-4b2e-a395-7674133254c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numpy rmse: 7.853390704464746 res: 0.4559650712915057\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4559650712915057"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "exp_rmse_score(final_train_pred_results, df_train_all_processed_label)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#my_exp_rmse_score=create_exp_rmse_score(-1)\n",
        "#my_exp_rmse_score(final_train_pred_results, df_train_all_processed_label)"
      ],
      "metadata": {
        "id": "1Z4PFvzOn1yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "u9u6TQtpM4Zv",
        "outputId": "51433135-a5e5-4327-97a9-f5b47bbf6029",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting categorical feature with input shape: (181214, 32)\n",
            "starting feature with input shape: (181214, 32)\n",
            "starting avg price feature with input shape: (181214, 44)\n",
            "starting fill na imputer with input shape:  (181214, 58)\n"
          ]
        }
      ],
      "source": [
        "df_test_all_merged=df_nfts_predict.merge(df_cols,on='collection_id').merge(df_cols_stats, on='collection_id')\n",
        "df_test_all_processed = preprocessing.transform(df_test_all_merged)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "tlu3AxUoM-qo",
        "outputId": "69fc1ebe-ca5d-4369-f858-112fdfbf8249",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5663/5663 [==============================] - 6s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "final_pred_results=regressor.predict(df_test_all_processed[all_column_names])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "9PqaNoiZNZ8M",
        "outputId": "5549f026-7c3d-4f28-d910-527136cab7e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f93e920b940>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVqElEQVR4nO3dcayddZ3n8fdn20GrMwrI5MZt2W03Nk4Q1hVvgImbyY3MQlFj+QMdCDNUl7HZiDPOpBsts3+QVUkwOwwjrJI0tmMxRGQZd9uMOEyD3Lj7BwjIxArocoMobUDUAk51lan73T/Or87Z6/219Jxyb8/1/UpO7vN8n9/zPL/ffdrz6XnO75ymqpAkaSH/bKk7IEk6cRkSkqQuQ0KS1GVISJK6DAlJUtfKpe7A8XbaaafV2rVrR9r3xz/+Ma985SuPb4dOMMt9jI5v8i33MZ6o43vwwQd/UFW/Ob++7EJi7dq1PPDAAyPtOzs7y8zMzPHt0AlmuY/R8U2+5T7GE3V8Sb6zUN3bTZKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpK5l94nrcezd/zzv2frFJTn3E9e9fUnOK0lH4isJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqSuo4ZEkh1JnknyjaHaf0nyzSRfT/Lfk5w8tO3qJHNJvpXkwqH6hlabS7J1qL4uyX2t/vkkJ7X6y9r6XNu+9ngNWpL04ryYVxKfATbMq+0Bzqyqfw38b+BqgCRnAJcCb2j7fCrJiiQrgE8CFwFnAJe1tgAfB26oqtcBzwJXtvqVwLOtfkNrJ0laREcNiar6CnBgXu3vqupQW70XWNOWNwK3VdXPqurbwBxwTnvMVdXjVfUCcBuwMUmAtwJ3tP13AhcPHWtnW74DOL+1lyQtkuPxP9P9e+DzbXk1g9A4bF+rATw5r34u8BrguaHAGW6/+vA+VXUoyfOt/Q/mdyDJZmAzwNTUFLOzsyMNZGoVbDnr0NEbvgRG7fOxOnjw4KKdayk4vsm33Mc4aeMbKySS/CfgEHDr8enOaKpqG7ANYHp6umZmZkY6zk237uL6vUvzP7o+cfnMopxndnaWUX8/k8DxTb7lPsZJG9/Iz4hJ3gO8Azi/qqqV9wOnDzVb02p06j8ETk6ysr2aGG5/+Fj7kqwEXt3aS5IWyUhTYJNsAD4EvLOqfjK0aTdwaZuZtA5YD3wVuB9Y32YyncTgze3dLVzuAS5p+28Cdg0da1NbvgT48lAYSZIWwVFfSST5HDADnJZkH3ANg9lMLwP2tPeS762q/1BVDye5HXiEwW2oq6rq5+04HwDuAlYAO6rq4XaKDwO3JfkY8BCwvdW3A59NMsfgjfNLj8N4JUnH4KghUVWXLVDevkDtcPtrgWsXqN8J3LlA/XEGs5/m138KvOto/ZMkvXT8xLUkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVLXUUMiyY4kzyT5xlDt1CR7kjzWfp7S6klyY5K5JF9PcvbQPpta+8eSbBqqvznJ3rbPjUlypHNIkhbPi3kl8Rlgw7zaVuDuqloP3N3WAS4C1rfHZuBmGDzhA9cA5wLnANcMPenfDLxvaL8NRzmHJGmRHDUkquorwIF55Y3Azra8E7h4qH5LDdwLnJzktcCFwJ6qOlBVzwJ7gA1t26uq6t6qKuCWecda6BySpEWycsT9pqrqqbb8NDDVllcDTw6129dqR6rvW6B+pHP8kiSbGbxyYWpqitnZ2WMcTjvhKthy1qGR9h3XqH0+VgcPHly0cy0Fxzf5lvsYJ218o4bEL1RVJanj0ZlRz1FV24BtANPT0zUzMzPSeW66dRfX7x37VzKSJy6fWZTzzM7OMurvZxI4vsm33Mc4aeMbdXbT99qtItrPZ1p9P3D6ULs1rXak+poF6kc6hyRpkYwaEruBwzOUNgG7hupXtFlO5wHPt1tGdwEXJDmlvWF9AXBX2/ajJOe1WU1XzDvWQueQJC2So95bSfI5YAY4Lck+BrOUrgNuT3Il8B3g3a35ncDbgDngJ8B7AarqQJKPAve3dh+pqsNvhr+fwQyqVcCX2oMjnEOStEiOGhJVdVln0/kLtC3gqs5xdgA7Fqg/AJy5QP2HC51DkrR4/MS1JKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoaKySS/GmSh5N8I8nnkrw8ybok9yWZS/L5JCe1ti9r63Nt+9qh41zd6t9KcuFQfUOrzSXZOk5fJUnHbuSQSLIa+GNguqrOBFYAlwIfB26oqtcBzwJXtl2uBJ5t9RtaO5Kc0fZ7A7AB+FSSFUlWAJ8ELgLOAC5rbSVJi2Tc200rgVVJVgKvAJ4C3grc0bbvBC5uyxvbOm37+UnS6rdV1c+q6tvAHHBOe8xV1eNV9QJwW2srSVokK0fdsar2J/lz4LvA/wH+DngQeK6qDrVm+4DVbXk18GTb91CS54HXtPq9Q4ce3ufJefVzF+pLks3AZoCpqSlmZ2dHGtPUKthy1qGjN3wJjNrnY3Xw4MFFO9dScHyTb7mPcdLGN3JIJDmFwb/s1wHPAf+Nwe2iRVdV24BtANPT0zUzMzPScW66dRfX7x35VzKWJy6fWZTzzM7OMurvZxI4vsm33Mc4aeMb53bT7wLfrqrvV9U/Al8A3gKc3G4/AawB9rfl/cDpAG37q4EfDtfn7dOrS5IWyTgh8V3gvCSvaO8tnA88AtwDXNLabAJ2teXdbZ22/ctVVa1+aZv9tA5YD3wVuB9Y32ZLncTgze3dY/RXknSMxnlP4r4kdwBfAw4BDzG45fNF4LYkH2u17W2X7cBnk8wBBxg86VNVDye5nUHAHAKuqqqfAyT5AHAXg5lTO6rq4VH7K0k6dmPdgK+qa4Br5pUfZzAzaX7bnwLv6hznWuDaBep3AneO00dJ0uj8xLUkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVLXWCGR5OQkdyT5ZpJHk/x2klOT7EnyWPt5SmubJDcmmUvy9SRnDx1nU2v/WJJNQ/U3J9nb9rkxScbpryTp2Iz7SuITwN9W1W8BbwQeBbYCd1fVeuDutg5wEbC+PTYDNwMkORW4BjgXOAe45nCwtDbvG9pvw5j9lSQdg5FDIsmrgd8BtgNU1QtV9RywEdjZmu0ELm7LG4FbauBe4OQkrwUuBPZU1YGqehbYA2xo215VVfdWVQG3DB1LkrQIVo6x7zrg+8BfJXkj8CDwQWCqqp5qbZ4GptryauDJof33tdqR6vsWqP+SJJsZvDphamqK2dnZkQY0tQq2nHVopH3HNWqfj9XBgwcX7VxLwfFNvuU+xkkb3zghsRI4G/ijqrovySf4p1tLAFRVJalxOvhiVNU2YBvA9PR0zczMjHScm27dxfV7x/mVjO6Jy2cW5Tyzs7OM+vuZBI5v8i33MU7a+MZ5T2IfsK+q7mvrdzAIje+1W0W0n8+07fuB04f2X9NqR6qvWaAuSVokI4dEVT0NPJnk9a10PvAIsBs4PENpE7CrLe8GrmiznM4Dnm+3pe4CLkhySnvD+gLgrrbtR0nOa7Oarhg6liRpEYx7b+WPgFuTnAQ8DryXQfDcnuRK4DvAu1vbO4G3AXPAT1pbqupAko8C97d2H6mqA235/cBngFXAl9pDkrRIxgqJqvp7YHqBTecv0LaAqzrH2QHsWKD+AHDmOH2UJI3OT1xLkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpK6xQyLJiiQPJfmbtr4uyX1J5pJ8PslJrf6ytj7Xtq8dOsbVrf6tJBcO1Te02lySreP2VZJ0bI7HK4kPAo8OrX8cuKGqXgc8C1zZ6lcCz7b6Da0dSc4ALgXeAGwAPtWCZwXwSeAi4AzgstZWkrRIxgqJJGuAtwOfbusB3grc0ZrsBC5uyxvbOm37+a39RuC2qvpZVX0bmAPOaY+5qnq8ql4AbmttJUmLZOWY+/8l8CHgN9r6a4DnqupQW98HrG7Lq4EnAarqUJLnW/vVwL1Dxxze58l59XMX6kSSzcBmgKmpKWZnZ0cazNQq2HLWoaM3fAmM2udjdfDgwUU711JwfJNvuY9x0sY3ckgkeQfwTFU9mGTm+HXp2FXVNmAbwPT0dM3MjNadm27dxfV7x83N0Txx+cyinGd2dpZRfz+TwPFNvuU+xkkb3zjPiG8B3pnkbcDLgVcBnwBOTrKyvZpYA+xv7fcDpwP7kqwEXg38cKh+2PA+vbokaRGM/J5EVV1dVWuqai2DN56/XFWXA/cAl7Rmm4BdbXl3W6dt/3JVVatf2mY/rQPWA18F7gfWt9lSJ7Vz7B61v5KkY/dS3Fv5MHBbko8BDwHbW3078Nkkc8ABBk/6VNXDSW4HHgEOAVdV1c8BknwAuAtYAeyoqodfgv5KkjqOS0hU1Sww25YfZzAzaX6bnwLv6ux/LXDtAvU7gTuPRx8lScfOT1xLkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1jRwSSU5Pck+SR5I8nOSDrX5qkj1JHms/T2n1JLkxyVySryc5e+hYm1r7x5JsGqq/Ocnets+NSTLOYCVJx2blGPseArZU1deS/AbwYJI9wHuAu6vquiRbga3Ah4GLgPXtcS5wM3BuklOBa4BpoNpxdlfVs63N+4D7gDuBDcCXxuizpF8Ra7d+cUnO+8R1b1+S875URn4lUVVPVdXX2vI/AI8Cq4GNwM7WbCdwcVveCNxSA/cCJyd5LXAhsKeqDrRg2ANsaNteVVX3VlUBtwwdS5K0CMZ5JfELSdYCb2LwL/6pqnqqbXoamGrLq4Enh3bb12pHqu9boL7Q+TcDmwGmpqaYnZ0daRxTq2DLWYdG2ndco/b5WB08eHDRzrUUHN+JZe/+5495n6lVcNOtu8Y+95azxj7ESI52fSbtGo4dEkl+Hfhr4E+q6kfDbxtUVSWpcc9xNFW1DdgGMD09XTMzMyMd56Zbd3H93uOSm8fsictnFuU8s7OzjPr7mQSO78TynhFu+Ww569CS/T08Ho72d3nSruFYs5uS/BqDgLi1qr7Qyt9rt4poP59p9f3A6UO7r2m1I9XXLFCXJC2ScWY3BdgOPFpVfzG0aTdweIbSJmDXUP2KNsvpPOD5dlvqLuCCJKe0mVAXAHe1bT9Kcl471xVDx5IkLYJxXtO9BfgDYG+Sv2+1PwOuA25PciXwHeDdbdudwNuAOeAnwHsBqupAko8C97d2H6mqA235/cBngFUMZjU5s0mSFtHIIVFV/wvofW7h/AXaF3BV51g7gB0L1B8Azhy1j5Kk8fiJa0lSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSuib3fxuXpBPQ2q1fPOL2LWcd4j1HaTOqJ657+3E/pq8kJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkrpO+JBIsiHJt5LMJdm61P2RpF8lJ/TnJJKsAD4J/DtgH3B/kt1V9cjS9uz4O9rc6uNl/hztl2JetaTl44QOCeAcYK6qHgdIchuwEVh2IbFUFiuc5jOcpMmQqlrqPnQluQTYUFV/2Nb/ADi3qj4wr91mYHNbfT3wrRFPeRrwgxH3nRTLfYyOb/It9zGeqOP7l1X1m/OLJ/oriRelqrYB28Y9TpIHqmr6OHTphLXcx+j4Jt9yH+Okje9Ef+N6P3D60PqaVpMkLYITPSTuB9YnWZfkJOBSYPcS90mSfmWc0LebqupQkg8AdwErgB1V9fBLeMqxb1lNgOU+Rsc3+Zb7GCdqfCf0G9eSpKV1ot9ukiQtIUNCktRlSDTL7es/kpye5J4kjyR5OMkHW/3UJHuSPNZ+nrLUfR1HkhVJHkryN219XZL72nX8fJvwMLGSnJzkjiTfTPJokt9eTtcwyZ+2P5/fSPK5JC+f9GuYZEeSZ5J8Y6i24DXLwI1trF9PcvbS9XxhhgT/39d/XAScAVyW5Iyl7dXYDgFbquoM4DzgqjamrcDdVbUeuLutT7IPAo8OrX8cuKGqXgc8C1y5JL06fj4B/G1V/RbwRgZjXRbXMMlq4I+B6ao6k8HklEuZ/Gv4GWDDvFrvml0ErG+PzcDNi9THF82QGPjF139U1QvA4a//mFhV9VRVfa0t/wODJ5fVDMa1szXbCVy8ND0cX5I1wNuBT7f1AG8F7mhNJn18rwZ+B9gOUFUvVNVzLKNryGCG5aokK4FXAE8x4dewqr4CHJhX7l2zjcAtNXAvcHKS1y5OT18cQ2JgNfDk0Pq+VlsWkqwF3gTcB0xV1VNt09PA1BJ163j4S+BDwP9t668BnquqQ2190q/jOuD7wF+1W2qfTvJKlsk1rKr9wJ8D32UQDs8DD7K8ruFhvWt2wj/3GBLLXJJfB/4a+JOq+tHwthrMf57IOdBJ3gE8U1UPLnVfXkIrgbOBm6vqTcCPmXdracKv4SkM/iW9DvjnwCv55ds0y86kXTNDYmBZfv1Hkl9jEBC3VtUXWvl7h1/Otp/PLFX/xvQW4J1JnmBwe/CtDO7fn9xuXcDkX8d9wL6quq+t38EgNJbLNfxd4NtV9f2q+kfgCwyu63K6hof1rtkJ/9xjSAwsu6//aPfntwOPVtVfDG3aDWxqy5uAXYvdt+Ohqq6uqjVVtZbB9fpyVV0O3ANc0ppN7PgAqupp4Mkkr2+l8xl8Tf6yuIYMbjOdl+QV7c/r4fEtm2s4pHfNdgNXtFlO5wHPD92WOiH4iesmydsY3OM+/PUf1y5xl8aS5N8C/xPYyz/ds/8zBu9L3A78C+A7wLurav6bbBMlyQzwH6vqHUn+FYNXFqcCDwG/X1U/W8r+jSPJv2HwxvxJwOPAexn8425ZXMMk/xn4PQaz8R4C/pDBPfmJvYZJPgfMMPhK8O8B1wD/gwWuWQvH/8rgNttPgPdW1QNL0e8eQ0KS1OXtJklSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1PX/ACs8YYUh3TXfAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "df_final_results=df_test_all_processed['global_index'].to_frame()\n",
        "df_final_results['last_sale_price']=np.where(final_pred_results>0,final_pred_results,0)\n",
        "#df_final_results['last_sale_price']=final_pred_results\n",
        "df_final_results.last_sale_price.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "uFoIW980NHOX"
      },
      "outputs": [],
      "source": [
        "current_time =datetime.datetime.now().strftime(\"%y_%m_%d_%H_%M_%S\")\n",
        "df_final_results.to_csv(f'submission_{current_time}.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bj-wZOTENSYJ"
      },
      "outputs": [],
      "source": [
        "#df_test_all_processed.global_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDHPG02LNJMQ"
      },
      "outputs": [],
      "source": [
        "#df_submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QELx_fbvNRZw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhQg_2TOrdJF"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(regressor, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lH4-9pMf6yko"
      },
      "outputs": [],
      "source": [
        "np.histogram(pred_results)\n",
        "#pred_results, y_true\n",
        "#y_true\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbgFhCa7oxCs"
      },
      "outputs": [],
      "source": [
        "np.sum(np.abs(pred_results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYyiwoxO-N-p"
      },
      "outputs": [],
      "source": [
        "df_pred_results=pd.DataFrame({'predict':pred_results, 'true':y_true})\n",
        "#df_pred_results=pd.DataFrame({'predict':pred_results})\n",
        "df_pred_results.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70m2Vz8XS9Y_"
      },
      "outputs": [],
      "source": [
        "df_pred_results.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDzgT5DujZnh"
      },
      "outputs": [],
      "source": [
        "fi=pd.DataFrame({'Feature':all_column_names,'importance':regressor.feature_importances_})\n",
        "fi.sort_values('importance',ascending=False, inplace=True)\n",
        "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
        "ax=sns.barplot(y='Feature',x='importance',data=fi)\n",
        "plt.xticks(rotation=90)\n",
        "fi.Feature[:30].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wdQFZmsjrfm"
      },
      "outputs": [],
      "source": [
        "regressor.predict(df_v.to_numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TY22qSLImNbX"
      },
      "outputs": [],
      "source": [
        "np.exp(-5.55/10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJrP1OIqpMho"
      },
      "outputs": [],
      "source": [
        "regressor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwIq3DsUpVcR"
      },
      "outputs": [],
      "source": [
        "len(all_column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYGoTweJw7es"
      },
      "source": [
        "#Run Regressor on the test validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYjerDfubRs2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def run_test_validation(num_iter=100):\n",
        "    seed_everything()\n",
        "    regressor, fit_params=create_lgb_regressor(num_iter)\n",
        "    #regressor, fit_params=create_catboost_regressor(num_iter)\n",
        "    \n",
        "    eval_set = [(df_train_processed[all_column_names],df_train_label),\n",
        "                (df_valid_processed[all_column_names],df_valid_label)]\n",
        "    fit_params['regressior__eval_set']=eval_set\n",
        "\n",
        "    print(f\"Applying num_iter: {num_iter} \")\n",
        "    res=regressor.fit(df_train_processed[all_column_names],df_train_label,  **fit_params)    \n",
        "    return regressor,res\n",
        "\n",
        "regressor,res=run_test_validation(num_iter=1000)t\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnnBDenFroiE"
      },
      "outputs": [],
      "source": [
        "np.exp(-23.3482362/10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BziEw0T8mmut"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uL4oc1Ns_RlK"
      },
      "outputs": [],
      "source": [
        "def run_all_train(num_iter=100):\n",
        "    seed_everything()\n",
        "    #regressor=create_regressor(num_iter)\n",
        "    regressor=create_catboost_regressor(num_iter)\n",
        "    \n",
        "    eval_set = [(df_train_all_processed[all_column_names],df_train_all_processed_label)]\n",
        "    fit_params={'regressior__eval_set':None, \n",
        "                #'regressior__eval_metric':[lgb_exp_rmse_score],\n",
        "                #'regressior__feature_name':all_column_names,\n",
        "                'regressior__cat_features':cat_features,\n",
        "                'regressior__verbose':1\n",
        "               }\n",
        "    print(f\"Applying num_iter: {num_iter} \")\n",
        "    res=regressor.fit(df_train_all_processed[all_column_names],df_train_all_processed_label,  **fit_params)    \n",
        "    return regressor,res\n",
        "\n",
        "regressor,res=run_all_train(num_iter=1000)\n",
        "res\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cW_yNldA_dsz"
      },
      "outputs": [],
      "source": [
        "df_train_all_processed[num_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I61DdtPHBMuJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/denizstij/Bitgrit_NFT_Price_Prediction/blob/main/Bitgrit_NFT_Price_Prediction.ipynb",
      "authorship_tag": "ABX9TyNWKA3g5UpFJABKzkMw6u1/",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}